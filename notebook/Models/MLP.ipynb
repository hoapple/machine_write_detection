{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLP\n",
        "## read data"
      ],
      "metadata": {
        "id": "KnrwoEUapnrt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NCtjp6TDj6W9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data1 = []\n",
        "data2 = []\n",
        "data3 = []\n",
        "test = []\n",
        "\n",
        "# Assuming the NDJSON data is stored in a file called 'data.ndjson'\n",
        "with open(\"domain1_train.json\", 'r') as file:\n",
        "    for line in file:\n",
        "        dict = json.loads(line.strip())\n",
        "        dict[\"domain\"] = 1\n",
        "        data3.append(dict)\n",
        "# Assuming the NDJSON data is stored in a file called 'data.ndjson'\n",
        "with open(\"domain2_train.json\", 'r') as file:\n",
        "    for line in file:\n",
        "        dict = json.loads(line.strip())\n",
        "        dict[\"domain\"] = 2\n",
        "        data3.append(dict)\n",
        "\n",
        "with open(\"test_set.json\", 'r') as file:\n",
        "    for line in file:\n",
        "        dict = json.loads(line.strip())\n",
        "        test.append(dict)\n",
        "\n",
        "\n",
        "# Assuming the NDJSON data is stored in a file called 'data.ndjson'\n",
        "with open(\"domain1_train.json\", 'r') as file:\n",
        "    for line in file:\n",
        "        dict = json.loads(line.strip())\n",
        "        dict[\"domain\"] = 1\n",
        "        data1.append(dict)\n",
        "# Assuming the NDJSON data is stored in a file called 'data.ndjson'\n",
        "with open(\"domain2_train.json\", 'r') as file:\n",
        "    for line in file:\n",
        "        dict = json.loads(line.strip())\n",
        "        dict[\"domain\"] = 2\n",
        "        data2.append(dict)\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "df3 = pd.DataFrame(data3)\n",
        "test = pd.DataFrame(test)\n",
        "\n",
        "\n",
        "y = pd.concat([df1['label'], df2['label']])\n",
        "\n",
        "# Convert sequences to BoW representation\n",
        "def sequences_to_bow(sequences, vocab_size):\n",
        "    matrix = np.zeros((len(sequences), vocab_size))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for token in sequence:\n",
        "            if token < vocab_size:\n",
        "                matrix[i][token] += 1\n",
        "    return matrix\n",
        "\n",
        "vocab_size = 5000  # as mentioned\n",
        "\n",
        "X = sequences_to_bow(df3['text'], vocab_size)\n",
        "X_pred = sequences_to_bow(test['text'], vocab_size)\n",
        "Xtrain,Ytrain = np.array(X),np.array(y)\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(Xtrain,Ytrain,test_size=0.25,stratify=Ytrain)\n"
      ],
      "metadata": {
        "id": "77ay5rL5kBE_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP baseline\n",
        "- bow\n",
        "- no sampling\n",
        "- no weight\n",
        "- test acc: 87%"
      ],
      "metadata": {
        "id": "yC4mHdjEkjg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(50,input_shape=(5000,),activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(X_train,Y_train,epochs=15,verbose=2)\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqrxH8CakLeJ",
        "outputId": "aeb9351f-fbe1-4e6f-9642-1e6b5c1aba5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 50)                250050    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               5100      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 150)               15150     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               30200     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 300701 (1.15 MB)\n",
            "Trainable params: 300701 (1.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "807/807 - 7s - loss: 0.3733 - accuracy: 0.8539 - 7s/epoch - 9ms/step\n",
            "Epoch 2/15\n",
            "807/807 - 6s - loss: 0.2521 - accuracy: 0.9061 - 6s/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "807/807 - 7s - loss: 0.2005 - accuracy: 0.9227 - 7s/epoch - 9ms/step\n",
            "Epoch 4/15\n",
            "807/807 - 6s - loss: 0.1695 - accuracy: 0.9306 - 6s/epoch - 7ms/step\n",
            "Epoch 5/15\n",
            "807/807 - 6s - loss: 0.1425 - accuracy: 0.9408 - 6s/epoch - 7ms/step\n",
            "Epoch 6/15\n",
            "807/807 - 6s - loss: 0.1218 - accuracy: 0.9501 - 6s/epoch - 8ms/step\n",
            "Epoch 7/15\n",
            "807/807 - 5s - loss: 0.0969 - accuracy: 0.9602 - 5s/epoch - 6ms/step\n",
            "Epoch 8/15\n",
            "807/807 - 7s - loss: 0.0789 - accuracy: 0.9710 - 7s/epoch - 9ms/step\n",
            "Epoch 9/15\n",
            "807/807 - 5s - loss: 0.0673 - accuracy: 0.9762 - 5s/epoch - 7ms/step\n",
            "Epoch 10/15\n",
            "807/807 - 7s - loss: 0.0559 - accuracy: 0.9806 - 7s/epoch - 9ms/step\n",
            "Epoch 11/15\n",
            "807/807 - 5s - loss: 0.0556 - accuracy: 0.9822 - 5s/epoch - 6ms/step\n",
            "Epoch 12/15\n",
            "807/807 - 7s - loss: 0.0466 - accuracy: 0.9845 - 7s/epoch - 8ms/step\n",
            "Epoch 13/15\n",
            "807/807 - 6s - loss: 0.0409 - accuracy: 0.9858 - 6s/epoch - 7ms/step\n",
            "Epoch 14/15\n",
            "807/807 - 6s - loss: 0.0408 - accuracy: 0.9875 - 6s/epoch - 8ms/step\n",
            "Epoch 15/15\n",
            "807/807 - 5s - loss: 0.0357 - accuracy: 0.9881 - 5s/epoch - 6ms/step\n",
            "269/269 [==============================] - 1s 4ms/step - loss: 0.7270 - accuracy: 0.8798\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7270073294639587, 0.8797674179077148]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimised MLP\n",
        "- parameter optimisation\n",
        "- acc 0.9009302258491516"
      ],
      "metadata": {
        "id": "VEQrEoBDl2qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Model\n",
        "optimized_model = Sequential()\n",
        "\n",
        "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "optimized_model.summary()\n",
        "optimized_model.fit(X_train, Y_train, epochs=50, verbose=2, validation_split=0.1, batch_size=32, callbacks=[early_stopping])\n",
        "optimized_model.evaluate(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNeOfpfl4ti",
        "outputId": "7781f55e-5d74-412a-c8eb-f863be92865f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 128)               640128    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 656769 (2.51 MB)\n",
            "Trainable params: 656769 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "726/726 - 9s - loss: 0.4926 - accuracy: 0.8609 - val_loss: 0.3855 - val_accuracy: 0.9008 - 9s/epoch - 12ms/step\n",
            "Epoch 2/50\n",
            "726/726 - 8s - loss: 0.3677 - accuracy: 0.9009 - val_loss: 0.3588 - val_accuracy: 0.9035 - 8s/epoch - 11ms/step\n",
            "Epoch 3/50\n",
            "726/726 - 9s - loss: 0.3412 - accuracy: 0.9062 - val_loss: 0.3629 - val_accuracy: 0.9023 - 9s/epoch - 12ms/step\n",
            "Epoch 4/50\n",
            "726/726 - 9s - loss: 0.3305 - accuracy: 0.9126 - val_loss: 0.3507 - val_accuracy: 0.9039 - 9s/epoch - 13ms/step\n",
            "Epoch 5/50\n",
            "726/726 - 9s - loss: 0.3199 - accuracy: 0.9152 - val_loss: 0.3609 - val_accuracy: 0.9062 - 9s/epoch - 12ms/step\n",
            "Epoch 6/50\n",
            "726/726 - 7s - loss: 0.3141 - accuracy: 0.9163 - val_loss: 0.3571 - val_accuracy: 0.9043 - 7s/epoch - 10ms/step\n",
            "Epoch 7/50\n",
            "726/726 - 13s - loss: 0.3141 - accuracy: 0.9172 - val_loss: 0.3566 - val_accuracy: 0.9062 - 13s/epoch - 18ms/step\n",
            "269/269 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.9009\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3545358180999756, 0.9009302258491516]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSYW8wRpy6UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimised MLP - imbalance handling\n",
        "- model-based\n",
        "- SMOTE\n"
      ],
      "metadata": {
        "id": "Wo0xgk0ul_4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[df1['label'] == 0, 'model'] = 7 # machine no.7\n",
        "df1.loc[df1['label'] == 1, 'model'] = 8 # human label as 8\n",
        "\n",
        "df2['model'] = df2['model'].fillna(9) # human label as 9\n",
        "df3 = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
        "df3['model'].describe()\n",
        " #0-7: machine; 8-9 human\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Split the dataset based on model values\n",
        "dfs = [df3[df3['model'] == i] for i in range(10)]  # 0-9 models\n"
      ],
      "metadata": {
        "id": "2lTNafV-ot5f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.groupby('model').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "uC5MPaZRo4k3",
        "outputId": "0376e4eb-3eaf-41d6-b7a7-40f983782779"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       text  label  domain\n",
              "model                     \n",
              "0.0    2364   2364    2364\n",
              "1.0    2357   2357    2357\n",
              "2.0    2339   2339    2339\n",
              "3.0    2358   2358    2358\n",
              "4.0     789    789     789\n",
              "5.0     780    780     780\n",
              "6.0    1763   1763    1763\n",
              "7.0    9750   9750    9750\n",
              "8.0    9750   9750    9750\n",
              "9.0    2150   2150    2150"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3b9dbce-5493-4524-8e92-3da92007d670\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>2364</td>\n",
              "      <td>2364</td>\n",
              "      <td>2364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2357</td>\n",
              "      <td>2357</td>\n",
              "      <td>2357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>2339</td>\n",
              "      <td>2339</td>\n",
              "      <td>2339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>2358</td>\n",
              "      <td>2358</td>\n",
              "      <td>2358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>789</td>\n",
              "      <td>789</td>\n",
              "      <td>789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>1763</td>\n",
              "      <td>1763</td>\n",
              "      <td>1763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>9750</td>\n",
              "      <td>9750</td>\n",
              "      <td>9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>9750</td>\n",
              "      <td>9750</td>\n",
              "      <td>9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>2150</td>\n",
              "      <td>2150</td>\n",
              "      <td>2150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3b9dbce-5493-4524-8e92-3da92007d670')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3b9dbce-5493-4524-8e92-3da92007d670 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3b9dbce-5493-4524-8e92-3da92007d670');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-978fa953-5383-4f41-988c-63cc6de435b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-978fa953-5383-4f41-988c-63cc6de435b3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-978fa953-5383-4f41-988c-63cc6de435b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model-based"
      ],
      "metadata": {
        "id": "FUOP2S4rp_Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target_samples = 1488\n",
        "\n",
        "# Resample machine labels 0-7\n",
        "for i in range(8):\n",
        "    if len(dfs[i]) > target_samples:\n",
        "        # Undersample if the count is greater than 1488\n",
        "        dfs[i] = resample(dfs[i], replace=False, n_samples=target_samples, random_state=42)\n",
        "    elif len(dfs[i]) < target_samples:\n",
        "        # Oversample if the count is less than 1488\n",
        "        dfs[i] = resample(dfs[i], replace=True, n_samples=target_samples, random_state=42)\n",
        "\n",
        "# Note: Not resampling human labels 8 and 9, as they are to be kept as they are\n",
        "\n",
        "# Concatenate results\n",
        "df_resampled1 = pd.concat(dfs)\n",
        "\n",
        "# Check the new distribution\n",
        "print(df_resampled1['model'].value_counts())\n",
        "#df_resampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QXJsx-8khn_",
        "outputId": "6d62becc-c444-4d82-8cc4-6e6565998edf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.0    9750\n",
            "9.0    2150\n",
            "0.0    1488\n",
            "1.0    1488\n",
            "2.0    1488\n",
            "3.0    1488\n",
            "4.0    1488\n",
            "5.0    1488\n",
            "6.0    1488\n",
            "7.0    1488\n",
            "Name: model, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = sequences_to_bow(df_resampled1['text'], vocab_size)\n",
        "y = df_resampled1['label'].values"
      ],
      "metadata": {
        "id": "xSpvFJ9Bvtkb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = sequences_to_bow(test['text'], 5000)\n",
        "Xtrain,Ytrain = np.array(X),np.array(y) # model\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(Xtrain,Ytrain,test_size=0.25,stratify=Ytrain)\n"
      ],
      "metadata": {
        "id": "re7SJ18ovzdX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Model\n",
        "optimized_model = Sequential()\n",
        "\n",
        "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "optimized_model.summary()\n",
        "optimized_model.fit(X_train, Y_train, epochs=50, verbose=2, validation_split=0.1, batch_size=32, callbacks=[early_stopping])\n",
        "optimized_model.evaluate(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW83CgwXv5by",
        "outputId": "63ee565f-4b6e-4731-da00-75b56bf4a903"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 128)               640128    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 656769 (2.51 MB)\n",
            "Trainable params: 656769 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "503/503 - 6s - loss: 0.5189 - accuracy: 0.8559 - val_loss: 0.4035 - val_accuracy: 0.8919 - 6s/epoch - 12ms/step\n",
            "Epoch 2/50\n",
            "503/503 - 6s - loss: 0.3705 - accuracy: 0.8924 - val_loss: 0.3662 - val_accuracy: 0.8959 - 6s/epoch - 11ms/step\n",
            "Epoch 3/50\n",
            "503/503 - 5s - loss: 0.3361 - accuracy: 0.9017 - val_loss: 0.3616 - val_accuracy: 0.8964 - 5s/epoch - 10ms/step\n",
            "Epoch 4/50\n",
            "503/503 - 6s - loss: 0.3226 - accuracy: 0.9036 - val_loss: 0.3435 - val_accuracy: 0.9026 - 6s/epoch - 11ms/step\n",
            "Epoch 5/50\n",
            "503/503 - 5s - loss: 0.3118 - accuracy: 0.9113 - val_loss: 0.3697 - val_accuracy: 0.8987 - 5s/epoch - 10ms/step\n",
            "Epoch 6/50\n",
            "503/503 - 5s - loss: 0.3046 - accuracy: 0.9139 - val_loss: 0.3643 - val_accuracy: 0.9037 - 5s/epoch - 11ms/step\n",
            "Epoch 7/50\n",
            "503/503 - 5s - loss: 0.2979 - accuracy: 0.9197 - val_loss: 0.3712 - val_accuracy: 0.8998 - 5s/epoch - 10ms/step\n",
            "186/186 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3600963056087494, 0.8924550414085388]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(50,input_shape=(5000,),activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = {0: 1., 1: 2.}\n",
        "model.fit(X, y, epochs=10, verbose=2, validation_split=0.1, batch_size=32, class_weight=class_weights)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcRSbovGwIDZ",
        "outputId": "85cb2f61-625a-4ebc-9af7-ed563f072201"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "670/670 - 6s - loss: 0.1500 - accuracy: 0.9655 - val_loss: 36.4075 - val_accuracy: 0.1000 - 6s/epoch - 10ms/step\n",
            "Epoch 2/10\n",
            "670/670 - 5s - loss: 0.0522 - accuracy: 0.9877 - val_loss: 40.5819 - val_accuracy: 0.1004 - 5s/epoch - 8ms/step\n",
            "Epoch 3/10\n",
            "670/670 - 5s - loss: 0.0254 - accuracy: 0.9937 - val_loss: 68.1191 - val_accuracy: 0.0995 - 5s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "670/670 - 5s - loss: 0.0204 - accuracy: 0.9957 - val_loss: 83.8880 - val_accuracy: 0.0987 - 5s/epoch - 7ms/step\n",
            "Epoch 5/10\n",
            "670/670 - 5s - loss: 0.0115 - accuracy: 0.9973 - val_loss: 82.4594 - val_accuracy: 0.0962 - 5s/epoch - 8ms/step\n",
            "Epoch 6/10\n",
            "670/670 - 5s - loss: 0.0090 - accuracy: 0.9980 - val_loss: 87.2169 - val_accuracy: 0.1008 - 5s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "670/670 - 5s - loss: 0.0063 - accuracy: 0.9986 - val_loss: 145.6340 - val_accuracy: 0.0958 - 5s/epoch - 8ms/step\n",
            "Epoch 8/10\n",
            "670/670 - 5s - loss: 0.0049 - accuracy: 0.9990 - val_loss: 143.8586 - val_accuracy: 0.0983 - 5s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "670/670 - 4s - loss: 0.0074 - accuracy: 0.9987 - val_loss: 95.6315 - val_accuracy: 0.1016 - 4s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "670/670 - 5s - loss: 0.0054 - accuracy: 0.9990 - val_loss: 153.2972 - val_accuracy: 0.1004 - 5s/epoch - 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x790297f1c100>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Predict on the new test data\n",
        "y_pred = model.predict(X_pred)\n",
        "y_class_pred = (y_pred > 0.5).astype(int)\n",
        "list(y_class_pred).count(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4TGwow9wXnJ",
        "outputId": "505560c8-1c80-4303-a261-ef45e8003dee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "286"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### smote\n",
        "- label-based(0/1): acc 0.91"
      ],
      "metadata": {
        "id": "MI6EvzXRqVZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "vocab_size = 5000\n",
        "\n",
        "def sequences_to_bow(sequences, vocab_size):\n",
        "    matrix = np.zeros((len(sequences), vocab_size))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for token in sequence:\n",
        "            if token < vocab_size:\n",
        "                matrix[i][token] += 1\n",
        "    return matrix\n",
        "\n",
        "X_vectorized = sequences_to_bow(df3['text'], vocab_size)\n",
        "y = df3['label'].values\n",
        "\n",
        "# Display distribution before SMOTE\n",
        "counter = Counter(y)\n",
        "print('Before', counter)\n",
        "\n",
        "# Apply SMOTE for balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_vectorized, y)\n",
        "\n",
        "# Display distribution after SMOTE\n",
        "counter = Counter(y_resampled_smote)\n",
        "print('After', counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zWo1QZklkLW",
        "outputId": "d133b4a7-58d6-4461-8b15-497621e7b83e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Counter({0: 22500, 1: 11900})\n",
            "After Counter({1: 22500, 0: 22500})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = sequences_to_bow(test['text'], 5000)\n",
        "Xtrain,Ytrain = np.array(X_resampled_smote),np.array(y_resampled_smote) # smote\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(Xtrain,Ytrain,test_size=0.25,stratify=Ytrain)\n"
      ],
      "metadata": {
        "id": "lbNg_gznpJ0g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Model\n",
        "optimized_model = Sequential()\n",
        "\n",
        "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "optimized_model.summary()\n",
        "optimized_model.fit(X_train, Y_train, epochs=50, verbose=2, validation_split=0.1, batch_size=32, callbacks=[early_stopping])\n",
        "optimized_model.evaluate(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy18Rg2SoQNK",
        "outputId": "6308dcb6-68af-4a0f-f59a-3a2c549afb09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               640128    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 656769 (2.51 MB)\n",
            "Trainable params: 656769 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "950/950 - 12s - loss: 0.4691 - accuracy: 0.8568 - val_loss: 0.3776 - val_accuracy: 0.8844 - 12s/epoch - 13ms/step\n",
            "Epoch 2/50\n",
            "950/950 - 10s - loss: 0.3661 - accuracy: 0.8895 - val_loss: 0.3689 - val_accuracy: 0.8957 - 10s/epoch - 11ms/step\n",
            "Epoch 3/50\n",
            "950/950 - 10s - loss: 0.3464 - accuracy: 0.8991 - val_loss: 0.3648 - val_accuracy: 0.8945 - 10s/epoch - 11ms/step\n",
            "Epoch 4/50\n",
            "950/950 - 10s - loss: 0.3333 - accuracy: 0.9093 - val_loss: 0.3576 - val_accuracy: 0.9037 - 10s/epoch - 11ms/step\n",
            "Epoch 5/50\n",
            "950/950 - 10s - loss: 0.3301 - accuracy: 0.9123 - val_loss: 0.3529 - val_accuracy: 0.9031 - 10s/epoch - 11ms/step\n",
            "Epoch 6/50\n",
            "950/950 - 9s - loss: 0.3186 - accuracy: 0.9204 - val_loss: 0.3612 - val_accuracy: 0.9064 - 9s/epoch - 9ms/step\n",
            "Epoch 7/50\n",
            "950/950 - 10s - loss: 0.3119 - accuracy: 0.9245 - val_loss: 0.3684 - val_accuracy: 0.8987 - 10s/epoch - 10ms/step\n",
            "Epoch 8/50\n",
            "950/950 - 10s - loss: 0.3048 - accuracy: 0.9277 - val_loss: 0.3517 - val_accuracy: 0.9099 - 10s/epoch - 11ms/step\n",
            "Epoch 9/50\n",
            "950/950 - 10s - loss: 0.3007 - accuracy: 0.9297 - val_loss: 0.3555 - val_accuracy: 0.9120 - 10s/epoch - 10ms/step\n",
            "Epoch 10/50\n",
            "950/950 - 9s - loss: 0.2962 - accuracy: 0.9333 - val_loss: 0.3590 - val_accuracy: 0.9111 - 9s/epoch - 10ms/step\n",
            "Epoch 11/50\n",
            "950/950 - 10s - loss: 0.2945 - accuracy: 0.9345 - val_loss: 0.3782 - val_accuracy: 0.9084 - 10s/epoch - 10ms/step\n",
            "352/352 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.9148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.336286723613739, 0.9148444533348083]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model\n",
        "optimized_model = Sequential()\n",
        "\n",
        "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "optimized_model.summary()\n",
        "optimized_model.fit(Xtrain, Ytrain, epochs=10, verbose=2, validation_split=0.1, batch_size=32,class_weight=class_weights)\n",
        "#optimized_model.evaluate(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3v9CE0cs3CF",
        "outputId": "e2622e0f-115c-4921-9040-02a1b33c7b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 128)               640128    \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 656769 (2.51 MB)\n",
            "Trainable params: 656769 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Predict on the new test data\n",
        "y_pred = optimized_model.predict(X_pred)\n",
        "y_class_pred = (y_pred > 0.5).astype(int)\n",
        "list(y_class_pred).count(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFjZiZ8xuxah",
        "outputId": "76cfc61b-2d00-498a-e1df-7e30a7ea6b77"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADASYN"
      ],
      "metadata": {
        "id": "rzZL5yeZyMQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from imblearn.over_sampling import ADASYN  # Import ADASYN\n",
        "from collections import Counter\n",
        "\n",
        "vocab_size = 5000\n",
        "\n",
        "def sequences_to_bow(sequences, vocab_size):\n",
        "    matrix = np.zeros((len(sequences), vocab_size))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for token in sequence:\n",
        "            if token < vocab_size:\n",
        "                matrix[i][token] += 1\n",
        "    return matrix\n",
        "\n",
        "X_vectorized = sequences_to_bow(df3['text'], vocab_size)\n",
        "y = df3['label'].values\n",
        "\n",
        "# Display distribution before ADASYN\n",
        "counter = Counter(y)\n",
        "print('Before', counter)\n",
        "\n",
        "# Apply ADASYN for balancing\n",
        "adasyn = ADASYN(random_state=42)  # Create an ADASYN instance\n",
        "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_vectorized, y)  # Use ADASYN for resampling\n",
        "\n",
        "# Display distribution after ADASYN\n",
        "counter = Counter(y_resampled_adasyn)\n",
        "print('After', counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfQ3FZTmu_dn",
        "outputId": "0d149b48-9990-4112-c3be-a7be550078ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Counter({0: 22500, 1: 11900})\n",
            "After Counter({0: 22500, 1: 20802})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model\n",
        "optimized_model = Sequential()\n",
        "\n",
        "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "optimized_model.summary()\n",
        "class_weights = {0: 1., 1: 2.}\n",
        "optimized_model.fit(X_resampled_adasyn, y_resampled_adasyn, epochs=10, verbose=2, validation_split=0.1, batch_size=32,class_weight=class_weights)\n",
        "#optimized_model.evaluate(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1YVxm6qvBWb",
        "outputId": "2814262d-15e9-49c4-936e-e89b371547a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               640128    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 656769 (2.51 MB)\n",
            "Trainable params: 656769 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1218/1218 - 15s - loss: 0.5870 - accuracy: 0.8716 - val_loss: 1.0285 - val_accuracy: 0.2697 - 15s/epoch - 12ms/step\n",
            "Epoch 2/10\n",
            "1218/1218 - 13s - loss: 0.4559 - accuracy: 0.9062 - val_loss: 1.1195 - val_accuracy: 0.2318 - 13s/epoch - 10ms/step\n",
            "Epoch 3/10\n",
            "1218/1218 - 13s - loss: 0.4351 - accuracy: 0.9110 - val_loss: 0.8339 - val_accuracy: 0.5419 - 13s/epoch - 10ms/step\n",
            "Epoch 4/10\n",
            "1218/1218 - 13s - loss: 0.4224 - accuracy: 0.9133 - val_loss: 0.8997 - val_accuracy: 0.4207 - 13s/epoch - 10ms/step\n",
            "Epoch 5/10\n",
            "1218/1218 - 13s - loss: 0.4195 - accuracy: 0.9139 - val_loss: 0.9887 - val_accuracy: 0.2796 - 13s/epoch - 11ms/step\n",
            "Epoch 6/10\n",
            "1218/1218 - 13s - loss: 0.4064 - accuracy: 0.9188 - val_loss: 1.0043 - val_accuracy: 0.2794 - 13s/epoch - 10ms/step\n",
            "Epoch 7/10\n",
            "1218/1218 - 13s - loss: 0.4055 - accuracy: 0.9189 - val_loss: 1.0474 - val_accuracy: 0.2235 - 13s/epoch - 10ms/step\n",
            "Epoch 8/10\n",
            "1218/1218 - 13s - loss: 0.3931 - accuracy: 0.9205 - val_loss: 0.8441 - val_accuracy: 0.4957 - 13s/epoch - 11ms/step\n",
            "Epoch 9/10\n",
            "1218/1218 - 13s - loss: 0.3854 - accuracy: 0.9216 - val_loss: 0.8263 - val_accuracy: 0.4775 - 13s/epoch - 10ms/step\n",
            "Epoch 10/10\n",
            "1218/1218 - 13s - loss: 0.3873 - accuracy: 0.9221 - val_loss: 0.7646 - val_accuracy: 0.4602 - 13s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7949f064f7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Predict on the new test data\n",
        "y_pred = optimized_model.predict(X_pred)\n",
        "y_class_pred = (y_pred > 0.375).astype(int)\n",
        "list(y_class_pred).count(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Vsb-NovMqD",
        "outputId": "d789b9cb-7f23-408c-f68a-3d957322052f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['class'] = y_class_pred\n",
        "test[['id', 'class']].to_csv('smote_mlp5.csv', index= False) #83.2% on kaggle"
      ],
      "metadata": {
        "id": "SXZVE29A0-hS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[['id', 'class']].to_csv('smote_mlp5.csv', index= False) #83.2% on kaggle"
      ],
      "metadata": {
        "id": "GVrE1oFz1FIv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[['id', 'class']].to_csv('smote_mlp6.csv', index= False) #85% on kaggle"
      ],
      "metadata": {
        "id": "oprYQCTs9Ird"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data augmentation\n",
        "suggested to be used before imbalance handling (if we are using ADASYN)"
      ],
      "metadata": {
        "id": "hucWBqUK8pPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_insertion(sequence, n):\n",
        "    for _ in range(n):\n",
        "        add_random_token(sequence)\n",
        "    return sequence\n",
        "\n",
        "def random_deletion(sequence, p):\n",
        "    if len(sequence) == 1:\n",
        "        return sequence\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p, sequence))\n",
        "    if len(remaining) == 0:\n",
        "        return [random.choice(sequence)]\n",
        "    return remaining\n",
        "\n",
        "def random_swap(sequence, n):\n",
        "    length = len(sequence)\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.randint(0, length-1), random.randint(0, length-1)\n",
        "        sequence[idx1], sequence[idx2] = sequence[idx2], sequence[idx1]\n",
        "    return sequence\n",
        "\n",
        "def add_random_token(sequence):\n",
        "    if len(sequence) == 0 or max(sequence) == 0:\n",
        "        # Either add a default token or skip this sequence.\n",
        "        sequence.append(1)\n",
        "        return\n",
        "    position = random.randint(0, len(sequence)-1)\n",
        "    random_token = random.randint(1, max(sequence))\n",
        "    sequence.insert(position, random_token)\n"
      ],
      "metadata": {
        "id": "FjJE7_wt8tQ6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from collections import Counter\n",
        "batch_size = 5000  # you can adjust this based on your memory capacity\n",
        "\n",
        "# Shuffle data\n",
        "df3 = shuffle(df3)\n",
        "\n",
        "num_batches = int(len(df3) / batch_size) + (1 if len(df3) % batch_size != 0 else 0)\n",
        "\n",
        "for batch in range(num_batches):\n",
        "    start_idx = batch * batch_size\n",
        "    end_idx = min((batch + 1) * batch_size, len(df3))\n",
        "\n",
        "    batch_data = df3.iloc[start_idx:end_idx]\n",
        "\n",
        "    augmented_data = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for text, label in zip(batch_data['text'].values, batch_data['label'].values):\n",
        "        # Original data\n",
        "        augmented_data.append(text)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # Augment data\n",
        "        augmented_sequence = random_insertion(list(text), 1)\n",
        "        augmented_sequence = random_deletion(augmented_sequence, 0.1)\n",
        "        augmented_sequence = random_swap(augmented_sequence, 2)\n",
        "\n",
        "        augmented_data.append(augmented_sequence)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "    augmented_data = np.array(augmented_data, dtype=object)\n",
        "    augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "    # Convert augmented data to bag-of-words representation\n",
        "    X_vectorized = sequences_to_bow(augmented_data, vocab_size)\n",
        "    y = np.array(augmented_labels)\n",
        "\n",
        "    # Display distribution before ADASYN\n",
        "    counter = Counter(y)\n",
        "    print(f'Batch {batch + 1} - Before', counter)\n",
        "\n",
        "    # Apply ADASYN for balancing\n",
        "    adasyn = ADASYN(random_state=42)\n",
        "    X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_vectorized, y)\n",
        "\n",
        "    # Display distribution after ADASYN\n",
        "    counter = Counter(y_resampled_adasyn)\n",
        "    print(f'Batch {batch + 1} - After', counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZHKjfYoC4Cx",
        "outputId": "3166a58e-2060-4391-b1de-fa61b253a9f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 - Before Counter({0: 6450, 1: 3550})\n",
            "Batch 1 - After Counter({1: 6824, 0: 6450})\n",
            "Batch 2 - Before Counter({0: 6464, 1: 3536})\n",
            "Batch 2 - After Counter({1: 6493, 0: 6464})\n",
            "Batch 3 - Before Counter({0: 6628, 1: 3372})\n",
            "Batch 3 - After Counter({1: 6780, 0: 6628})\n",
            "Batch 4 - Before Counter({0: 6574, 1: 3426})\n",
            "Batch 4 - After Counter({1: 6670, 0: 6574})\n",
            "Batch 5 - Before Counter({0: 6520, 1: 3480})\n",
            "Batch 5 - After Counter({1: 6686, 0: 6520})\n",
            "Batch 6 - Before Counter({0: 6616, 1: 3384})\n",
            "Batch 6 - After Counter({1: 6858, 0: 6616})\n",
            "Batch 7 - Before Counter({0: 5748, 1: 3052})\n",
            "Batch 7 - After Counter({1: 6138, 0: 5748})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from collections import Counter\n",
        "batch_size = 5000  # you can adjust this based on your memory capacity\n",
        "\n",
        "# Shuffle data\n",
        "df3 = shuffle(df3)\n",
        "\n",
        "num_batches = int(len(df3) / batch_size) + (1 if len(df3) % batch_size != 0 else 0)\n",
        "\n",
        "all_X_resampled = []\n",
        "all_y_resampled = []\n",
        "\n",
        "for batch in range(num_batches):\n",
        "    start_idx = batch * batch_size\n",
        "    end_idx = min((batch + 1) * batch_size, len(df3))\n",
        "\n",
        "    batch_data = df3.iloc[start_idx:end_idx]\n",
        "\n",
        "    augmented_data = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for text, label in zip(batch_data['text'].values, batch_data['label'].values):\n",
        "        # Original data\n",
        "        augmented_data.append(text)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # Augment data\n",
        "        augmented_sequence = random_insertion(list(text), 1)\n",
        "        augmented_sequence = random_deletion(augmented_sequence, 0.1)\n",
        "        augmented_sequence = random_swap(augmented_sequence, 2)\n",
        "\n",
        "        augmented_data.append(augmented_sequence)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "    augmented_data = np.array(augmented_data, dtype=object)\n",
        "    augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "    # Convert augmented data to bag-of-words representation\n",
        "    X_vectorized = sequences_to_bow(augmented_data, vocab_size)\n",
        "    y = np.array(augmented_labels)\n",
        "\n",
        "    # Apply ADASYN for balancing\n",
        "    adasyn = ADASYN(random_state=42)\n",
        "    X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_vectorized, y)\n",
        "\n",
        "    all_X_resampled.append(X_resampled_adasyn)\n",
        "    all_y_resampled.append(y_resampled_adasyn)\n",
        "\n",
        "# Combine data from all batches\n",
        "all_X_resampled = np.vstack(all_X_resampled)\n",
        "all_y_resampled = np.hstack(all_y_resampled)\n",
        "\n",
        "# Display distribution of combined data\n",
        "counter = Counter(all_y_resampled)\n",
        "print('Overall After Resampling', counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbEm0c4mOYcC",
        "outputId": "0090a391-33f4-42f6-c9d0-035c570a9340"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall After Resampling Counter({1: 45690, 0: 45000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(all_y_resampled).count(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2TMXz1qQ1Dw",
        "outputId": "259bae1e-9b0b-4a53-bb16-2445fe8354fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44613"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('all_X_resampled.npy', all_X_resampled)\n",
        "np.save('all_y_resampled.npy', all_y_resampled)\n"
      ],
      "metadata": {
        "id": "jObBRbGiRRj1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_X_resampled = np.load('all_X_resampled.npy')\n",
        "all_y_resampled = np.load('all_y_resampled.npy')\n",
        "\n"
      ],
      "metadata": {
        "id": "OgPxlpIqRcVO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "optimized_model = Sequential()\n",
        "\n",
        "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "optimized_model.add(Dropout(0.3))\n",
        "\n",
        "optimized_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "optimized_model.summary()\n",
        "class_weights = {0: 1., 1: 2.}\n",
        "optimized_model.fit(all_X_resampled, all_y_resampled, epochs=10, verbose=2, validation_split=0.1, batch_size=32,class_weight=class_weights)\n",
        "#optimized_model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOFPBmt3EKWJ",
        "outputId": "a8b54d07-5561-4dda-f654-7438422b595e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               640128    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 656769 (2.51 MB)\n",
            "Trainable params: 656769 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2551/2551 - 30s - loss: 0.6060 - accuracy: 0.8416 - val_loss: 0.4949 - val_accuracy: 0.8549 - 30s/epoch - 12ms/step\n",
            "Epoch 2/10\n",
            "2551/2551 - 29s - loss: 0.5065 - accuracy: 0.8942 - val_loss: 0.5521 - val_accuracy: 0.8506 - 29s/epoch - 11ms/step\n",
            "Epoch 3/10\n",
            "2551/2551 - 27s - loss: 0.4759 - accuracy: 0.9119 - val_loss: 0.5528 - val_accuracy: 0.8472 - 27s/epoch - 11ms/step\n",
            "Epoch 4/10\n",
            "2551/2551 - 27s - loss: 0.4555 - accuracy: 0.9206 - val_loss: 0.5625 - val_accuracy: 0.8596 - 27s/epoch - 11ms/step\n",
            "Epoch 5/10\n",
            "2551/2551 - 26s - loss: 0.4431 - accuracy: 0.9259 - val_loss: 0.5840 - val_accuracy: 0.8619 - 26s/epoch - 10ms/step\n",
            "Epoch 6/10\n",
            "2551/2551 - 29s - loss: 0.4362 - accuracy: 0.9292 - val_loss: 0.6242 - val_accuracy: 0.8495 - 29s/epoch - 11ms/step\n",
            "Epoch 7/10\n",
            "2551/2551 - 32s - loss: 0.4317 - accuracy: 0.9302 - val_loss: 0.5891 - val_accuracy: 0.8575 - 32s/epoch - 13ms/step\n",
            "Epoch 8/10\n",
            "2551/2551 - 26s - loss: 0.4261 - accuracy: 0.9317 - val_loss: 0.5602 - val_accuracy: 0.8648 - 26s/epoch - 10ms/step\n",
            "Epoch 9/10\n",
            "2551/2551 - 28s - loss: 0.4222 - accuracy: 0.9322 - val_loss: 0.5521 - val_accuracy: 0.8574 - 28s/epoch - 11ms/step\n",
            "Epoch 10/10\n",
            "2551/2551 - 36s - loss: 0.4173 - accuracy: 0.9331 - val_loss: 0.5828 - val_accuracy: 0.8563 - 36s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fcaa1c95f60>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = sequences_to_bow(test['text'], 5000)\n",
        "\n",
        "y_pred = optimized_model.predict(X_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUOVdydRPfoQ",
        "outputId": "f6514249-7f45-44f0-8089-9e16bdc259d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_class_pred = (y_pred > 0.3).astype(int)\n",
        "list(y_class_pred).count(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CXQAy6bTDOX",
        "outputId": "812c2735-e89e-452c-c823-0ab95b797fa3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "450"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['class'] = y_class_pred\n",
        "test[['id', 'class']].to_csv('smote_mlp8.csv', index= False) #"
      ],
      "metadata": {
        "id": "7cGvrlmMUA2j"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}
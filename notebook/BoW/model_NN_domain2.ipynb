{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN\n",
    "## domain 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "label = []\n",
    "\n",
    "with open(\"../../data/domain2_train.json\") as f:\n",
    "    for line in f:\n",
    "        # read line by line\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # add values\n",
    "        text.append(data[\"text\"])\n",
    "        label.append(data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'0': 0, '1': 1, '2': 1112, '3': 2223, '4': 3334, '5': 4445, '6': 4556, '7': 4667, '8': 4778, '9': 4889, '10': 2, '11': 113, '12': 224, '13': 335, '14': 446, '15': 557, '16': 668, '17': 779, '18': 890, '19': 1001, '20': 1113, '21': 1224, '22': 1335, '23': 1446, '24': 1557, '25': 1668, '26': 1779, '27': 1890, '28': 2001, '29': 2112, '30': 2224, '31': 2335, '32': 2446, '33': 2557, '34': 2668, '35': 2779, '36': 2890, '37': 3001, '38': 3112, '39': 3223, '40': 3335, '41': 3446, '42': 3557, '43': 3668, '44': 3779, '45': 3890, '46': 4001, '47': 4112, '48': 4223, '49': 4334, '50': 4446, '51': 4457, '52': 4468, '53': 4479, '54': 4490, '55': 4501, '56': 4512, '57': 4523, '58': 4534, '59': 4545, '60': 4557, '61': 4568, '62': 4579, '63': 4590, '64': 4601, '65': 4612, '66': 4623, '67': 4634, '68': 4645, '69': 4656, '70': 4668, '71': 4679, '72': 4690, '73': 4701, '74': 4712, '75': 4723, '76': 4734, '77': 4745, '78': 4756, '79': 4767, '80': 4779, '81': 4790, '82': 4801, '83': 4812, '84': 4823, '85': 4834, '86': 4845, '87': 4856, '88': 4867, '89': 4878, '90': 4890, '91': 4901, '92': 4912, '93': 4923, '94': 4934, '95': 4945, '96': 4956, '97': 4967, '98': 4978, '99': 4989, '100': 3, '101': 14, '102': 25, '103': 36, '104': 47, '105': 58, '106': 69, '107': 80, '108': 91, '109': 102, '110': 114, '111': 125, '112': 136, '113': 147, '114': 158, '115': 169, '116': 180, '117': 191, '118': 202, '119': 213, '120': 225, '121': 236, '122': 247, '123': 258, '124': 269, '125': 280, '126': 291, '127': 302, '128': 313, '129': 324, '130': 336, '131': 347, '132': 358, '133': 369, '134': 380, '135': 391, '136': 402, '137': 413, '138': 424, '139': 435, '140': 447, '141': 458, '142': 469, '143': 480, '144': 491, '145': 502, '146': 513, '147': 524, '148': 535, '149': 546, '150': 558, '151': 569, '152': 580, '153': 591, '154': 602, '155': 613, '156': 624, '157': 635, '158': 646, '159': 657, '160': 669, '161': 680, '162': 691, '163': 702, '164': 713, '165': 724, '166': 735, '167': 746, '168': 757, '169': 768, '170': 780, '171': 791, '172': 802, '173': 813, '174': 824, '175': 835, '176': 846, '177': 857, '178': 868, '179': 879, '180': 891, '181': 902, '182': 913, '183': 924, '184': 935, '185': 946, '186': 957, '187': 968, '188': 979, '189': 990, '190': 1002, '191': 1013, '192': 1024, '193': 1035, '194': 1046, '195': 1057, '196': 1068, '197': 1079, '198': 1090, '199': 1101, '200': 1114, '201': 1125, '202': 1136, '203': 1147, '204': 1158, '205': 1169, '206': 1180, '207': 1191, '208': 1202, '209': 1213, '210': 1225, '211': 1236, '212': 1247, '213': 1258, '214': 1269, '215': 1280, '216': 1291, '217': 1302, '218': 1313, '219': 1324, '220': 1336, '221': 1347, '222': 1358, '223': 1369, '224': 1380, '225': 1391, '226': 1402, '227': 1413, '228': 1424, '229': 1435, '230': 1447, '231': 1458, '232': 1469, '233': 1480, '234': 1491, '235': 1502, '236': 1513, '237': 1524, '238': 1535, '239': 1546, '240': 1558, '241': 1569, '242': 1580, '243': 1591, '244': 1602, '245': 1613, '246': 1624, '247': 1635, '248': 1646, '249': 1657, '250': 1669, '251': 1680, '252': 1691, '253': 1702, '254': 1713, '255': 1724, '256': 1735, '257': 1746, '258': 1757, '259': 1768, '260': 1780, '261': 1791, '262': 1802, '263': 1813, '264': 1824, '265': 1835, '266': 1846, '267': 1857, '268': 1868, '269': 1879, '270': 1891, '271': 1902, '272': 1913, '273': 1924, '274': 1935, '275': 1946, '276': 1957, '277': 1968, '278': 1979, '279': 1990, '280': 2002, '281': 2013, '282': 2024, '283': 2035, '284': 2046, '285': 2057, '286': 2068, '287': 2079, '288': 2090, '289': 2101, '290': 2113, '291': 2124, '292': 2135, '293': 2146, '294': 2157, '295': 2168, '296': 2179, '297': 2190, '298': 2201, '299': 2212, '300': 2225, '301': 2236, '302': 2247, '303': 2258, '304': 2269, '305': 2280, '306': 2291, '307': 2302, '308': 2313, '309': 2324, '310': 2336, '311': 2347, '312': 2358, '313': 2369, '314': 2380, '315': 2391, '316': 2402, '317': 2413, '318': 2424, '319': 2435, '320': 2447, '321': 2458, '322': 2469, '323': 2480, '324': 2491, '325': 2502, '326': 2513, '327': 2524, '328': 2535, '329': 2546, '330': 2558, '331': 2569, '332': 2580, '333': 2591, '334': 2602, '335': 2613, '336': 2624, '337': 2635, '338': 2646, '339': 2657, '340': 2669, '341': 2680, '342': 2691, '343': 2702, '344': 2713, '345': 2724, '346': 2735, '347': 2746, '348': 2757, '349': 2768, '350': 2780, '351': 2791, '352': 2802, '353': 2813, '354': 2824, '355': 2835, '356': 2846, '357': 2857, '358': 2868, '359': 2879, '360': 2891, '361': 2902, '362': 2913, '363': 2924, '364': 2935, '365': 2946, '366': 2957, '367': 2968, '368': 2979, '369': 2990, '370': 3002, '371': 3013, '372': 3024, '373': 3035, '374': 3046, '375': 3057, '376': 3068, '377': 3079, '378': 3090, '379': 3101, '380': 3113, '381': 3124, '382': 3135, '383': 3146, '384': 3157, '385': 3168, '386': 3179, '387': 3190, '388': 3201, '389': 3212, '390': 3224, '391': 3235, '392': 3246, '393': 3257, '394': 3268, '395': 3279, '396': 3290, '397': 3301, '398': 3312, '399': 3323, '400': 3336, '401': 3347, '402': 3358, '403': 3369, '404': 3380, '405': 3391, '406': 3402, '407': 3413, '408': 3424, '409': 3435, '410': 3447, '411': 3458, '412': 3469, '413': 3480, '414': 3491, '415': 3502, '416': 3513, '417': 3524, '418': 3535, '419': 3546, '420': 3558, '421': 3569, '422': 3580, '423': 3591, '424': 3602, '425': 3613, '426': 3624, '427': 3635, '428': 3646, '429': 3657, '430': 3669, '431': 3680, '432': 3691, '433': 3702, '434': 3713, '435': 3724, '436': 3735, '437': 3746, '438': 3757, '439': 3768, '440': 3780, '441': 3791, '442': 3802, '443': 3813, '444': 3824, '445': 3835, '446': 3846, '447': 3857, '448': 3868, '449': 3879, '450': 3891, '451': 3902, '452': 3913, '453': 3924, '454': 3935, '455': 3946, '456': 3957, '457': 3968, '458': 3979, '459': 3990, '460': 4002, '461': 4013, '462': 4024, '463': 4035, '464': 4046, '465': 4057, '466': 4068, '467': 4079, '468': 4090, '469': 4101, '470': 4113, '471': 4124, '472': 4135, '473': 4146, '474': 4157, '475': 4168, '476': 4179, '477': 4190, '478': 4201, '479': 4212, '480': 4224, '481': 4235, '482': 4246, '483': 4257, '484': 4268, '485': 4279, '486': 4290, '487': 4301, '488': 4312, '489': 4323, '490': 4335, '491': 4346, '492': 4357, '493': 4368, '494': 4379, '495': 4390, '496': 4401, '497': 4412, '498': 4423, '499': 4434, '500': 4447, '501': 4448, '502': 4449, '503': 4450, '504': 4451, '505': 4452, '506': 4453, '507': 4454, '508': 4455, '509': 4456, '510': 4458, '511': 4459, '512': 4460, '513': 4461, '514': 4462, '515': 4463, '516': 4464, '517': 4465, '518': 4466, '519': 4467, '520': 4469, '521': 4470, '522': 4471, '523': 4472, '524': 4473, '525': 4474, '526': 4475, '527': 4476, '528': 4477, '529': 4478, '530': 4480, '531': 4481, '532': 4482, '533': 4483, '534': 4484, '535': 4485, '536': 4486, '537': 4487, '538': 4488, '539': 4489, '540': 4491, '541': 4492, '542': 4493, '543': 4494, '544': 4495, '545': 4496, '546': 4497, '547': 4498, '548': 4499, '549': 4500, '550': 4502, '551': 4503, '552': 4504, '553': 4505, '554': 4506, '555': 4507, '556': 4508, '557': 4509, '558': 4510, '559': 4511, '560': 4513, '561': 4514, '562': 4515, '563': 4516, '564': 4517, '565': 4518, '566': 4519, '567': 4520, '568': 4521, '569': 4522, '570': 4524, '571': 4525, '572': 4526, '573': 4527, '574': 4528, '575': 4529, '576': 4530, '577': 4531, '578': 4532, '579': 4533, '580': 4535, '581': 4536, '582': 4537, '583': 4538, '584': 4539, '585': 4540, '586': 4541, '587': 4542, '588': 4543, '589': 4544, '590': 4546, '591': 4547, '592': 4548, '593': 4549, '594': 4550, '595': 4551, '596': 4552, '597': 4553, '598': 4554, '599': 4555, '600': 4558, '601': 4559, '602': 4560, '603': 4561, '604': 4562, '605': 4563, '606': 4564, '607': 4565, '608': 4566, '609': 4567, '610': 4569, '611': 4570, '612': 4571, '613': 4572, '614': 4573, '615': 4574, '616': 4575, '617': 4576, '618': 4577, '619': 4578, '620': 4580, '621': 4581, '622': 4582, '623': 4583, '624': 4584, '625': 4585, '626': 4586, '627': 4587, '628': 4588, '629': 4589, '630': 4591, '631': 4592, '632': 4593, '633': 4594, '634': 4595, '635': 4596, '636': 4597, '637': 4598, '638': 4599, '639': 4600, '640': 4602, '641': 4603, '642': 4604, '643': 4605, '644': 4606, '645': 4607, '646': 4608, '647': 4609, '648': 4610, '649': 4611, '650': 4613, '651': 4614, '652': 4615, '653': 4616, '654': 4617, '655': 4618, '656': 4619, '657': 4620, '658': 4621, '659': 4622, '660': 4624, '661': 4625, '662': 4626, '663': 4627, '664': 4628, '665': 4629, '666': 4630, '667': 4631, '668': 4632, '669': 4633, '670': 4635, '671': 4636, '672': 4637, '673': 4638, '674': 4639, '675': 4640, '676': 4641, '677': 4642, '678': 4643, '679': 4644, '680': 4646, '681': 4647, '682': 4648, '683': 4649, '684': 4650, '685': 4651, '686': 4652, '687': 4653, '688': 4654, '689': 4655, '690': 4657, '691': 4658, '692': 4659, '693': 4660, '694': 4661, '695': 4662, '696': 4663, '697': 4664, '698': 4665, '699': 4666, '700': 4669, '701': 4670, '702': 4671, '703': 4672, '704': 4673, '705': 4674, '706': 4675, '707': 4676, '708': 4677, '709': 4678, '710': 4680, '711': 4681, '712': 4682, '713': 4683, '714': 4684, '715': 4685, '716': 4686, '717': 4687, '718': 4688, '719': 4689, '720': 4691, '721': 4692, '722': 4693, '723': 4694, '724': 4695, '725': 4696, '726': 4697, '727': 4698, '728': 4699, '729': 4700, '730': 4702, '731': 4703, '732': 4704, '733': 4705, '734': 4706, '735': 4707, '736': 4708, '737': 4709, '738': 4710, '739': 4711, '740': 4713, '741': 4714, '742': 4715, '743': 4716, '744': 4717, '745': 4718, '746': 4719, '747': 4720, '748': 4721, '749': 4722, '750': 4724, '751': 4725, '752': 4726, '753': 4727, '754': 4728, '755': 4729, '756': 4730, '757': 4731, '758': 4732, '759': 4733, '760': 4735, '761': 4736, '762': 4737, '763': 4738, '764': 4739, '765': 4740, '766': 4741, '767': 4742, '768': 4743, '769': 4744, '770': 4746, '771': 4747, '772': 4748, '773': 4749, '774': 4750, '775': 4751, '776': 4752, '777': 4753, '778': 4754, '779': 4755, '780': 4757, '781': 4758, '782': 4759, '783': 4760, '784': 4761, '785': 4762, '786': 4763, '787': 4764, '788': 4765, '789': 4766, '790': 4768, '791': 4769, '792': 4770, '793': 4771, '794': 4772, '795': 4773, '796': 4774, '797': 4775, '798': 4776, '799': 4777, '800': 4780, '801': 4781, '802': 4782, '803': 4783, '804': 4784, '805': 4785, '806': 4786, '807': 4787, '808': 4788, '809': 4789, '810': 4791, '811': 4792, '812': 4793, '813': 4794, '814': 4795, '815': 4796, '816': 4797, '817': 4798, '818': 4799, '819': 4800, '820': 4802, '821': 4803, '822': 4804, '823': 4805, '824': 4806, '825': 4807, '826': 4808, '827': 4809, '828': 4810, '829': 4811, '830': 4813, '831': 4814, '832': 4815, '833': 4816, '834': 4817, '835': 4818, '836': 4819, '837': 4820, '838': 4821, '839': 4822, '840': 4824, '841': 4825, '842': 4826, '843': 4827, '844': 4828, '845': 4829, '846': 4830, '847': 4831, '848': 4832, '849': 4833, '850': 4835, '851': 4836, '852': 4837, '853': 4838, '854': 4839, '855': 4840, '856': 4841, '857': 4842, '858': 4843, '859': 4844, '860': 4846, '861': 4847, '862': 4848, '863': 4849, '864': 4850, '865': 4851, '866': 4852, '867': 4853, '868': 4854, '869': 4855, '870': 4857, '871': 4858, '872': 4859, '873': 4860, '874': 4861, '875': 4862, '876': 4863, '877': 4864, '878': 4865, '879': 4866, '880': 4868, '881': 4869, '882': 4870, '883': 4871, '884': 4872, '885': 4873, '886': 4874, '887': 4875, '888': 4876, '889': 4877, '890': 4879, '891': 4880, '892': 4881, '893': 4882, '894': 4883, '895': 4884, '896': 4885, '897': 4886, '898': 4887, '899': 4888, '900': 4891, '901': 4892, '902': 4893, '903': 4894, '904': 4895, '905': 4896, '906': 4897, '907': 4898, '908': 4899, '909': 4900, '910': 4902, '911': 4903, '912': 4904, '913': 4905, '914': 4906, '915': 4907, '916': 4908, '917': 4909, '918': 4910, '919': 4911, '920': 4913, '921': 4914, '922': 4915, '923': 4916, '924': 4917, '925': 4918, '926': 4919, '927': 4920, '928': 4921, '929': 4922, '930': 4924, '931': 4925, '932': 4926, '933': 4927, '934': 4928, '935': 4929, '936': 4930, '937': 4931, '938': 4932, '939': 4933, '940': 4935, '941': 4936, '942': 4937, '943': 4938, '944': 4939, '945': 4940, '946': 4941, '947': 4942, '948': 4943, '949': 4944, '950': 4946, '951': 4947, '952': 4948, '953': 4949, '954': 4950, '955': 4951, '956': 4952, '957': 4953, '958': 4954, '959': 4955, '960': 4957, '961': 4958, '962': 4959, '963': 4960, '964': 4961, '965': 4962, '966': 4963, '967': 4964, '968': 4965, '969': 4966, '970': 4968, '971': 4969, '972': 4970, '973': 4971, '974': 4972, '975': 4973, '976': 4974, '977': 4975, '978': 4976, '979': 4977, '980': 4979, '981': 4980, '982': 4981, '983': 4982, '984': 4983, '985': 4984, '986': 4985, '987': 4986, '988': 4987, '989': 4988, '990': 4990, '991': 4991, '992': 4992, '993': 4993, '994': 4994, '995': 4995, '996': 4996, '997': 4997, '998': 4998, '999': 4999, '1000': 4, '1001': 5, '1002': 6, '1003': 7, '1004': 8, '1005': 9, '1006': 10, '1007': 11, '1008': 12, '1009': 13, '1010': 15, '1011': 16, '1012': 17, '1013': 18, '1014': 19, '1015': 20, '1016': 21, '1017': 22, '1018': 23, '1019': 24, '1020': 26, '1021': 27, '1022': 28, '1023': 29, '1024': 30, '1025': 31, '1026': 32, '1027': 33, '1028': 34, '1029': 35, '1030': 37, '1031': 38, '1032': 39, '1033': 40, '1034': 41, '1035': 42, '1036': 43, '1037': 44, '1038': 45, '1039': 46, '1040': 48, '1041': 49, '1042': 50, '1043': 51, '1044': 52, '1045': 53, '1046': 54, '1047': 55, '1048': 56, '1049': 57, '1050': 59, '1051': 60, '1052': 61, '1053': 62, '1054': 63, '1055': 64, '1056': 65, '1057': 66, '1058': 67, '1059': 68, '1060': 70, '1061': 71, '1062': 72, '1063': 73, '1064': 74, '1065': 75, '1066': 76, '1067': 77, '1068': 78, '1069': 79, '1070': 81, '1071': 82, '1072': 83, '1073': 84, '1074': 85, '1075': 86, '1076': 87, '1077': 88, '1078': 89, '1079': 90, '1080': 92, '1081': 93, '1082': 94, '1083': 95, '1084': 96, '1085': 97, '1086': 98, '1087': 99, '1088': 100, '1089': 101, '1090': 103, '1091': 104, '1092': 105, '1093': 106, '1094': 107, '1095': 108, '1096': 109, '1097': 110, '1098': 111, '1099': 112, '1100': 115, '1101': 116, '1102': 117, '1103': 118, '1104': 119, '1105': 120, '1106': 121, '1107': 122, '1108': 123, '1109': 124, '1110': 126, '1111': 127, '1112': 128, '1113': 129, '1114': 130, '1115': 131, '1116': 132, '1117': 133, '1118': 134, '1119': 135, '1120': 137, '1121': 138, '1122': 139, '1123': 140, '1124': 141, '1125': 142, '1126': 143, '1127': 144, '1128': 145, '1129': 146, '1130': 148, '1131': 149, '1132': 150, '1133': 151, '1134': 152, '1135': 153, '1136': 154, '1137': 155, '1138': 156, '1139': 157, '1140': 159, '1141': 160, '1142': 161, '1143': 162, '1144': 163, '1145': 164, '1146': 165, '1147': 166, '1148': 167, '1149': 168, '1150': 170, '1151': 171, '1152': 172, '1153': 173, '1154': 174, '1155': 175, '1156': 176, '1157': 177, '1158': 178, '1159': 179, '1160': 181, '1161': 182, '1162': 183, '1163': 184, '1164': 185, '1165': 186, '1166': 187, '1167': 188, '1168': 189, '1169': 190, '1170': 192, '1171': 193, '1172': 194, '1173': 195, '1174': 196, '1175': 197, '1176': 198, '1177': 199, '1178': 200, '1179': 201, '1180': 203, '1181': 204, '1182': 205, '1183': 206, '1184': 207, '1185': 208, '1186': 209, '1187': 210, '1188': 211, '1189': 212, '1190': 214, '1191': 215, '1192': 216, '1193': 217, '1194': 218, '1195': 219, '1196': 220, '1197': 221, '1198': 222, '1199': 223, '1200': 226, '1201': 227, '1202': 228, '1203': 229, '1204': 230, '1205': 231, '1206': 232, '1207': 233, '1208': 234, '1209': 235, '1210': 237, '1211': 238, '1212': 239, '1213': 240, '1214': 241, '1215': 242, '1216': 243, '1217': 244, '1218': 245, '1219': 246, '1220': 248, '1221': 249, '1222': 250, '1223': 251, '1224': 252, '1225': 253, '1226': 254, '1227': 255, '1228': 256, '1229': 257, '1230': 259, '1231': 260, '1232': 261, '1233': 262, '1234': 263, '1235': 264, '1236': 265, '1237': 266, '1238': 267, '1239': 268, '1240': 270, '1241': 271, '1242': 272, '1243': 273, '1244': 274, '1245': 275, '1246': 276, '1247': 277, '1248': 278, '1249': 279, '1250': 281, '1251': 282, '1252': 283, '1253': 284, '1254': 285, '1255': 286, '1256': 287, '1257': 288, '1258': 289, '1259': 290, '1260': 292, '1261': 293, '1262': 294, '1263': 295, '1264': 296, '1265': 297, '1266': 298, '1267': 299, '1268': 300, '1269': 301, '1270': 303, '1271': 304, '1272': 305, '1273': 306, '1274': 307, '1275': 308, '1276': 309, '1277': 310, '1278': 311, '1279': 312, '1280': 314, '1281': 315, '1282': 316, '1283': 317, '1284': 318, '1285': 319, '1286': 320, '1287': 321, '1288': 322, '1289': 323, '1290': 325, '1291': 326, '1292': 327, '1293': 328, '1294': 329, '1295': 330, '1296': 331, '1297': 332, '1298': 333, '1299': 334, '1300': 337, '1301': 338, '1302': 339, '1303': 340, '1304': 341, '1305': 342, '1306': 343, '1307': 344, '1308': 345, '1309': 346, '1310': 348, '1311': 349, '1312': 350, '1313': 351, '1314': 352, '1315': 353, '1316': 354, '1317': 355, '1318': 356, '1319': 357, '1320': 359, '1321': 360, '1322': 361, '1323': 362, '1324': 363, '1325': 364, '1326': 365, '1327': 366, '1328': 367, '1329': 368, '1330': 370, '1331': 371, '1332': 372, '1333': 373, '1334': 374, '1335': 375, '1336': 376, '1337': 377, '1338': 378, '1339': 379, '1340': 381, '1341': 382, '1342': 383, '1343': 384, '1344': 385, '1345': 386, '1346': 387, '1347': 388, '1348': 389, '1349': 390, '1350': 392, '1351': 393, '1352': 394, '1353': 395, '1354': 396, '1355': 397, '1356': 398, '1357': 399, '1358': 400, '1359': 401, '1360': 403, '1361': 404, '1362': 405, '1363': 406, '1364': 407, '1365': 408, '1366': 409, '1367': 410, '1368': 411, '1369': 412, '1370': 414, '1371': 415, '1372': 416, '1373': 417, '1374': 418, '1375': 419, '1376': 420, '1377': 421, '1378': 422, '1379': 423, '1380': 425, '1381': 426, '1382': 427, '1383': 428, '1384': 429, '1385': 430, '1386': 431, '1387': 432, '1388': 433, '1389': 434, '1390': 436, '1391': 437, '1392': 438, '1393': 439, '1394': 440, '1395': 441, '1396': 442, '1397': 443, '1398': 444, '1399': 445, '1400': 448, '1401': 449, '1402': 450, '1403': 451, '1404': 452, '1405': 453, '1406': 454, '1407': 455, '1408': 456, '1409': 457, '1410': 459, '1411': 460, '1412': 461, '1413': 462, '1414': 463, '1415': 464, '1416': 465, '1417': 466, '1418': 467, '1419': 468, '1420': 470, '1421': 471, '1422': 472, '1423': 473, '1424': 474, '1425': 475, '1426': 476, '1427': 477, '1428': 478, '1429': 479, '1430': 481, '1431': 482, '1432': 483, '1433': 484, '1434': 485, '1435': 486, '1436': 487, '1437': 488, '1438': 489, '1439': 490, '1440': 492, '1441': 493, '1442': 494, '1443': 495, '1444': 496, '1445': 497, '1446': 498, '1447': 499, '1448': 500, '1449': 501, '1450': 503, '1451': 504, '1452': 505, '1453': 506, '1454': 507, '1455': 508, '1456': 509, '1457': 510, '1458': 511, '1459': 512, '1460': 514, '1461': 515, '1462': 516, '1463': 517, '1464': 518, '1465': 519, '1466': 520, '1467': 521, '1468': 522, '1469': 523, '1470': 525, '1471': 526, '1472': 527, '1473': 528, '1474': 529, '1475': 530, '1476': 531, '1477': 532, '1478': 533, '1479': 534, '1480': 536, '1481': 537, '1482': 538, '1483': 539, '1484': 540, '1485': 541, '1486': 542, '1487': 543, '1488': 544, '1489': 545, '1490': 547, '1491': 548, '1492': 549, '1493': 550, '1494': 551, '1495': 552, '1496': 553, '1497': 554, '1498': 555, '1499': 556, '1500': 559, '1501': 560, '1502': 561, '1503': 562, '1504': 563, '1505': 564, '1506': 565, '1507': 566, '1508': 567, '1509': 568, '1510': 570, '1511': 571, '1512': 572, '1513': 573, '1514': 574, '1515': 575, '1516': 576, '1517': 577, '1518': 578, '1519': 579, '1520': 581, '1521': 582, '1522': 583, '1523': 584, '1524': 585, '1525': 586, '1526': 587, '1527': 588, '1528': 589, '1529': 590, '1530': 592, '1531': 593, '1532': 594, '1533': 595, '1534': 596, '1535': 597, '1536': 598, '1537': 599, '1538': 600, '1539': 601, '1540': 603, '1541': 604, '1542': 605, '1543': 606, '1544': 607, '1545': 608, '1546': 609, '1547': 610, '1548': 611, '1549': 612, '1550': 614, '1551': 615, '1552': 616, '1553': 617, '1554': 618, '1555': 619, '1556': 620, '1557': 621, '1558': 622, '1559': 623, '1560': 625, '1561': 626, '1562': 627, '1563': 628, '1564': 629, '1565': 630, '1566': 631, '1567': 632, '1568': 633, '1569': 634, '1570': 636, '1571': 637, '1572': 638, '1573': 639, '1574': 640, '1575': 641, '1576': 642, '1577': 643, '1578': 644, '1579': 645, '1580': 647, '1581': 648, '1582': 649, '1583': 650, '1584': 651, '1585': 652, '1586': 653, '1587': 654, '1588': 655, '1589': 656, '1590': 658, '1591': 659, '1592': 660, '1593': 661, '1594': 662, '1595': 663, '1596': 664, '1597': 665, '1598': 666, '1599': 667, '1600': 670, '1601': 671, '1602': 672, '1603': 673, '1604': 674, '1605': 675, '1606': 676, '1607': 677, '1608': 678, '1609': 679, '1610': 681, '1611': 682, '1612': 683, '1613': 684, '1614': 685, '1615': 686, '1616': 687, '1617': 688, '1618': 689, '1619': 690, '1620': 692, '1621': 693, '1622': 694, '1623': 695, '1624': 696, '1625': 697, '1626': 698, '1627': 699, '1628': 700, '1629': 701, '1630': 703, '1631': 704, '1632': 705, '1633': 706, '1634': 707, '1635': 708, '1636': 709, '1637': 710, '1638': 711, '1639': 712, '1640': 714, '1641': 715, '1642': 716, '1643': 717, '1644': 718, '1645': 719, '1646': 720, '1647': 721, '1648': 722, '1649': 723, '1650': 725, '1651': 726, '1652': 727, '1653': 728, '1654': 729, '1655': 730, '1656': 731, '1657': 732, '1658': 733, '1659': 734, '1660': 736, '1661': 737, '1662': 738, '1663': 739, '1664': 740, '1665': 741, '1666': 742, '1667': 743, '1668': 744, '1669': 745, '1670': 747, '1671': 748, '1672': 749, '1673': 750, '1674': 751, '1675': 752, '1676': 753, '1677': 754, '1678': 755, '1679': 756, '1680': 758, '1681': 759, '1682': 760, '1683': 761, '1684': 762, '1685': 763, '1686': 764, '1687': 765, '1688': 766, '1689': 767, '1690': 769, '1691': 770, '1692': 771, '1693': 772, '1694': 773, '1695': 774, '1696': 775, '1697': 776, '1698': 777, '1699': 778, '1700': 781, '1701': 782, '1702': 783, '1703': 784, '1704': 785, '1705': 786, '1706': 787, '1707': 788, '1708': 789, '1709': 790, '1710': 792, '1711': 793, '1712': 794, '1713': 795, '1714': 796, '1715': 797, '1716': 798, '1717': 799, '1718': 800, '1719': 801, '1720': 803, '1721': 804, '1722': 805, '1723': 806, '1724': 807, '1725': 808, '1726': 809, '1727': 810, '1728': 811, '1729': 812, '1730': 814, '1731': 815, '1732': 816, '1733': 817, '1734': 818, '1735': 819, '1736': 820, '1737': 821, '1738': 822, '1739': 823, '1740': 825, '1741': 826, '1742': 827, '1743': 828, '1744': 829, '1745': 830, '1746': 831, '1747': 832, '1748': 833, '1749': 834, '1750': 836, '1751': 837, '1752': 838, '1753': 839, '1754': 840, '1755': 841, '1756': 842, '1757': 843, '1758': 844, '1759': 845, '1760': 847, '1761': 848, '1762': 849, '1763': 850, '1764': 851, '1765': 852, '1766': 853, '1767': 854, '1768': 855, '1769': 856, '1770': 858, '1771': 859, '1772': 860, '1773': 861, '1774': 862, '1775': 863, '1776': 864, '1777': 865, '1778': 866, '1779': 867, '1780': 869, '1781': 870, '1782': 871, '1783': 872, '1784': 873, '1785': 874, '1786': 875, '1787': 876, '1788': 877, '1789': 878, '1790': 880, '1791': 881, '1792': 882, '1793': 883, '1794': 884, '1795': 885, '1796': 886, '1797': 887, '1798': 888, '1799': 889, '1800': 892, '1801': 893, '1802': 894, '1803': 895, '1804': 896, '1805': 897, '1806': 898, '1807': 899, '1808': 900, '1809': 901, '1810': 903, '1811': 904, '1812': 905, '1813': 906, '1814': 907, '1815': 908, '1816': 909, '1817': 910, '1818': 911, '1819': 912, '1820': 914, '1821': 915, '1822': 916, '1823': 917, '1824': 918, '1825': 919, '1826': 920, '1827': 921, '1828': 922, '1829': 923, '1830': 925, '1831': 926, '1832': 927, '1833': 928, '1834': 929, '1835': 930, '1836': 931, '1837': 932, '1838': 933, '1839': 934, '1840': 936, '1841': 937, '1842': 938, '1843': 939, '1844': 940, '1845': 941, '1846': 942, '1847': 943, '1848': 944, '1849': 945, '1850': 947, '1851': 948, '1852': 949, '1853': 950, '1854': 951, '1855': 952, '1856': 953, '1857': 954, '1858': 955, '1859': 956, '1860': 958, '1861': 959, '1862': 960, '1863': 961, '1864': 962, '1865': 963, '1866': 964, '1867': 965, '1868': 966, '1869': 967, '1870': 969, '1871': 970, '1872': 971, '1873': 972, '1874': 973, '1875': 974, '1876': 975, '1877': 976, '1878': 977, '1879': 978, '1880': 980, '1881': 981, '1882': 982, '1883': 983, '1884': 984, '1885': 985, '1886': 986, '1887': 987, '1888': 988, '1889': 989, '1890': 991, '1891': 992, '1892': 993, '1893': 994, '1894': 995, '1895': 996, '1896': 997, '1897': 998, '1898': 999, '1899': 1000, '1900': 1003, '1901': 1004, '1902': 1005, '1903': 1006, '1904': 1007, '1905': 1008, '1906': 1009, '1907': 1010, '1908': 1011, '1909': 1012, '1910': 1014, '1911': 1015, '1912': 1016, '1913': 1017, '1914': 1018, '1915': 1019, '1916': 1020, '1917': 1021, '1918': 1022, '1919': 1023, '1920': 1025, '1921': 1026, '1922': 1027, '1923': 1028, '1924': 1029, '1925': 1030, '1926': 1031, '1927': 1032, '1928': 1033, '1929': 1034, '1930': 1036, '1931': 1037, '1932': 1038, '1933': 1039, '1934': 1040, '1935': 1041, '1936': 1042, '1937': 1043, '1938': 1044, '1939': 1045, '1940': 1047, '1941': 1048, '1942': 1049, '1943': 1050, '1944': 1051, '1945': 1052, '1946': 1053, '1947': 1054, '1948': 1055, '1949': 1056, '1950': 1058, '1951': 1059, '1952': 1060, '1953': 1061, '1954': 1062, '1955': 1063, '1956': 1064, '1957': 1065, '1958': 1066, '1959': 1067, '1960': 1069, '1961': 1070, '1962': 1071, '1963': 1072, '1964': 1073, '1965': 1074, '1966': 1075, '1967': 1076, '1968': 1077, '1969': 1078, '1970': 1080, '1971': 1081, '1972': 1082, '1973': 1083, '1974': 1084, '1975': 1085, '1976': 1086, '1977': 1087, '1978': 1088, '1979': 1089, '1980': 1091, '1981': 1092, '1982': 1093, '1983': 1094, '1984': 1095, '1985': 1096, '1986': 1097, '1987': 1098, '1988': 1099, '1989': 1100, '1990': 1102, '1991': 1103, '1992': 1104, '1993': 1105, '1994': 1106, '1995': 1107, '1996': 1108, '1997': 1109, '1998': 1110, '1999': 1111, '2000': 1115, '2001': 1116, '2002': 1117, '2003': 1118, '2004': 1119, '2005': 1120, '2006': 1121, '2007': 1122, '2008': 1123, '2009': 1124, '2010': 1126, '2011': 1127, '2012': 1128, '2013': 1129, '2014': 1130, '2015': 1131, '2016': 1132, '2017': 1133, '2018': 1134, '2019': 1135, '2020': 1137, '2021': 1138, '2022': 1139, '2023': 1140, '2024': 1141, '2025': 1142, '2026': 1143, '2027': 1144, '2028': 1145, '2029': 1146, '2030': 1148, '2031': 1149, '2032': 1150, '2033': 1151, '2034': 1152, '2035': 1153, '2036': 1154, '2037': 1155, '2038': 1156, '2039': 1157, '2040': 1159, '2041': 1160, '2042': 1161, '2043': 1162, '2044': 1163, '2045': 1164, '2046': 1165, '2047': 1166, '2048': 1167, '2049': 1168, '2050': 1170, '2051': 1171, '2052': 1172, '2053': 1173, '2054': 1174, '2055': 1175, '2056': 1176, '2057': 1177, '2058': 1178, '2059': 1179, '2060': 1181, '2061': 1182, '2062': 1183, '2063': 1184, '2064': 1185, '2065': 1186, '2066': 1187, '2067': 1188, '2068': 1189, '2069': 1190, '2070': 1192, '2071': 1193, '2072': 1194, '2073': 1195, '2074': 1196, '2075': 1197, '2076': 1198, '2077': 1199, '2078': 1200, '2079': 1201, '2080': 1203, '2081': 1204, '2082': 1205, '2083': 1206, '2084': 1207, '2085': 1208, '2086': 1209, '2087': 1210, '2088': 1211, '2089': 1212, '2090': 1214, '2091': 1215, '2092': 1216, '2093': 1217, '2094': 1218, '2095': 1219, '2096': 1220, '2097': 1221, '2098': 1222, '2099': 1223, '2100': 1226, '2101': 1227, '2102': 1228, '2103': 1229, '2104': 1230, '2105': 1231, '2106': 1232, '2107': 1233, '2108': 1234, '2109': 1235, '2110': 1237, '2111': 1238, '2112': 1239, '2113': 1240, '2114': 1241, '2115': 1242, '2116': 1243, '2117': 1244, '2118': 1245, '2119': 1246, '2120': 1248, '2121': 1249, '2122': 1250, '2123': 1251, '2124': 1252, '2125': 1253, '2126': 1254, '2127': 1255, '2128': 1256, '2129': 1257, '2130': 1259, '2131': 1260, '2132': 1261, '2133': 1262, '2134': 1263, '2135': 1264, '2136': 1265, '2137': 1266, '2138': 1267, '2139': 1268, '2140': 1270, '2141': 1271, '2142': 1272, '2143': 1273, '2144': 1274, '2145': 1275, '2146': 1276, '2147': 1277, '2148': 1278, '2149': 1279, '2150': 1281, '2151': 1282, '2152': 1283, '2153': 1284, '2154': 1285, '2155': 1286, '2156': 1287, '2157': 1288, '2158': 1289, '2159': 1290, '2160': 1292, '2161': 1293, '2162': 1294, '2163': 1295, '2164': 1296, '2165': 1297, '2166': 1298, '2167': 1299, '2168': 1300, '2169': 1301, '2170': 1303, '2171': 1304, '2172': 1305, '2173': 1306, '2174': 1307, '2175': 1308, '2176': 1309, '2177': 1310, '2178': 1311, '2179': 1312, '2180': 1314, '2181': 1315, '2182': 1316, '2183': 1317, '2184': 1318, '2185': 1319, '2186': 1320, '2187': 1321, '2188': 1322, '2189': 1323, '2190': 1325, '2191': 1326, '2192': 1327, '2193': 1328, '2194': 1329, '2195': 1330, '2196': 1331, '2197': 1332, '2198': 1333, '2199': 1334, '2200': 1337, '2201': 1338, '2202': 1339, '2203': 1340, '2204': 1341, '2205': 1342, '2206': 1343, '2207': 1344, '2208': 1345, '2209': 1346, '2210': 1348, '2211': 1349, '2212': 1350, '2213': 1351, '2214': 1352, '2215': 1353, '2216': 1354, '2217': 1355, '2218': 1356, '2219': 1357, '2220': 1359, '2221': 1360, '2222': 1361, '2223': 1362, '2224': 1363, '2225': 1364, '2226': 1365, '2227': 1366, '2228': 1367, '2229': 1368, '2230': 1370, '2231': 1371, '2232': 1372, '2233': 1373, '2234': 1374, '2235': 1375, '2236': 1376, '2237': 1377, '2238': 1378, '2239': 1379, '2240': 1381, '2241': 1382, '2242': 1383, '2243': 1384, '2244': 1385, '2245': 1386, '2246': 1387, '2247': 1388, '2248': 1389, '2249': 1390, '2250': 1392, '2251': 1393, '2252': 1394, '2253': 1395, '2254': 1396, '2255': 1397, '2256': 1398, '2257': 1399, '2258': 1400, '2259': 1401, '2260': 1403, '2261': 1404, '2262': 1405, '2263': 1406, '2264': 1407, '2265': 1408, '2266': 1409, '2267': 1410, '2268': 1411, '2269': 1412, '2270': 1414, '2271': 1415, '2272': 1416, '2273': 1417, '2274': 1418, '2275': 1419, '2276': 1420, '2277': 1421, '2278': 1422, '2279': 1423, '2280': 1425, '2281': 1426, '2282': 1427, '2283': 1428, '2284': 1429, '2285': 1430, '2286': 1431, '2287': 1432, '2288': 1433, '2289': 1434, '2290': 1436, '2291': 1437, '2292': 1438, '2293': 1439, '2294': 1440, '2295': 1441, '2296': 1442, '2297': 1443, '2298': 1444, '2299': 1445, '2300': 1448, '2301': 1449, '2302': 1450, '2303': 1451, '2304': 1452, '2305': 1453, '2306': 1454, '2307': 1455, '2308': 1456, '2309': 1457, '2310': 1459, '2311': 1460, '2312': 1461, '2313': 1462, '2314': 1463, '2315': 1464, '2316': 1465, '2317': 1466, '2318': 1467, '2319': 1468, '2320': 1470, '2321': 1471, '2322': 1472, '2323': 1473, '2324': 1474, '2325': 1475, '2326': 1476, '2327': 1477, '2328': 1478, '2329': 1479, '2330': 1481, '2331': 1482, '2332': 1483, '2333': 1484, '2334': 1485, '2335': 1486, '2336': 1487, '2337': 1488, '2338': 1489, '2339': 1490, '2340': 1492, '2341': 1493, '2342': 1494, '2343': 1495, '2344': 1496, '2345': 1497, '2346': 1498, '2347': 1499, '2348': 1500, '2349': 1501, '2350': 1503, '2351': 1504, '2352': 1505, '2353': 1506, '2354': 1507, '2355': 1508, '2356': 1509, '2357': 1510, '2358': 1511, '2359': 1512, '2360': 1514, '2361': 1515, '2362': 1516, '2363': 1517, '2364': 1518, '2365': 1519, '2366': 1520, '2367': 1521, '2368': 1522, '2369': 1523, '2370': 1525, '2371': 1526, '2372': 1527, '2373': 1528, '2374': 1529, '2375': 1530, '2376': 1531, '2377': 1532, '2378': 1533, '2379': 1534, '2380': 1536, '2381': 1537, '2382': 1538, '2383': 1539, '2384': 1540, '2385': 1541, '2386': 1542, '2387': 1543, '2388': 1544, '2389': 1545, '2390': 1547, '2391': 1548, '2392': 1549, '2393': 1550, '2394': 1551, '2395': 1552, '2396': 1553, '2397': 1554, '2398': 1555, '2399': 1556, '2400': 1559, '2401': 1560, '2402': 1561, '2403': 1562, '2404': 1563, '2405': 1564, '2406': 1565, '2407': 1566, '2408': 1567, '2409': 1568, '2410': 1570, '2411': 1571, '2412': 1572, '2413': 1573, '2414': 1574, '2415': 1575, '2416': 1576, '2417': 1577, '2418': 1578, '2419': 1579, '2420': 1581, '2421': 1582, '2422': 1583, '2423': 1584, '2424': 1585, '2425': 1586, '2426': 1587, '2427': 1588, '2428': 1589, '2429': 1590, '2430': 1592, '2431': 1593, '2432': 1594, '2433': 1595, '2434': 1596, '2435': 1597, '2436': 1598, '2437': 1599, '2438': 1600, '2439': 1601, '2440': 1603, '2441': 1604, '2442': 1605, '2443': 1606, '2444': 1607, '2445': 1608, '2446': 1609, '2447': 1610, '2448': 1611, '2449': 1612, '2450': 1614, '2451': 1615, '2452': 1616, '2453': 1617, '2454': 1618, '2455': 1619, '2456': 1620, '2457': 1621, '2458': 1622, '2459': 1623, '2460': 1625, '2461': 1626, '2462': 1627, '2463': 1628, '2464': 1629, '2465': 1630, '2466': 1631, '2467': 1632, '2468': 1633, '2469': 1634, '2470': 1636, '2471': 1637, '2472': 1638, '2473': 1639, '2474': 1640, '2475': 1641, '2476': 1642, '2477': 1643, '2478': 1644, '2479': 1645, '2480': 1647, '2481': 1648, '2482': 1649, '2483': 1650, '2484': 1651, '2485': 1652, '2486': 1653, '2487': 1654, '2488': 1655, '2489': 1656, '2490': 1658, '2491': 1659, '2492': 1660, '2493': 1661, '2494': 1662, '2495': 1663, '2496': 1664, '2497': 1665, '2498': 1666, '2499': 1667, '2500': 1670, '2501': 1671, '2502': 1672, '2503': 1673, '2504': 1674, '2505': 1675, '2506': 1676, '2507': 1677, '2508': 1678, '2509': 1679, '2510': 1681, '2511': 1682, '2512': 1683, '2513': 1684, '2514': 1685, '2515': 1686, '2516': 1687, '2517': 1688, '2518': 1689, '2519': 1690, '2520': 1692, '2521': 1693, '2522': 1694, '2523': 1695, '2524': 1696, '2525': 1697, '2526': 1698, '2527': 1699, '2528': 1700, '2529': 1701, '2530': 1703, '2531': 1704, '2532': 1705, '2533': 1706, '2534': 1707, '2535': 1708, '2536': 1709, '2537': 1710, '2538': 1711, '2539': 1712, '2540': 1714, '2541': 1715, '2542': 1716, '2543': 1717, '2544': 1718, '2545': 1719, '2546': 1720, '2547': 1721, '2548': 1722, '2549': 1723, '2550': 1725, '2551': 1726, '2552': 1727, '2553': 1728, '2554': 1729, '2555': 1730, '2556': 1731, '2557': 1732, '2558': 1733, '2559': 1734, '2560': 1736, '2561': 1737, '2562': 1738, '2563': 1739, '2564': 1740, '2565': 1741, '2566': 1742, '2567': 1743, '2568': 1744, '2569': 1745, '2570': 1747, '2571': 1748, '2572': 1749, '2573': 1750, '2574': 1751, '2575': 1752, '2576': 1753, '2577': 1754, '2578': 1755, '2579': 1756, '2580': 1758, '2581': 1759, '2582': 1760, '2583': 1761, '2584': 1762, '2585': 1763, '2586': 1764, '2587': 1765, '2588': 1766, '2589': 1767, '2590': 1769, '2591': 1770, '2592': 1771, '2593': 1772, '2594': 1773, '2595': 1774, '2596': 1775, '2597': 1776, '2598': 1777, '2599': 1778, '2600': 1781, '2601': 1782, '2602': 1783, '2603': 1784, '2604': 1785, '2605': 1786, '2606': 1787, '2607': 1788, '2608': 1789, '2609': 1790, '2610': 1792, '2611': 1793, '2612': 1794, '2613': 1795, '2614': 1796, '2615': 1797, '2616': 1798, '2617': 1799, '2618': 1800, '2619': 1801, '2620': 1803, '2621': 1804, '2622': 1805, '2623': 1806, '2624': 1807, '2625': 1808, '2626': 1809, '2627': 1810, '2628': 1811, '2629': 1812, '2630': 1814, '2631': 1815, '2632': 1816, '2633': 1817, '2634': 1818, '2635': 1819, '2636': 1820, '2637': 1821, '2638': 1822, '2639': 1823, '2640': 1825, '2641': 1826, '2642': 1827, '2643': 1828, '2644': 1829, '2645': 1830, '2646': 1831, '2647': 1832, '2648': 1833, '2649': 1834, '2650': 1836, '2651': 1837, '2652': 1838, '2653': 1839, '2654': 1840, '2655': 1841, '2656': 1842, '2657': 1843, '2658': 1844, '2659': 1845, '2660': 1847, '2661': 1848, '2662': 1849, '2663': 1850, '2664': 1851, '2665': 1852, '2666': 1853, '2667': 1854, '2668': 1855, '2669': 1856, '2670': 1858, '2671': 1859, '2672': 1860, '2673': 1861, '2674': 1862, '2675': 1863, '2676': 1864, '2677': 1865, '2678': 1866, '2679': 1867, '2680': 1869, '2681': 1870, '2682': 1871, '2683': 1872, '2684': 1873, '2685': 1874, '2686': 1875, '2687': 1876, '2688': 1877, '2689': 1878, '2690': 1880, '2691': 1881, '2692': 1882, '2693': 1883, '2694': 1884, '2695': 1885, '2696': 1886, '2697': 1887, '2698': 1888, '2699': 1889, '2700': 1892, '2701': 1893, '2702': 1894, '2703': 1895, '2704': 1896, '2705': 1897, '2706': 1898, '2707': 1899, '2708': 1900, '2709': 1901, '2710': 1903, '2711': 1904, '2712': 1905, '2713': 1906, '2714': 1907, '2715': 1908, '2716': 1909, '2717': 1910, '2718': 1911, '2719': 1912, '2720': 1914, '2721': 1915, '2722': 1916, '2723': 1917, '2724': 1918, '2725': 1919, '2726': 1920, '2727': 1921, '2728': 1922, '2729': 1923, '2730': 1925, '2731': 1926, '2732': 1927, '2733': 1928, '2734': 1929, '2735': 1930, '2736': 1931, '2737': 1932, '2738': 1933, '2739': 1934, '2740': 1936, '2741': 1937, '2742': 1938, '2743': 1939, '2744': 1940, '2745': 1941, '2746': 1942, '2747': 1943, '2748': 1944, '2749': 1945, '2750': 1947, '2751': 1948, '2752': 1949, '2753': 1950, '2754': 1951, '2755': 1952, '2756': 1953, '2757': 1954, '2758': 1955, '2759': 1956, '2760': 1958, '2761': 1959, '2762': 1960, '2763': 1961, '2764': 1962, '2765': 1963, '2766': 1964, '2767': 1965, '2768': 1966, '2769': 1967, '2770': 1969, '2771': 1970, '2772': 1971, '2773': 1972, '2774': 1973, '2775': 1974, '2776': 1975, '2777': 1976, '2778': 1977, '2779': 1978, '2780': 1980, '2781': 1981, '2782': 1982, '2783': 1983, '2784': 1984, '2785': 1985, '2786': 1986, '2787': 1987, '2788': 1988, '2789': 1989, '2790': 1991, '2791': 1992, '2792': 1993, '2793': 1994, '2794': 1995, '2795': 1996, '2796': 1997, '2797': 1998, '2798': 1999, '2799': 2000, '2800': 2003, '2801': 2004, '2802': 2005, '2803': 2006, '2804': 2007, '2805': 2008, '2806': 2009, '2807': 2010, '2808': 2011, '2809': 2012, '2810': 2014, '2811': 2015, '2812': 2016, '2813': 2017, '2814': 2018, '2815': 2019, '2816': 2020, '2817': 2021, '2818': 2022, '2819': 2023, '2820': 2025, '2821': 2026, '2822': 2027, '2823': 2028, '2824': 2029, '2825': 2030, '2826': 2031, '2827': 2032, '2828': 2033, '2829': 2034, '2830': 2036, '2831': 2037, '2832': 2038, '2833': 2039, '2834': 2040, '2835': 2041, '2836': 2042, '2837': 2043, '2838': 2044, '2839': 2045, '2840': 2047, '2841': 2048, '2842': 2049, '2843': 2050, '2844': 2051, '2845': 2052, '2846': 2053, '2847': 2054, '2848': 2055, '2849': 2056, '2850': 2058, '2851': 2059, '2852': 2060, '2853': 2061, '2854': 2062, '2855': 2063, '2856': 2064, '2857': 2065, '2858': 2066, '2859': 2067, '2860': 2069, '2861': 2070, '2862': 2071, '2863': 2072, '2864': 2073, '2865': 2074, '2866': 2075, '2867': 2076, '2868': 2077, '2869': 2078, '2870': 2080, '2871': 2081, '2872': 2082, '2873': 2083, '2874': 2084, '2875': 2085, '2876': 2086, '2877': 2087, '2878': 2088, '2879': 2089, '2880': 2091, '2881': 2092, '2882': 2093, '2883': 2094, '2884': 2095, '2885': 2096, '2886': 2097, '2887': 2098, '2888': 2099, '2889': 2100, '2890': 2102, '2891': 2103, '2892': 2104, '2893': 2105, '2894': 2106, '2895': 2107, '2896': 2108, '2897': 2109, '2898': 2110, '2899': 2111, '2900': 2114, '2901': 2115, '2902': 2116, '2903': 2117, '2904': 2118, '2905': 2119, '2906': 2120, '2907': 2121, '2908': 2122, '2909': 2123, '2910': 2125, '2911': 2126, '2912': 2127, '2913': 2128, '2914': 2129, '2915': 2130, '2916': 2131, '2917': 2132, '2918': 2133, '2919': 2134, '2920': 2136, '2921': 2137, '2922': 2138, '2923': 2139, '2924': 2140, '2925': 2141, '2926': 2142, '2927': 2143, '2928': 2144, '2929': 2145, '2930': 2147, '2931': 2148, '2932': 2149, '2933': 2150, '2934': 2151, '2935': 2152, '2936': 2153, '2937': 2154, '2938': 2155, '2939': 2156, '2940': 2158, '2941': 2159, '2942': 2160, '2943': 2161, '2944': 2162, '2945': 2163, '2946': 2164, '2947': 2165, '2948': 2166, '2949': 2167, '2950': 2169, '2951': 2170, '2952': 2171, '2953': 2172, '2954': 2173, '2955': 2174, '2956': 2175, '2957': 2176, '2958': 2177, '2959': 2178, '2960': 2180, '2961': 2181, '2962': 2182, '2963': 2183, '2964': 2184, '2965': 2185, '2966': 2186, '2967': 2187, '2968': 2188, '2969': 2189, '2970': 2191, '2971': 2192, '2972': 2193, '2973': 2194, '2974': 2195, '2975': 2196, '2976': 2197, '2977': 2198, '2978': 2199, '2979': 2200, '2980': 2202, '2981': 2203, '2982': 2204, '2983': 2205, '2984': 2206, '2985': 2207, '2986': 2208, '2987': 2209, '2988': 2210, '2989': 2211, '2990': 2213, '2991': 2214, '2992': 2215, '2993': 2216, '2994': 2217, '2995': 2218, '2996': 2219, '2997': 2220, '2998': 2221, '2999': 2222, '3000': 2226, '3001': 2227, '3002': 2228, '3003': 2229, '3004': 2230, '3005': 2231, '3006': 2232, '3007': 2233, '3008': 2234, '3009': 2235, '3010': 2237, '3011': 2238, '3012': 2239, '3013': 2240, '3014': 2241, '3015': 2242, '3016': 2243, '3017': 2244, '3018': 2245, '3019': 2246, '3020': 2248, '3021': 2249, '3022': 2250, '3023': 2251, '3024': 2252, '3025': 2253, '3026': 2254, '3027': 2255, '3028': 2256, '3029': 2257, '3030': 2259, '3031': 2260, '3032': 2261, '3033': 2262, '3034': 2263, '3035': 2264, '3036': 2265, '3037': 2266, '3038': 2267, '3039': 2268, '3040': 2270, '3041': 2271, '3042': 2272, '3043': 2273, '3044': 2274, '3045': 2275, '3046': 2276, '3047': 2277, '3048': 2278, '3049': 2279, '3050': 2281, '3051': 2282, '3052': 2283, '3053': 2284, '3054': 2285, '3055': 2286, '3056': 2287, '3057': 2288, '3058': 2289, '3059': 2290, '3060': 2292, '3061': 2293, '3062': 2294, '3063': 2295, '3064': 2296, '3065': 2297, '3066': 2298, '3067': 2299, '3068': 2300, '3069': 2301, '3070': 2303, '3071': 2304, '3072': 2305, '3073': 2306, '3074': 2307, '3075': 2308, '3076': 2309, '3077': 2310, '3078': 2311, '3079': 2312, '3080': 2314, '3081': 2315, '3082': 2316, '3083': 2317, '3084': 2318, '3085': 2319, '3086': 2320, '3087': 2321, '3088': 2322, '3089': 2323, '3090': 2325, '3091': 2326, '3092': 2327, '3093': 2328, '3094': 2329, '3095': 2330, '3096': 2331, '3097': 2332, '3098': 2333, '3099': 2334, '3100': 2337, '3101': 2338, '3102': 2339, '3103': 2340, '3104': 2341, '3105': 2342, '3106': 2343, '3107': 2344, '3108': 2345, '3109': 2346, '3110': 2348, '3111': 2349, '3112': 2350, '3113': 2351, '3114': 2352, '3115': 2353, '3116': 2354, '3117': 2355, '3118': 2356, '3119': 2357, '3120': 2359, '3121': 2360, '3122': 2361, '3123': 2362, '3124': 2363, '3125': 2364, '3126': 2365, '3127': 2366, '3128': 2367, '3129': 2368, '3130': 2370, '3131': 2371, '3132': 2372, '3133': 2373, '3134': 2374, '3135': 2375, '3136': 2376, '3137': 2377, '3138': 2378, '3139': 2379, '3140': 2381, '3141': 2382, '3142': 2383, '3143': 2384, '3144': 2385, '3145': 2386, '3146': 2387, '3147': 2388, '3148': 2389, '3149': 2390, '3150': 2392, '3151': 2393, '3152': 2394, '3153': 2395, '3154': 2396, '3155': 2397, '3156': 2398, '3157': 2399, '3158': 2400, '3159': 2401, '3160': 2403, '3161': 2404, '3162': 2405, '3163': 2406, '3164': 2407, '3165': 2408, '3166': 2409, '3167': 2410, '3168': 2411, '3169': 2412, '3170': 2414, '3171': 2415, '3172': 2416, '3173': 2417, '3174': 2418, '3175': 2419, '3176': 2420, '3177': 2421, '3178': 2422, '3179': 2423, '3180': 2425, '3181': 2426, '3182': 2427, '3183': 2428, '3184': 2429, '3185': 2430, '3186': 2431, '3187': 2432, '3188': 2433, '3189': 2434, '3190': 2436, '3191': 2437, '3192': 2438, '3193': 2439, '3194': 2440, '3195': 2441, '3196': 2442, '3197': 2443, '3198': 2444, '3199': 2445, '3200': 2448, '3201': 2449, '3202': 2450, '3203': 2451, '3204': 2452, '3205': 2453, '3206': 2454, '3207': 2455, '3208': 2456, '3209': 2457, '3210': 2459, '3211': 2460, '3212': 2461, '3213': 2462, '3214': 2463, '3215': 2464, '3216': 2465, '3217': 2466, '3218': 2467, '3219': 2468, '3220': 2470, '3221': 2471, '3222': 2472, '3223': 2473, '3224': 2474, '3225': 2475, '3226': 2476, '3227': 2477, '3228': 2478, '3229': 2479, '3230': 2481, '3231': 2482, '3232': 2483, '3233': 2484, '3234': 2485, '3235': 2486, '3236': 2487, '3237': 2488, '3238': 2489, '3239': 2490, '3240': 2492, '3241': 2493, '3242': 2494, '3243': 2495, '3244': 2496, '3245': 2497, '3246': 2498, '3247': 2499, '3248': 2500, '3249': 2501, '3250': 2503, '3251': 2504, '3252': 2505, '3253': 2506, '3254': 2507, '3255': 2508, '3256': 2509, '3257': 2510, '3258': 2511, '3259': 2512, '3260': 2514, '3261': 2515, '3262': 2516, '3263': 2517, '3264': 2518, '3265': 2519, '3266': 2520, '3267': 2521, '3268': 2522, '3269': 2523, '3270': 2525, '3271': 2526, '3272': 2527, '3273': 2528, '3274': 2529, '3275': 2530, '3276': 2531, '3277': 2532, '3278': 2533, '3279': 2534, '3280': 2536, '3281': 2537, '3282': 2538, '3283': 2539, '3284': 2540, '3285': 2541, '3286': 2542, '3287': 2543, '3288': 2544, '3289': 2545, '3290': 2547, '3291': 2548, '3292': 2549, '3293': 2550, '3294': 2551, '3295': 2552, '3296': 2553, '3297': 2554, '3298': 2555, '3299': 2556, '3300': 2559, '3301': 2560, '3302': 2561, '3303': 2562, '3304': 2563, '3305': 2564, '3306': 2565, '3307': 2566, '3308': 2567, '3309': 2568, '3310': 2570, '3311': 2571, '3312': 2572, '3313': 2573, '3314': 2574, '3315': 2575, '3316': 2576, '3317': 2577, '3318': 2578, '3319': 2579, '3320': 2581, '3321': 2582, '3322': 2583, '3323': 2584, '3324': 2585, '3325': 2586, '3326': 2587, '3327': 2588, '3328': 2589, '3329': 2590, '3330': 2592, '3331': 2593, '3332': 2594, '3333': 2595, '3334': 2596, '3335': 2597, '3336': 2598, '3337': 2599, '3338': 2600, '3339': 2601, '3340': 2603, '3341': 2604, '3342': 2605, '3343': 2606, '3344': 2607, '3345': 2608, '3346': 2609, '3347': 2610, '3348': 2611, '3349': 2612, '3350': 2614, '3351': 2615, '3352': 2616, '3353': 2617, '3354': 2618, '3355': 2619, '3356': 2620, '3357': 2621, '3358': 2622, '3359': 2623, '3360': 2625, '3361': 2626, '3362': 2627, '3363': 2628, '3364': 2629, '3365': 2630, '3366': 2631, '3367': 2632, '3368': 2633, '3369': 2634, '3370': 2636, '3371': 2637, '3372': 2638, '3373': 2639, '3374': 2640, '3375': 2641, '3376': 2642, '3377': 2643, '3378': 2644, '3379': 2645, '3380': 2647, '3381': 2648, '3382': 2649, '3383': 2650, '3384': 2651, '3385': 2652, '3386': 2653, '3387': 2654, '3388': 2655, '3389': 2656, '3390': 2658, '3391': 2659, '3392': 2660, '3393': 2661, '3394': 2662, '3395': 2663, '3396': 2664, '3397': 2665, '3398': 2666, '3399': 2667, '3400': 2670, '3401': 2671, '3402': 2672, '3403': 2673, '3404': 2674, '3405': 2675, '3406': 2676, '3407': 2677, '3408': 2678, '3409': 2679, '3410': 2681, '3411': 2682, '3412': 2683, '3413': 2684, '3414': 2685, '3415': 2686, '3416': 2687, '3417': 2688, '3418': 2689, '3419': 2690, '3420': 2692, '3421': 2693, '3422': 2694, '3423': 2695, '3424': 2696, '3425': 2697, '3426': 2698, '3427': 2699, '3428': 2700, '3429': 2701, '3430': 2703, '3431': 2704, '3432': 2705, '3433': 2706, '3434': 2707, '3435': 2708, '3436': 2709, '3437': 2710, '3438': 2711, '3439': 2712, '3440': 2714, '3441': 2715, '3442': 2716, '3443': 2717, '3444': 2718, '3445': 2719, '3446': 2720, '3447': 2721, '3448': 2722, '3449': 2723, '3450': 2725, '3451': 2726, '3452': 2727, '3453': 2728, '3454': 2729, '3455': 2730, '3456': 2731, '3457': 2732, '3458': 2733, '3459': 2734, '3460': 2736, '3461': 2737, '3462': 2738, '3463': 2739, '3464': 2740, '3465': 2741, '3466': 2742, '3467': 2743, '3468': 2744, '3469': 2745, '3470': 2747, '3471': 2748, '3472': 2749, '3473': 2750, '3474': 2751, '3475': 2752, '3476': 2753, '3477': 2754, '3478': 2755, '3479': 2756, '3480': 2758, '3481': 2759, '3482': 2760, '3483': 2761, '3484': 2762, '3485': 2763, '3486': 2764, '3487': 2765, '3488': 2766, '3489': 2767, '3490': 2769, '3491': 2770, '3492': 2771, '3493': 2772, '3494': 2773, '3495': 2774, '3496': 2775, '3497': 2776, '3498': 2777, '3499': 2778, '3500': 2781, '3501': 2782, '3502': 2783, '3503': 2784, '3504': 2785, '3505': 2786, '3506': 2787, '3507': 2788, '3508': 2789, '3509': 2790, '3510': 2792, '3511': 2793, '3512': 2794, '3513': 2795, '3514': 2796, '3515': 2797, '3516': 2798, '3517': 2799, '3518': 2800, '3519': 2801, '3520': 2803, '3521': 2804, '3522': 2805, '3523': 2806, '3524': 2807, '3525': 2808, '3526': 2809, '3527': 2810, '3528': 2811, '3529': 2812, '3530': 2814, '3531': 2815, '3532': 2816, '3533': 2817, '3534': 2818, '3535': 2819, '3536': 2820, '3537': 2821, '3538': 2822, '3539': 2823, '3540': 2825, '3541': 2826, '3542': 2827, '3543': 2828, '3544': 2829, '3545': 2830, '3546': 2831, '3547': 2832, '3548': 2833, '3549': 2834, '3550': 2836, '3551': 2837, '3552': 2838, '3553': 2839, '3554': 2840, '3555': 2841, '3556': 2842, '3557': 2843, '3558': 2844, '3559': 2845, '3560': 2847, '3561': 2848, '3562': 2849, '3563': 2850, '3564': 2851, '3565': 2852, '3566': 2853, '3567': 2854, '3568': 2855, '3569': 2856, '3570': 2858, '3571': 2859, '3572': 2860, '3573': 2861, '3574': 2862, '3575': 2863, '3576': 2864, '3577': 2865, '3578': 2866, '3579': 2867, '3580': 2869, '3581': 2870, '3582': 2871, '3583': 2872, '3584': 2873, '3585': 2874, '3586': 2875, '3587': 2876, '3588': 2877, '3589': 2878, '3590': 2880, '3591': 2881, '3592': 2882, '3593': 2883, '3594': 2884, '3595': 2885, '3596': 2886, '3597': 2887, '3598': 2888, '3599': 2889, '3600': 2892, '3601': 2893, '3602': 2894, '3603': 2895, '3604': 2896, '3605': 2897, '3606': 2898, '3607': 2899, '3608': 2900, '3609': 2901, '3610': 2903, '3611': 2904, '3612': 2905, '3613': 2906, '3614': 2907, '3615': 2908, '3616': 2909, '3617': 2910, '3618': 2911, '3619': 2912, '3620': 2914, '3621': 2915, '3622': 2916, '3623': 2917, '3624': 2918, '3625': 2919, '3626': 2920, '3627': 2921, '3628': 2922, '3629': 2923, '3630': 2925, '3631': 2926, '3632': 2927, '3633': 2928, '3634': 2929, '3635': 2930, '3636': 2931, '3637': 2932, '3638': 2933, '3639': 2934, '3640': 2936, '3641': 2937, '3642': 2938, '3643': 2939, '3644': 2940, '3645': 2941, '3646': 2942, '3647': 2943, '3648': 2944, '3649': 2945, '3650': 2947, '3651': 2948, '3652': 2949, '3653': 2950, '3654': 2951, '3655': 2952, '3656': 2953, '3657': 2954, '3658': 2955, '3659': 2956, '3660': 2958, '3661': 2959, '3662': 2960, '3663': 2961, '3664': 2962, '3665': 2963, '3666': 2964, '3667': 2965, '3668': 2966, '3669': 2967, '3670': 2969, '3671': 2970, '3672': 2971, '3673': 2972, '3674': 2973, '3675': 2974, '3676': 2975, '3677': 2976, '3678': 2977, '3679': 2978, '3680': 2980, '3681': 2981, '3682': 2982, '3683': 2983, '3684': 2984, '3685': 2985, '3686': 2986, '3687': 2987, '3688': 2988, '3689': 2989, '3690': 2991, '3691': 2992, '3692': 2993, '3693': 2994, '3694': 2995, '3695': 2996, '3696': 2997, '3697': 2998, '3698': 2999, '3699': 3000, '3700': 3003, '3701': 3004, '3702': 3005, '3703': 3006, '3704': 3007, '3705': 3008, '3706': 3009, '3707': 3010, '3708': 3011, '3709': 3012, '3710': 3014, '3711': 3015, '3712': 3016, '3713': 3017, '3714': 3018, '3715': 3019, '3716': 3020, '3717': 3021, '3718': 3022, '3719': 3023, '3720': 3025, '3721': 3026, '3722': 3027, '3723': 3028, '3724': 3029, '3725': 3030, '3726': 3031, '3727': 3032, '3728': 3033, '3729': 3034, '3730': 3036, '3731': 3037, '3732': 3038, '3733': 3039, '3734': 3040, '3735': 3041, '3736': 3042, '3737': 3043, '3738': 3044, '3739': 3045, '3740': 3047, '3741': 3048, '3742': 3049, '3743': 3050, '3744': 3051, '3745': 3052, '3746': 3053, '3747': 3054, '3748': 3055, '3749': 3056, '3750': 3058, '3751': 3059, '3752': 3060, '3753': 3061, '3754': 3062, '3755': 3063, '3756': 3064, '3757': 3065, '3758': 3066, '3759': 3067, '3760': 3069, '3761': 3070, '3762': 3071, '3763': 3072, '3764': 3073, '3765': 3074, '3766': 3075, '3767': 3076, '3768': 3077, '3769': 3078, '3770': 3080, '3771': 3081, '3772': 3082, '3773': 3083, '3774': 3084, '3775': 3085, '3776': 3086, '3777': 3087, '3778': 3088, '3779': 3089, '3780': 3091, '3781': 3092, '3782': 3093, '3783': 3094, '3784': 3095, '3785': 3096, '3786': 3097, '3787': 3098, '3788': 3099, '3789': 3100, '3790': 3102, '3791': 3103, '3792': 3104, '3793': 3105, '3794': 3106, '3795': 3107, '3796': 3108, '3797': 3109, '3798': 3110, '3799': 3111, '3800': 3114, '3801': 3115, '3802': 3116, '3803': 3117, '3804': 3118, '3805': 3119, '3806': 3120, '3807': 3121, '3808': 3122, '3809': 3123, '3810': 3125, '3811': 3126, '3812': 3127, '3813': 3128, '3814': 3129, '3815': 3130, '3816': 3131, '3817': 3132, '3818': 3133, '3819': 3134, '3820': 3136, '3821': 3137, '3822': 3138, '3823': 3139, '3824': 3140, '3825': 3141, '3826': 3142, '3827': 3143, '3828': 3144, '3829': 3145, '3830': 3147, '3831': 3148, '3832': 3149, '3833': 3150, '3834': 3151, '3835': 3152, '3836': 3153, '3837': 3154, '3838': 3155, '3839': 3156, '3840': 3158, '3841': 3159, '3842': 3160, '3843': 3161, '3844': 3162, '3845': 3163, '3846': 3164, '3847': 3165, '3848': 3166, '3849': 3167, '3850': 3169, '3851': 3170, '3852': 3171, '3853': 3172, '3854': 3173, '3855': 3174, '3856': 3175, '3857': 3176, '3858': 3177, '3859': 3178, '3860': 3180, '3861': 3181, '3862': 3182, '3863': 3183, '3864': 3184, '3865': 3185, '3866': 3186, '3867': 3187, '3868': 3188, '3869': 3189, '3870': 3191, '3871': 3192, '3872': 3193, '3873': 3194, '3874': 3195, '3875': 3196, '3876': 3197, '3877': 3198, '3878': 3199, '3879': 3200, '3880': 3202, '3881': 3203, '3882': 3204, '3883': 3205, '3884': 3206, '3885': 3207, '3886': 3208, '3887': 3209, '3888': 3210, '3889': 3211, '3890': 3213, '3891': 3214, '3892': 3215, '3893': 3216, '3894': 3217, '3895': 3218, '3896': 3219, '3897': 3220, '3898': 3221, '3899': 3222, '3900': 3225, '3901': 3226, '3902': 3227, '3903': 3228, '3904': 3229, '3905': 3230, '3906': 3231, '3907': 3232, '3908': 3233, '3909': 3234, '3910': 3236, '3911': 3237, '3912': 3238, '3913': 3239, '3914': 3240, '3915': 3241, '3916': 3242, '3917': 3243, '3918': 3244, '3919': 3245, '3920': 3247, '3921': 3248, '3922': 3249, '3923': 3250, '3924': 3251, '3925': 3252, '3926': 3253, '3927': 3254, '3928': 3255, '3929': 3256, '3930': 3258, '3931': 3259, '3932': 3260, '3933': 3261, '3934': 3262, '3935': 3263, '3936': 3264, '3937': 3265, '3938': 3266, '3939': 3267, '3940': 3269, '3941': 3270, '3942': 3271, '3943': 3272, '3944': 3273, '3945': 3274, '3946': 3275, '3947': 3276, '3948': 3277, '3949': 3278, '3950': 3280, '3951': 3281, '3952': 3282, '3953': 3283, '3954': 3284, '3955': 3285, '3956': 3286, '3957': 3287, '3958': 3288, '3959': 3289, '3960': 3291, '3961': 3292, '3962': 3293, '3963': 3294, '3964': 3295, '3965': 3296, '3966': 3297, '3967': 3298, '3968': 3299, '3969': 3300, '3970': 3302, '3971': 3303, '3972': 3304, '3973': 3305, '3974': 3306, '3975': 3307, '3976': 3308, '3977': 3309, '3978': 3310, '3979': 3311, '3980': 3313, '3981': 3314, '3982': 3315, '3983': 3316, '3984': 3317, '3985': 3318, '3986': 3319, '3987': 3320, '3988': 3321, '3989': 3322, '3990': 3324, '3991': 3325, '3992': 3326, '3993': 3327, '3994': 3328, '3995': 3329, '3996': 3330, '3997': 3331, '3998': 3332, '3999': 3333, '4000': 3337, '4001': 3338, '4002': 3339, '4003': 3340, '4004': 3341, '4005': 3342, '4006': 3343, '4007': 3344, '4008': 3345, '4009': 3346, '4010': 3348, '4011': 3349, '4012': 3350, '4013': 3351, '4014': 3352, '4015': 3353, '4016': 3354, '4017': 3355, '4018': 3356, '4019': 3357, '4020': 3359, '4021': 3360, '4022': 3361, '4023': 3362, '4024': 3363, '4025': 3364, '4026': 3365, '4027': 3366, '4028': 3367, '4029': 3368, '4030': 3370, '4031': 3371, '4032': 3372, '4033': 3373, '4034': 3374, '4035': 3375, '4036': 3376, '4037': 3377, '4038': 3378, '4039': 3379, '4040': 3381, '4041': 3382, '4042': 3383, '4043': 3384, '4044': 3385, '4045': 3386, '4046': 3387, '4047': 3388, '4048': 3389, '4049': 3390, '4050': 3392, '4051': 3393, '4052': 3394, '4053': 3395, '4054': 3396, '4055': 3397, '4056': 3398, '4057': 3399, '4058': 3400, '4059': 3401, '4060': 3403, '4061': 3404, '4062': 3405, '4063': 3406, '4064': 3407, '4065': 3408, '4066': 3409, '4067': 3410, '4068': 3411, '4069': 3412, '4070': 3414, '4071': 3415, '4072': 3416, '4073': 3417, '4074': 3418, '4075': 3419, '4076': 3420, '4077': 3421, '4078': 3422, '4079': 3423, '4080': 3425, '4081': 3426, '4082': 3427, '4083': 3428, '4084': 3429, '4085': 3430, '4086': 3431, '4087': 3432, '4088': 3433, '4089': 3434, '4090': 3436, '4091': 3437, '4092': 3438, '4093': 3439, '4094': 3440, '4095': 3441, '4096': 3442, '4097': 3443, '4098': 3444, '4099': 3445, '4100': 3448, '4101': 3449, '4102': 3450, '4103': 3451, '4104': 3452, '4105': 3453, '4106': 3454, '4107': 3455, '4108': 3456, '4109': 3457, '4110': 3459, '4111': 3460, '4112': 3461, '4113': 3462, '4114': 3463, '4115': 3464, '4116': 3465, '4117': 3466, '4118': 3467, '4119': 3468, '4120': 3470, '4121': 3471, '4122': 3472, '4123': 3473, '4124': 3474, '4125': 3475, '4126': 3476, '4127': 3477, '4128': 3478, '4129': 3479, '4130': 3481, '4131': 3482, '4132': 3483, '4133': 3484, '4134': 3485, '4135': 3486, '4136': 3487, '4137': 3488, '4138': 3489, '4139': 3490, '4140': 3492, '4141': 3493, '4142': 3494, '4143': 3495, '4144': 3496, '4145': 3497, '4146': 3498, '4147': 3499, '4148': 3500, '4149': 3501, '4150': 3503, '4151': 3504, '4152': 3505, '4153': 3506, '4154': 3507, '4155': 3508, '4156': 3509, '4157': 3510, '4158': 3511, '4159': 3512, '4160': 3514, '4161': 3515, '4162': 3516, '4163': 3517, '4164': 3518, '4165': 3519, '4166': 3520, '4167': 3521, '4168': 3522, '4169': 3523, '4170': 3525, '4171': 3526, '4172': 3527, '4173': 3528, '4174': 3529, '4175': 3530, '4176': 3531, '4177': 3532, '4178': 3533, '4179': 3534, '4180': 3536, '4181': 3537, '4182': 3538, '4183': 3539, '4184': 3540, '4185': 3541, '4186': 3542, '4187': 3543, '4188': 3544, '4189': 3545, '4190': 3547, '4191': 3548, '4192': 3549, '4193': 3550, '4194': 3551, '4195': 3552, '4196': 3553, '4197': 3554, '4198': 3555, '4199': 3556, '4200': 3559, '4201': 3560, '4202': 3561, '4203': 3562, '4204': 3563, '4205': 3564, '4206': 3565, '4207': 3566, '4208': 3567, '4209': 3568, '4210': 3570, '4211': 3571, '4212': 3572, '4213': 3573, '4214': 3574, '4215': 3575, '4216': 3576, '4217': 3577, '4218': 3578, '4219': 3579, '4220': 3581, '4221': 3582, '4222': 3583, '4223': 3584, '4224': 3585, '4225': 3586, '4226': 3587, '4227': 3588, '4228': 3589, '4229': 3590, '4230': 3592, '4231': 3593, '4232': 3594, '4233': 3595, '4234': 3596, '4235': 3597, '4236': 3598, '4237': 3599, '4238': 3600, '4239': 3601, '4240': 3603, '4241': 3604, '4242': 3605, '4243': 3606, '4244': 3607, '4245': 3608, '4246': 3609, '4247': 3610, '4248': 3611, '4249': 3612, '4250': 3614, '4251': 3615, '4252': 3616, '4253': 3617, '4254': 3618, '4255': 3619, '4256': 3620, '4257': 3621, '4258': 3622, '4259': 3623, '4260': 3625, '4261': 3626, '4262': 3627, '4263': 3628, '4264': 3629, '4265': 3630, '4266': 3631, '4267': 3632, '4268': 3633, '4269': 3634, '4270': 3636, '4271': 3637, '4272': 3638, '4273': 3639, '4274': 3640, '4275': 3641, '4276': 3642, '4277': 3643, '4278': 3644, '4279': 3645, '4280': 3647, '4281': 3648, '4282': 3649, '4283': 3650, '4284': 3651, '4285': 3652, '4286': 3653, '4287': 3654, '4288': 3655, '4289': 3656, '4290': 3658, '4291': 3659, '4292': 3660, '4293': 3661, '4294': 3662, '4295': 3663, '4296': 3664, '4297': 3665, '4298': 3666, '4299': 3667, '4300': 3670, '4301': 3671, '4302': 3672, '4303': 3673, '4304': 3674, '4305': 3675, '4306': 3676, '4307': 3677, '4308': 3678, '4309': 3679, '4310': 3681, '4311': 3682, '4312': 3683, '4313': 3684, '4314': 3685, '4315': 3686, '4316': 3687, '4317': 3688, '4318': 3689, '4319': 3690, '4320': 3692, '4321': 3693, '4322': 3694, '4323': 3695, '4324': 3696, '4325': 3697, '4326': 3698, '4327': 3699, '4328': 3700, '4329': 3701, '4330': 3703, '4331': 3704, '4332': 3705, '4333': 3706, '4334': 3707, '4335': 3708, '4336': 3709, '4337': 3710, '4338': 3711, '4339': 3712, '4340': 3714, '4341': 3715, '4342': 3716, '4343': 3717, '4344': 3718, '4345': 3719, '4346': 3720, '4347': 3721, '4348': 3722, '4349': 3723, '4350': 3725, '4351': 3726, '4352': 3727, '4353': 3728, '4354': 3729, '4355': 3730, '4356': 3731, '4357': 3732, '4358': 3733, '4359': 3734, '4360': 3736, '4361': 3737, '4362': 3738, '4363': 3739, '4364': 3740, '4365': 3741, '4366': 3742, '4367': 3743, '4368': 3744, '4369': 3745, '4370': 3747, '4371': 3748, '4372': 3749, '4373': 3750, '4374': 3751, '4375': 3752, '4376': 3753, '4377': 3754, '4378': 3755, '4379': 3756, '4380': 3758, '4381': 3759, '4382': 3760, '4383': 3761, '4384': 3762, '4385': 3763, '4386': 3764, '4387': 3765, '4388': 3766, '4389': 3767, '4390': 3769, '4391': 3770, '4392': 3771, '4393': 3772, '4394': 3773, '4395': 3774, '4396': 3775, '4397': 3776, '4398': 3777, '4399': 3778, '4400': 3781, '4401': 3782, '4402': 3783, '4403': 3784, '4404': 3785, '4405': 3786, '4406': 3787, '4407': 3788, '4408': 3789, '4409': 3790, '4410': 3792, '4411': 3793, '4412': 3794, '4413': 3795, '4414': 3796, '4415': 3797, '4416': 3798, '4417': 3799, '4418': 3800, '4419': 3801, '4420': 3803, '4421': 3804, '4422': 3805, '4423': 3806, '4424': 3807, '4425': 3808, '4426': 3809, '4427': 3810, '4428': 3811, '4429': 3812, '4430': 3814, '4431': 3815, '4432': 3816, '4433': 3817, '4434': 3818, '4435': 3819, '4436': 3820, '4437': 3821, '4438': 3822, '4439': 3823, '4440': 3825, '4441': 3826, '4442': 3827, '4443': 3828, '4444': 3829, '4445': 3830, '4446': 3831, '4447': 3832, '4448': 3833, '4449': 3834, '4450': 3836, '4451': 3837, '4452': 3838, '4453': 3839, '4454': 3840, '4455': 3841, '4456': 3842, '4457': 3843, '4458': 3844, '4459': 3845, '4460': 3847, '4461': 3848, '4462': 3849, '4463': 3850, '4464': 3851, '4465': 3852, '4466': 3853, '4467': 3854, '4468': 3855, '4469': 3856, '4470': 3858, '4471': 3859, '4472': 3860, '4473': 3861, '4474': 3862, '4475': 3863, '4476': 3864, '4477': 3865, '4478': 3866, '4479': 3867, '4480': 3869, '4481': 3870, '4482': 3871, '4483': 3872, '4484': 3873, '4485': 3874, '4486': 3875, '4487': 3876, '4488': 3877, '4489': 3878, '4490': 3880, '4491': 3881, '4492': 3882, '4493': 3883, '4494': 3884, '4495': 3885, '4496': 3886, '4497': 3887, '4498': 3888, '4499': 3889, '4500': 3892, '4501': 3893, '4502': 3894, '4503': 3895, '4504': 3896, '4505': 3897, '4506': 3898, '4507': 3899, '4508': 3900, '4509': 3901, '4510': 3903, '4511': 3904, '4512': 3905, '4513': 3906, '4514': 3907, '4515': 3908, '4516': 3909, '4517': 3910, '4518': 3911, '4519': 3912, '4520': 3914, '4521': 3915, '4522': 3916, '4523': 3917, '4524': 3918, '4525': 3919, '4526': 3920, '4527': 3921, '4528': 3922, '4529': 3923, '4530': 3925, '4531': 3926, '4532': 3927, '4533': 3928, '4534': 3929, '4535': 3930, '4536': 3931, '4537': 3932, '4538': 3933, '4539': 3934, '4540': 3936, '4541': 3937, '4542': 3938, '4543': 3939, '4544': 3940, '4545': 3941, '4546': 3942, '4547': 3943, '4548': 3944, '4549': 3945, '4550': 3947, '4551': 3948, '4552': 3949, '4553': 3950, '4554': 3951, '4555': 3952, '4556': 3953, '4557': 3954, '4558': 3955, '4559': 3956, '4560': 3958, '4561': 3959, '4562': 3960, '4563': 3961, '4564': 3962, '4565': 3963, '4566': 3964, '4567': 3965, '4568': 3966, '4569': 3967, '4570': 3969, '4571': 3970, '4572': 3971, '4573': 3972, '4574': 3973, '4575': 3974, '4576': 3975, '4577': 3976, '4578': 3977, '4579': 3978, '4580': 3980, '4581': 3981, '4582': 3982, '4583': 3983, '4584': 3984, '4585': 3985, '4586': 3986, '4587': 3987, '4588': 3988, '4589': 3989, '4590': 3991, '4591': 3992, '4592': 3993, '4593': 3994, '4594': 3995, '4595': 3996, '4596': 3997, '4597': 3998, '4598': 3999, '4599': 4000, '4600': 4003, '4601': 4004, '4602': 4005, '4603': 4006, '4604': 4007, '4605': 4008, '4606': 4009, '4607': 4010, '4608': 4011, '4609': 4012, '4610': 4014, '4611': 4015, '4612': 4016, '4613': 4017, '4614': 4018, '4615': 4019, '4616': 4020, '4617': 4021, '4618': 4022, '4619': 4023, '4620': 4025, '4621': 4026, '4622': 4027, '4623': 4028, '4624': 4029, '4625': 4030, '4626': 4031, '4627': 4032, '4628': 4033, '4629': 4034, '4630': 4036, '4631': 4037, '4632': 4038, '4633': 4039, '4634': 4040, '4635': 4041, '4636': 4042, '4637': 4043, '4638': 4044, '4639': 4045, '4640': 4047, '4641': 4048, '4642': 4049, '4643': 4050, '4644': 4051, '4645': 4052, '4646': 4053, '4647': 4054, '4648': 4055, '4649': 4056, '4650': 4058, '4651': 4059, '4652': 4060, '4653': 4061, '4654': 4062, '4655': 4063, '4656': 4064, '4657': 4065, '4658': 4066, '4659': 4067, '4660': 4069, '4661': 4070, '4662': 4071, '4663': 4072, '4664': 4073, '4665': 4074, '4666': 4075, '4667': 4076, '4668': 4077, '4669': 4078, '4670': 4080, '4671': 4081, '4672': 4082, '4673': 4083, '4674': 4084, '4675': 4085, '4676': 4086, '4677': 4087, '4678': 4088, '4679': 4089, '4680': 4091, '4681': 4092, '4682': 4093, '4683': 4094, '4684': 4095, '4685': 4096, '4686': 4097, '4687': 4098, '4688': 4099, '4689': 4100, '4690': 4102, '4691': 4103, '4692': 4104, '4693': 4105, '4694': 4106, '4695': 4107, '4696': 4108, '4697': 4109, '4698': 4110, '4699': 4111, '4700': 4114, '4701': 4115, '4702': 4116, '4703': 4117, '4704': 4118, '4705': 4119, '4706': 4120, '4707': 4121, '4708': 4122, '4709': 4123, '4710': 4125, '4711': 4126, '4712': 4127, '4713': 4128, '4714': 4129, '4715': 4130, '4716': 4131, '4717': 4132, '4718': 4133, '4719': 4134, '4720': 4136, '4721': 4137, '4722': 4138, '4723': 4139, '4724': 4140, '4725': 4141, '4726': 4142, '4727': 4143, '4728': 4144, '4729': 4145, '4730': 4147, '4731': 4148, '4732': 4149, '4733': 4150, '4734': 4151, '4735': 4152, '4736': 4153, '4737': 4154, '4738': 4155, '4739': 4156, '4740': 4158, '4741': 4159, '4742': 4160, '4743': 4161, '4744': 4162, '4745': 4163, '4746': 4164, '4747': 4165, '4748': 4166, '4749': 4167, '4750': 4169, '4751': 4170, '4752': 4171, '4753': 4172, '4754': 4173, '4755': 4174, '4756': 4175, '4757': 4176, '4758': 4177, '4759': 4178, '4760': 4180, '4761': 4181, '4762': 4182, '4763': 4183, '4764': 4184, '4765': 4185, '4766': 4186, '4767': 4187, '4768': 4188, '4769': 4189, '4770': 4191, '4771': 4192, '4772': 4193, '4773': 4194, '4774': 4195, '4775': 4196, '4776': 4197, '4777': 4198, '4778': 4199, '4779': 4200, '4780': 4202, '4781': 4203, '4782': 4204, '4783': 4205, '4784': 4206, '4785': 4207, '4786': 4208, '4787': 4209, '4788': 4210, '4789': 4211, '4790': 4213, '4791': 4214, '4792': 4215, '4793': 4216, '4794': 4217, '4795': 4218, '4796': 4219, '4797': 4220, '4798': 4221, '4799': 4222, '4800': 4225, '4801': 4226, '4802': 4227, '4803': 4228, '4804': 4229, '4805': 4230, '4806': 4231, '4807': 4232, '4808': 4233, '4809': 4234, '4810': 4236, '4811': 4237, '4812': 4238, '4813': 4239, '4814': 4240, '4815': 4241, '4816': 4242, '4817': 4243, '4818': 4244, '4819': 4245, '4820': 4247, '4821': 4248, '4822': 4249, '4823': 4250, '4824': 4251, '4825': 4252, '4826': 4253, '4827': 4254, '4828': 4255, '4829': 4256, '4830': 4258, '4831': 4259, '4832': 4260, '4833': 4261, '4834': 4262, '4835': 4263, '4836': 4264, '4837': 4265, '4838': 4266, '4839': 4267, '4840': 4269, '4841': 4270, '4842': 4271, '4843': 4272, '4844': 4273, '4845': 4274, '4846': 4275, '4847': 4276, '4848': 4277, '4849': 4278, '4850': 4280, '4851': 4281, '4852': 4282, '4853': 4283, '4854': 4284, '4855': 4285, '4856': 4286, '4857': 4287, '4858': 4288, '4859': 4289, '4860': 4291, '4861': 4292, '4862': 4293, '4863': 4294, '4864': 4295, '4865': 4296, '4866': 4297, '4867': 4298, '4868': 4299, '4869': 4300, '4870': 4302, '4871': 4303, '4872': 4304, '4873': 4305, '4874': 4306, '4875': 4307, '4876': 4308, '4877': 4309, '4878': 4310, '4879': 4311, '4880': 4313, '4881': 4314, '4882': 4315, '4883': 4316, '4884': 4317, '4885': 4318, '4886': 4319, '4887': 4320, '4888': 4321, '4889': 4322, '4890': 4324, '4891': 4325, '4892': 4326, '4893': 4327, '4894': 4328, '4895': 4329, '4896': 4330, '4897': 4331, '4898': 4332, '4899': 4333, '4900': 4336, '4901': 4337, '4902': 4338, '4903': 4339, '4904': 4340, '4905': 4341, '4906': 4342, '4907': 4343, '4908': 4344, '4909': 4345, '4910': 4347, '4911': 4348, '4912': 4349, '4913': 4350, '4914': 4351, '4915': 4352, '4916': 4353, '4917': 4354, '4918': 4355, '4919': 4356, '4920': 4358, '4921': 4359, '4922': 4360, '4923': 4361, '4924': 4362, '4925': 4363, '4926': 4364, '4927': 4365, '4928': 4366, '4929': 4367, '4930': 4369, '4931': 4370, '4932': 4371, '4933': 4372, '4934': 4373, '4935': 4374, '4936': 4375, '4937': 4376, '4938': 4377, '4939': 4378, '4940': 4380, '4941': 4381, '4942': 4382, '4943': 4383, '4944': 4384, '4945': 4385, '4946': 4386, '4947': 4387, '4948': 4388, '4949': 4389, '4950': 4391, '4951': 4392, '4952': 4393, '4953': 4394, '4954': 4395, '4955': 4396, '4956': 4397, '4957': 4398, '4958': 4399, '4959': 4400, '4960': 4402, '4961': 4403, '4962': 4404, '4963': 4405, '4964': 4406, '4965': 4407, '4966': 4408, '4967': 4409, '4968': 4410, '4969': 4411, '4970': 4413, '4971': 4414, '4972': 4415, '4973': 4416, '4974': 4417, '4975': 4418, '4976': 4419, '4977': 4420, '4978': 4421, '4979': 4422, '4980': 4424, '4981': 4425, '4982': 4426, '4983': 4427, '4984': 4428, '4985': 4429, '4986': 4430, '4987': 4431, '4988': 4432, '4989': 4433, '4990': 4435, '4991': 4436, '4992': 4437, '4993': 4438, '4994': 4439, '4995': 4440, '4996': 4441, '4997': 4442, '4998': 4443, '4999': 4444}\n",
      "Encoded Document is:\n",
      "[[ 3  5  1 ...  0  0  0]\n",
      " [ 4  4  2 ...  0  0  0]\n",
      " [84 25  5 ...  0  0  0]\n",
      " ...\n",
      " [ 3  5  2 ...  3  0  0]\n",
      " [ 0  5  3 ...  0  0  0]\n",
      " [ 2  5  4 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "vector_sample = np.arange(5000)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def toStr(n):\n",
    "   return str(n)\n",
    "\n",
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer(preprocessor= toStr, analyzer=\"word\", token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "vectorizer.fit(vector_sample)\n",
    "\n",
    "# Printing the identified Unique words along with their indices\n",
    "print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "\n",
    "# Encode the Document\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "# Summarizing the Encoded Texts\n",
    "print(\"Encoded Document is:\")\n",
    "print(vector.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (14900, 5000)\n",
      "Shape of y: (14900,)\n"
     ]
    }
   ],
   "source": [
    "X = vector.toarray()\n",
    "y = np.array(label).ravel()\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/119], Loss: 0.6882\n",
      "Epoch [1/10], Step [101/119], Loss: 0.6265\n",
      "Epoch [1/10], Step [201/119], Loss: 0.5535\n",
      "Epoch [1/10], Step [301/119], Loss: 0.6742\n",
      "Epoch [1/10], Step [401/119], Loss: 0.5512\n",
      "Epoch [1/10], Step [501/119], Loss: 0.4626\n",
      "Epoch [1/10], Step [601/119], Loss: 0.6897\n",
      "Epoch [1/10], Step [701/119], Loss: 0.4012\n",
      "Epoch [1/10], Step [801/119], Loss: 0.4517\n",
      "Epoch [1/10], Step [901/119], Loss: 0.6092\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.4886\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.4655\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.4427\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.4984\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.5647\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.4409\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.3672\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.4381\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.4583\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.4794\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.4815\n",
      "Epoch [1/10], Step [2101/119], Loss: 0.3732\n",
      "Epoch [1/10], Step [2201/119], Loss: 0.3386\n",
      "Epoch [1/10], Step [2301/119], Loss: 0.3344\n",
      "Epoch [1/10], Step [2401/119], Loss: 0.4273\n",
      "Epoch [1/10], Step [2501/119], Loss: 0.4334\n",
      "Epoch [1/10], Step [2601/119], Loss: 0.3884\n",
      "Epoch [1/10], Step [2701/119], Loss: 0.4125\n",
      "Epoch [1/10], Step [2801/119], Loss: 0.6136\n",
      "Epoch [1/10], Step [2901/119], Loss: 0.3543\n",
      "Epoch [1/10], Step [3001/119], Loss: 0.5082\n",
      "Epoch [1/10], Step [3101/119], Loss: 0.4373\n",
      "Epoch [1/10], Step [3201/119], Loss: 0.4711\n",
      "Epoch [1/10], Step [3301/119], Loss: 0.3727\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.5003\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.4547\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.4821\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.4285\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.3917\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.4052\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.3842\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.3717\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.4791\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.4324\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.4214\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.2632\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.4033\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.4552\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.4896\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.4041\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.3533\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.3356\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.4170\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.3709\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.3133\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.4804\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.3833\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.3724\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.4464\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.3708\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.3587\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.4183\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.4623\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.4895\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.4213\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.4502\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.4888\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.3814\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.4262\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.3466\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.3726\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.5252\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.4151\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.4466\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.3233\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.2304\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.3330\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.4000\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.3787\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.4100\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.4713\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.4276\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.4580\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.3736\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.3352\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.4016\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.4171\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.3994\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.3228\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.2953\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.3691\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.3126\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.4090\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.2838\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.3689\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.4086\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.5091\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.4525\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.4383\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.4678\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.4016\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.4565\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.3982\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.3541\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.4156\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.4852\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.3869\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.3833\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.2880\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.4120\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.3585\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.3242\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.3563\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.4540\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.4821\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.3723\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.3470\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.4010\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.3233\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.5318\n",
      "Epoch [2/10], Step [1/119], Loss: 0.3611\n",
      "Epoch [2/10], Step [101/119], Loss: 0.4029\n",
      "Epoch [2/10], Step [201/119], Loss: 0.3530\n",
      "Epoch [2/10], Step [301/119], Loss: 0.3712\n",
      "Epoch [2/10], Step [401/119], Loss: 0.3327\n",
      "Epoch [2/10], Step [501/119], Loss: 0.3110\n",
      "Epoch [2/10], Step [601/119], Loss: 0.3954\n",
      "Epoch [2/10], Step [701/119], Loss: 0.2740\n",
      "Epoch [2/10], Step [801/119], Loss: 0.3395\n",
      "Epoch [2/10], Step [901/119], Loss: 0.3694\n",
      "Epoch [2/10], Step [1001/119], Loss: 0.2810\n",
      "Epoch [2/10], Step [1101/119], Loss: 0.3432\n",
      "Epoch [2/10], Step [1201/119], Loss: 0.2822\n",
      "Epoch [2/10], Step [1301/119], Loss: 0.3012\n",
      "Epoch [2/10], Step [1401/119], Loss: 0.4161\n",
      "Epoch [2/10], Step [1501/119], Loss: 0.3544\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.2381\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.3534\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.3507\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.3610\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.3663\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.2717\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.2647\n",
      "Epoch [2/10], Step [2301/119], Loss: 0.2570\n",
      "Epoch [2/10], Step [2401/119], Loss: 0.3055\n",
      "Epoch [2/10], Step [2501/119], Loss: 0.3799\n",
      "Epoch [2/10], Step [2601/119], Loss: 0.3096\n",
      "Epoch [2/10], Step [2701/119], Loss: 0.3059\n",
      "Epoch [2/10], Step [2801/119], Loss: 0.4467\n",
      "Epoch [2/10], Step [2901/119], Loss: 0.2881\n",
      "Epoch [2/10], Step [3001/119], Loss: 0.3468\n",
      "Epoch [2/10], Step [3101/119], Loss: 0.3996\n",
      "Epoch [2/10], Step [3201/119], Loss: 0.3367\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.3154\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.4434\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.4128\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.4183\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.3646\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.3185\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.3287\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.3187\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.2856\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.4253\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.3409\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.3455\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.2092\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.3573\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.3181\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.4123\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.3810\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.3380\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.2644\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.3375\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.2989\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.2372\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.4540\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.3360\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.2926\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.3637\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.3111\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.2788\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.3353\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.4034\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.3388\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.3766\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.3323\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.4353\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.3370\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.3484\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.3185\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.3158\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.4985\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.3157\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.3800\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.2582\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.1751\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.2577\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.3539\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.3207\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.3531\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.3836\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.3458\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.3427\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.2757\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.2804\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.3028\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.3414\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.3466\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.2741\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.2221\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.3052\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.2549\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.3575\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.2522\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.2626\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.3495\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.4627\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.3595\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.3320\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.3424\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.3117\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.3687\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.3530\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.2865\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.3347\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.4364\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.3436\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.3385\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.2606\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.3426\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.3317\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.3224\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.3064\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.3922\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.4262\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.3055\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.3236\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.3523\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.2823\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.4393\n",
      "Epoch [3/10], Step [1/119], Loss: 0.2953\n",
      "Epoch [3/10], Step [101/119], Loss: 0.3635\n",
      "Epoch [3/10], Step [201/119], Loss: 0.2980\n",
      "Epoch [3/10], Step [301/119], Loss: 0.2994\n",
      "Epoch [3/10], Step [401/119], Loss: 0.2773\n",
      "Epoch [3/10], Step [501/119], Loss: 0.2713\n",
      "Epoch [3/10], Step [601/119], Loss: 0.3507\n",
      "Epoch [3/10], Step [701/119], Loss: 0.2105\n",
      "Epoch [3/10], Step [801/119], Loss: 0.2905\n",
      "Epoch [3/10], Step [901/119], Loss: 0.3624\n",
      "Epoch [3/10], Step [1001/119], Loss: 0.2479\n",
      "Epoch [3/10], Step [1101/119], Loss: 0.2933\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.2146\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.2628\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.3349\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.2742\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.2281\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.3237\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.2927\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.2781\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.3251\n",
      "Epoch [3/10], Step [2101/119], Loss: 0.2141\n",
      "Epoch [3/10], Step [2201/119], Loss: 0.2382\n",
      "Epoch [3/10], Step [2301/119], Loss: 0.2047\n",
      "Epoch [3/10], Step [2401/119], Loss: 0.2990\n",
      "Epoch [3/10], Step [2501/119], Loss: 0.3795\n",
      "Epoch [3/10], Step [2601/119], Loss: 0.2615\n",
      "Epoch [3/10], Step [2701/119], Loss: 0.2890\n",
      "Epoch [3/10], Step [2801/119], Loss: 0.3424\n",
      "Epoch [3/10], Step [2901/119], Loss: 0.2718\n",
      "Epoch [3/10], Step [3001/119], Loss: 0.2684\n",
      "Epoch [3/10], Step [3101/119], Loss: 0.3423\n",
      "Epoch [3/10], Step [3201/119], Loss: 0.2943\n",
      "Epoch [3/10], Step [3301/119], Loss: 0.2077\n",
      "Epoch [3/10], Step [3401/119], Loss: 0.3572\n",
      "Epoch [3/10], Step [3501/119], Loss: 0.3546\n",
      "Epoch [3/10], Step [3601/119], Loss: 0.3697\n",
      "Epoch [3/10], Step [3701/119], Loss: 0.3155\n",
      "Epoch [3/10], Step [3801/119], Loss: 0.2613\n",
      "Epoch [3/10], Step [3901/119], Loss: 0.3147\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.2880\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.2524\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.3440\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.2632\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.2782\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.1914\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.3393\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.2448\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.3902\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.3745\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.2885\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.2462\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.2497\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.2946\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.1841\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.4258\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.2656\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.2416\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.2939\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.2275\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.2199\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.2921\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.3036\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.2545\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.3086\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.2638\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.3522\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.2419\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.2667\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.2732\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.2383\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.3767\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.2498\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.2916\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.2037\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.1385\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.1751\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.2538\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.2582\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.2790\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.3106\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.2804\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.2822\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.2242\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.2304\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.2433\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.2734\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.3266\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.2214\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.1965\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.2487\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.2164\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.2692\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.2243\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.2176\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.2667\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.3545\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.2848\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.2879\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.2671\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.2472\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.3150\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.3670\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.2349\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.2618\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.3299\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.3474\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.3180\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.2034\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.2963\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.2822\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.2768\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.2807\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.3061\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.3067\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.3036\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.2811\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.3179\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.2142\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.3347\n",
      "Epoch [4/10], Step [1/119], Loss: 0.2279\n",
      "Epoch [4/10], Step [101/119], Loss: 0.3508\n",
      "Epoch [4/10], Step [201/119], Loss: 0.2984\n",
      "Epoch [4/10], Step [301/119], Loss: 0.2550\n",
      "Epoch [4/10], Step [401/119], Loss: 0.2208\n",
      "Epoch [4/10], Step [501/119], Loss: 0.2893\n",
      "Epoch [4/10], Step [601/119], Loss: 0.2941\n",
      "Epoch [4/10], Step [701/119], Loss: 0.1950\n",
      "Epoch [4/10], Step [801/119], Loss: 0.2870\n",
      "Epoch [4/10], Step [901/119], Loss: 0.2791\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.1925\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.2392\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.1452\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.2523\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.3547\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.2340\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.2209\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.2890\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.2391\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.2205\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.2088\n",
      "Epoch [4/10], Step [2101/119], Loss: 0.1775\n",
      "Epoch [4/10], Step [2201/119], Loss: 0.1971\n",
      "Epoch [4/10], Step [2301/119], Loss: 0.1556\n",
      "Epoch [4/10], Step [2401/119], Loss: 0.2562\n",
      "Epoch [4/10], Step [2501/119], Loss: 0.2868\n",
      "Epoch [4/10], Step [2601/119], Loss: 0.2042\n",
      "Epoch [4/10], Step [2701/119], Loss: 0.2299\n",
      "Epoch [4/10], Step [2801/119], Loss: 0.2936\n",
      "Epoch [4/10], Step [2901/119], Loss: 0.2180\n",
      "Epoch [4/10], Step [3001/119], Loss: 0.2298\n",
      "Epoch [4/10], Step [3101/119], Loss: 0.3018\n",
      "Epoch [4/10], Step [3201/119], Loss: 0.2384\n",
      "Epoch [4/10], Step [3301/119], Loss: 0.1808\n",
      "Epoch [4/10], Step [3401/119], Loss: 0.2775\n",
      "Epoch [4/10], Step [3501/119], Loss: 0.2896\n",
      "Epoch [4/10], Step [3601/119], Loss: 0.3150\n",
      "Epoch [4/10], Step [3701/119], Loss: 0.2766\n",
      "Epoch [4/10], Step [3801/119], Loss: 0.2313\n",
      "Epoch [4/10], Step [3901/119], Loss: 0.2148\n",
      "Epoch [4/10], Step [4001/119], Loss: 0.2202\n",
      "Epoch [4/10], Step [4101/119], Loss: 0.2025\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.2963\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.2613\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.2288\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.1513\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.2784\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.1912\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.2712\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.2310\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.2239\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.1765\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.1894\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.2533\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.1674\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.3003\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.2369\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.1656\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.2364\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.1861\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.1685\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.2299\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.2252\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.1581\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.2512\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.1716\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.3049\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.1880\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.1884\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.2319\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.2300\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.3230\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.2301\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.2393\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.1767\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.1605\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.1519\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.2266\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.1782\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.2627\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.2831\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.2084\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.2498\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.1870\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.2055\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.1543\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.1905\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.2161\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.1823\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.1472\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.1817\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.1839\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.2185\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.1871\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.1541\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.2162\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.3120\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.2039\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.1577\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.2134\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.2234\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.2178\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.2548\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.1972\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.2705\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.2289\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.2937\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.1682\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.2063\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.2986\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.2387\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.2714\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.2141\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.2832\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.2306\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.3578\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.3165\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.3421\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.1487\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.2574\n",
      "Epoch [5/10], Step [1/119], Loss: 0.3133\n",
      "Epoch [5/10], Step [101/119], Loss: 0.4355\n",
      "Epoch [5/10], Step [201/119], Loss: 0.2688\n",
      "Epoch [5/10], Step [301/119], Loss: 0.2114\n",
      "Epoch [5/10], Step [401/119], Loss: 0.1737\n",
      "Epoch [5/10], Step [501/119], Loss: 0.2697\n",
      "Epoch [5/10], Step [601/119], Loss: 0.2406\n",
      "Epoch [5/10], Step [701/119], Loss: 0.2098\n",
      "Epoch [5/10], Step [801/119], Loss: 0.2999\n",
      "Epoch [5/10], Step [901/119], Loss: 0.2722\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.1805\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.2008\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.1232\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.2216\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.3714\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.2581\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.1908\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.2637\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.1992\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.2019\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.1768\n",
      "Epoch [5/10], Step [2101/119], Loss: 0.1979\n",
      "Epoch [5/10], Step [2201/119], Loss: 0.2231\n",
      "Epoch [5/10], Step [2301/119], Loss: 0.2115\n",
      "Epoch [5/10], Step [2401/119], Loss: 0.2579\n",
      "Epoch [5/10], Step [2501/119], Loss: 0.1899\n",
      "Epoch [5/10], Step [2601/119], Loss: 0.1940\n",
      "Epoch [5/10], Step [2701/119], Loss: 0.1697\n",
      "Epoch [5/10], Step [2801/119], Loss: 0.3221\n",
      "Epoch [5/10], Step [2901/119], Loss: 0.2039\n",
      "Epoch [5/10], Step [3001/119], Loss: 0.2086\n",
      "Epoch [5/10], Step [3101/119], Loss: 0.2214\n",
      "Epoch [5/10], Step [3201/119], Loss: 0.2007\n",
      "Epoch [5/10], Step [3301/119], Loss: 0.2047\n",
      "Epoch [5/10], Step [3401/119], Loss: 0.2749\n",
      "Epoch [5/10], Step [3501/119], Loss: 0.2647\n",
      "Epoch [5/10], Step [3601/119], Loss: 0.1940\n",
      "Epoch [5/10], Step [3701/119], Loss: 0.2375\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.1688\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.1549\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.1992\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.1639\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.3184\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.1963\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.1598\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.1677\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.2118\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.1830\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.2040\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.2253\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.1884\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.1604\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.3748\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.2409\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.1137\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.2358\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.2134\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.2031\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.2190\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.1599\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.1524\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.2078\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.2380\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.1345\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.2437\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.1497\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.2513\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.2041\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.1718\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.2019\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.1816\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.2008\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.1693\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.1845\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.1482\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.0882\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.1179\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.2128\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.1580\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.2276\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.2019\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.1990\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.2525\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.1488\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.1949\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.1645\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.1843\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.2184\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.1462\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.0710\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.1798\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.1799\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.1854\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.1833\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.1437\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.2430\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.2689\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.1639\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.1327\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.1924\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.1485\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.1192\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.1719\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.2262\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.1391\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.1542\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.2349\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.1399\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.1954\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.1471\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.1562\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.1701\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.1498\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.3674\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.4062\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.1755\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.2376\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.3666\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.3210\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0796\n",
      "Epoch [6/10], Step [1/119], Loss: 0.1839\n",
      "Epoch [6/10], Step [101/119], Loss: 0.1701\n",
      "Epoch [6/10], Step [201/119], Loss: 0.1990\n",
      "Epoch [6/10], Step [301/119], Loss: 0.1384\n",
      "Epoch [6/10], Step [401/119], Loss: 0.1842\n",
      "Epoch [6/10], Step [501/119], Loss: 0.2498\n",
      "Epoch [6/10], Step [601/119], Loss: 0.2842\n",
      "Epoch [6/10], Step [701/119], Loss: 0.1478\n",
      "Epoch [6/10], Step [801/119], Loss: 0.2397\n",
      "Epoch [6/10], Step [901/119], Loss: 0.1229\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.1600\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.3490\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.3440\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.1942\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.2161\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.1075\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.1577\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.2521\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.2668\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.6425\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.1891\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.1154\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.1394\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.1310\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.1223\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.3137\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.1560\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.3394\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.2142\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.1336\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.1665\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.2206\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.3265\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.1132\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.2588\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.2310\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.1947\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.1730\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.1550\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.2688\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.2521\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.1631\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.1617\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.1327\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.1329\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.1059\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.2018\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.1474\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.2207\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.1432\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.0971\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.1013\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.1121\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.1298\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.0707\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.2370\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.1507\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.1581\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.1923\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.1214\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.1528\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.1826\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.2357\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.1161\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.1666\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.0859\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.2676\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.1900\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.1444\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.1055\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.1064\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.1439\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.1320\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.1266\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.1192\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.0850\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.0912\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.0815\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.1253\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.1319\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.1988\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.1534\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.1340\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.0948\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.1537\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.1110\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.1599\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.1786\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.1127\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.1669\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.1243\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.1247\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.1792\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.1201\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.0975\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.1570\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.1675\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.1817\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.1272\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.1250\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.1333\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0944\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.1191\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0787\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.1488\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.1159\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.1180\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0939\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0715\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.1248\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.1337\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.1054\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.1541\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.2579\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.2511\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.1886\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.1318\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.2630\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.2327\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0414\n",
      "Epoch [7/10], Step [1/119], Loss: 0.1382\n",
      "Epoch [7/10], Step [101/119], Loss: 0.2029\n",
      "Epoch [7/10], Step [201/119], Loss: 0.1196\n",
      "Epoch [7/10], Step [301/119], Loss: 0.0693\n",
      "Epoch [7/10], Step [401/119], Loss: 0.1059\n",
      "Epoch [7/10], Step [501/119], Loss: 0.1929\n",
      "Epoch [7/10], Step [601/119], Loss: 0.1691\n",
      "Epoch [7/10], Step [701/119], Loss: 0.1058\n",
      "Epoch [7/10], Step [801/119], Loss: 0.2173\n",
      "Epoch [7/10], Step [901/119], Loss: 0.2913\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.1283\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.1199\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.1519\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.1760\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.2810\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.2598\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.1812\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.1334\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0985\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.1745\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.1844\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.1694\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.2280\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.1773\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.2794\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.1855\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.0739\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.1182\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.1927\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.2422\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.2788\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.2081\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.1182\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.0615\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.1390\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.1357\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.2558\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.2340\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.3554\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.1248\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.0710\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.1091\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.1571\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.1252\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.2651\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.1203\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.1356\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.0777\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.1206\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.0976\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.1000\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.1714\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.1632\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.0799\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.0634\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.2179\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.1011\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.0937\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.1383\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.0749\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.1023\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.1426\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.1117\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.0942\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.0953\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.0793\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.1452\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.0815\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.1032\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.0923\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.1561\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.2275\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.1099\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.0773\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.0825\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.1109\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.1175\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.1219\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.1208\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.0662\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.0811\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.0852\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.1650\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.1524\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.0820\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.0598\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.0443\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.0760\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.0656\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.0898\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.1407\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.1025\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.1031\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.0613\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.1451\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.1900\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.1538\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.0935\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.0518\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.0755\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.0934\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.0644\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.0947\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.0578\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.1014\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0693\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.1099\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0704\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0913\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.1098\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0451\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.1095\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0930\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0753\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0660\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.1299\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.1963\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.3708\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0916\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0054\n",
      "Epoch [8/10], Step [1/119], Loss: 0.0953\n",
      "Epoch [8/10], Step [101/119], Loss: 0.0933\n",
      "Epoch [8/10], Step [201/119], Loss: 0.1659\n",
      "Epoch [8/10], Step [301/119], Loss: 0.1714\n",
      "Epoch [8/10], Step [401/119], Loss: 0.2344\n",
      "Epoch [8/10], Step [501/119], Loss: 0.1325\n",
      "Epoch [8/10], Step [601/119], Loss: 0.0802\n",
      "Epoch [8/10], Step [701/119], Loss: 0.0294\n",
      "Epoch [8/10], Step [801/119], Loss: 0.0820\n",
      "Epoch [8/10], Step [901/119], Loss: 0.0965\n",
      "Epoch [8/10], Step [1001/119], Loss: 0.3117\n",
      "Epoch [8/10], Step [1101/119], Loss: 0.3423\n",
      "Epoch [8/10], Step [1201/119], Loss: 0.1338\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.0981\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.2628\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.0557\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.0810\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.1452\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.1973\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.1607\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.0886\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.0933\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.0566\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.0489\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.0910\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.1777\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.1581\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.0569\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.1889\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.0865\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.0652\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.0617\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.0956\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.0649\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.0972\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.0859\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.1163\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.0790\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.0559\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.0603\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.0574\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.0633\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.1350\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.0685\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.0719\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.0639\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.0754\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.0353\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.0877\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.1350\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.0849\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.0698\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.0704\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.0327\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.0255\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.1343\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.0864\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.1011\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.1240\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.0543\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.1171\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.0911\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.1040\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.0568\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.1188\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.0804\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.2026\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.0803\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.0677\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.0583\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.0515\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.1110\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.1108\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.1024\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.0509\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.0384\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.0455\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.0529\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.0817\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.0743\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.0764\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.1575\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.0583\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.0419\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.0487\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.0412\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.0845\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.0808\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.0394\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.0504\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.0224\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.0890\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.0738\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.0482\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.0531\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.0701\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.0704\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.0625\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.0746\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.2739\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.1810\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.0539\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.0348\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.0392\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.0592\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.0979\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.1208\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.1313\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.1077\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.0484\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.0353\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.0489\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.0313\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.2338\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.0261\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.0503\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.1596\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0907\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.1218\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0097\n",
      "Epoch [9/10], Step [1/119], Loss: 0.1704\n",
      "Epoch [9/10], Step [101/119], Loss: 0.2051\n",
      "Epoch [9/10], Step [201/119], Loss: 0.0424\n",
      "Epoch [9/10], Step [301/119], Loss: 0.0552\n",
      "Epoch [9/10], Step [401/119], Loss: 0.0293\n",
      "Epoch [9/10], Step [501/119], Loss: 0.0946\n",
      "Epoch [9/10], Step [601/119], Loss: 0.1286\n",
      "Epoch [9/10], Step [701/119], Loss: 0.0638\n",
      "Epoch [9/10], Step [801/119], Loss: 0.1214\n",
      "Epoch [9/10], Step [901/119], Loss: 0.1604\n",
      "Epoch [9/10], Step [1001/119], Loss: 0.0903\n",
      "Epoch [9/10], Step [1101/119], Loss: 0.0684\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.0177\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.0492\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.1318\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.0872\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.0673\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.0992\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.0521\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.0579\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.0410\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.0304\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.0639\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.0404\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.0629\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.0918\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.0277\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.0435\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.0602\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.0416\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.0339\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.0384\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.0794\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.0262\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.0593\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.0662\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.0435\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.0496\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.0419\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.0271\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.0374\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.0539\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.0729\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.0368\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.0234\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.0431\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.0335\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.0813\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.0310\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.0676\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.0329\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.0466\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.0604\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.0315\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.0167\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.1061\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.0510\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.0380\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.0375\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.0554\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.0250\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.0579\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.0389\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.0210\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.0437\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.0265\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.0591\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.0676\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.0341\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.1399\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.0983\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.0346\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.0605\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.0391\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.0204\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.0338\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.1087\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.2155\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.0622\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.0309\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.0776\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.0412\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.0607\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.0604\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.0499\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.0867\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.1137\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.0930\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.0214\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.0232\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.0453\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.1028\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.0962\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.0427\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.0481\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.0759\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.0921\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.0567\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.0153\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.0236\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0426\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0317\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0151\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0743\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0694\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0284\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0354\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0293\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0833\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0660\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.1296\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.1015\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0444\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.1815\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0146\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0148\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0459\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0434\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0333\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0028\n",
      "Epoch [10/10], Step [1/119], Loss: 0.2207\n",
      "Epoch [10/10], Step [101/119], Loss: 0.2240\n",
      "Epoch [10/10], Step [201/119], Loss: 0.2080\n",
      "Epoch [10/10], Step [301/119], Loss: 0.1312\n",
      "Epoch [10/10], Step [401/119], Loss: 0.0393\n",
      "Epoch [10/10], Step [501/119], Loss: 0.0731\n",
      "Epoch [10/10], Step [601/119], Loss: 0.0255\n",
      "Epoch [10/10], Step [701/119], Loss: 0.0105\n",
      "Epoch [10/10], Step [801/119], Loss: 0.0600\n",
      "Epoch [10/10], Step [901/119], Loss: 0.0606\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.2378\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.2212\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0682\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0148\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0301\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0162\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0598\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0778\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0974\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.1497\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0893\n",
      "Epoch [10/10], Step [2101/119], Loss: 0.0858\n",
      "Epoch [10/10], Step [2201/119], Loss: 0.0484\n",
      "Epoch [10/10], Step [2301/119], Loss: 0.0145\n",
      "Epoch [10/10], Step [2401/119], Loss: 0.0286\n",
      "Epoch [10/10], Step [2501/119], Loss: 0.0483\n",
      "Epoch [10/10], Step [2601/119], Loss: 0.0206\n",
      "Epoch [10/10], Step [2701/119], Loss: 0.0434\n",
      "Epoch [10/10], Step [2801/119], Loss: 0.0459\n",
      "Epoch [10/10], Step [2901/119], Loss: 0.0303\n",
      "Epoch [10/10], Step [3001/119], Loss: 0.0568\n",
      "Epoch [10/10], Step [3101/119], Loss: 0.1961\n",
      "Epoch [10/10], Step [3201/119], Loss: 0.0274\n",
      "Epoch [10/10], Step [3301/119], Loss: 0.0266\n",
      "Epoch [10/10], Step [3401/119], Loss: 0.0729\n",
      "Epoch [10/10], Step [3501/119], Loss: 0.0381\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.0303\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.0333\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.0408\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.0655\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.0157\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.0373\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.0619\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.0446\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.0267\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.0386\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.0282\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.0243\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.0313\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.0234\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.0589\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.0546\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.0290\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.0262\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.0127\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.0317\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.0597\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.0437\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.0526\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.0422\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.0754\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.0652\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.0531\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.0707\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.0361\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.0282\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.0483\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.0689\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.0580\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.0394\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.0344\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.0380\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.1190\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.0473\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.0251\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.0125\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.0373\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.0220\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.0674\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.1045\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.0679\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.1054\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.1099\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.0549\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.0342\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.0317\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.0694\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.1974\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.1512\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.0649\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.0156\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.0466\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.0256\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.0110\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.0128\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.0451\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.2112\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.1121\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.0811\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.0747\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.0263\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.0289\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.0538\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.0108\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.0243\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.0391\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.0236\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.0266\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.0384\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.0530\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.0626\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.1254\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.1046\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.1356\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.0201\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.0326\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.0430\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.0907\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.0384\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.0051\n",
      "Accuracy of the model on test data: 85.03%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the Neural Network\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Assuming your data is loaded into X_train, y_train, X_test, y_test\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 5000\n",
    "hidden_size = 100\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create an instance of the classifier and define loss and optimizer\n",
    "model = TextClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train_tensor[i:i+batch_size]\n",
    "        y_batch = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train)//batch_size}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f'Accuracy of the model on test data: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Neural Network\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/119], Loss: 0.7240\n",
      "Epoch [1/10], Step [101/119], Loss: 0.5781\n",
      "Epoch [1/10], Step [201/119], Loss: 0.4704\n",
      "Epoch [1/10], Step [301/119], Loss: 0.3934\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2852\n",
      "Epoch [1/10], Step [501/119], Loss: 0.2266\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1682\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1174\n",
      "Epoch [1/10], Step [801/119], Loss: 0.0954\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0745\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0565\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0273\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0195\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0130\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0137\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0081\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0081\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0056\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0040\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0027\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0024\n",
      "Epoch [1/10], Step [2101/119], Loss: 0.0023\n",
      "Epoch [1/10], Step [2201/119], Loss: 0.0014\n",
      "Epoch [1/10], Step [2301/119], Loss: 0.0013\n",
      "Epoch [1/10], Step [2401/119], Loss: 0.0007\n",
      "Epoch [1/10], Step [2501/119], Loss: 0.0009\n",
      "Epoch [1/10], Step [2601/119], Loss: 0.0004\n",
      "Epoch [1/10], Step [2701/119], Loss: 0.0004\n",
      "Epoch [1/10], Step [2801/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [2901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3001/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [3101/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [3201/119], Loss: 0.0004\n",
      "Epoch [1/10], Step [3301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.0007\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.0012\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.0008\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.0005\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.0009\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.0005\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.0028\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.0010\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.0030\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.0006\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0004\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0015\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1001/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.0009\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2301/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3201/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.0004\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.0014\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.0009\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.0005\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.0028\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.0014\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.0014\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0006\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0006\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0010\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.0014\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3201/119], Loss: 0.0003\n",
      "Epoch [3/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.0003\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.0002\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.0007\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.0003\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.0007\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.0006\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.0023\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.0008\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.0009\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.0004\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0013\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.0011\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3201/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4101/119], Loss: 0.0003\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.0006\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.0004\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.0002\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.0003\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.0020\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.0003\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.0006\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0005\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.0005\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3201/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.0002\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.0002\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.0004\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.0016\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.0004\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.0003\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.0003\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.0002\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.0002\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.0002\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.0014\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.0002\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.0003\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0004\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.0001\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.0001\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.0001\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.0003\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.0003\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.0001\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.0004\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.0001\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.0002\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.0001\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [1/119], Loss: 0.6311\n",
      "Epoch [1/10], Step [101/119], Loss: 0.4370\n",
      "Epoch [1/10], Step [201/119], Loss: 0.3305\n",
      "Epoch [1/10], Step [301/119], Loss: 0.2537\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2113\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1201\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1202\n",
      "Epoch [1/10], Step [701/119], Loss: 0.0790\n",
      "Epoch [1/10], Step [801/119], Loss: 0.0916\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0447\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0403\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0273\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0265\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0128\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0126\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0134\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0073\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0049\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0036\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0030\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0033\n",
      "Epoch [1/10], Step [2101/119], Loss: 7.8572\n",
      "Epoch [1/10], Step [2201/119], Loss: 13.4020\n",
      "Epoch [1/10], Step [2301/119], Loss: 13.1342\n",
      "Epoch [1/10], Step [2401/119], Loss: 11.5949\n",
      "Epoch [1/10], Step [2501/119], Loss: 10.5116\n",
      "Epoch [1/10], Step [2601/119], Loss: 9.0663\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.9166\n",
      "Epoch [1/10], Step [2801/119], Loss: 5.8033\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.5259\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.5127\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.2882\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.7121\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.2306\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9468\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.8377\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.7898\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.7765\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.7796\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.7643\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.7624\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.7565\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.7501\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.7476\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.7413\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.7345\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.7353\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.7307\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.7284\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.7234\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.7173\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.7141\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.7131\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.7007\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.6968\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.6831\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.6773\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.6641\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.6523\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.6265\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.5851\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.5551\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.5161\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.4715\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.4402\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.3888\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.3586\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.3415\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.2951\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.2442\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.2298\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.1973\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.1781\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.1599\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.1543\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.1079\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.1146\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.0965\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.0874\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.0789\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.0668\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.0591\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.0558\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.0489\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.0412\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0378\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.0288\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0328\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0294\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0259\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0231\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0184\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0192\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0159\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0147\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0157\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0151\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0148\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0115\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0126\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0100\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0127\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0067\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0110\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0081\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0109\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0091\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0101\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0047\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0073\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0088\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0082\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0105\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0069\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0058\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0076\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0071\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0039\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0051\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0053\n",
      "Epoch [2/10], Step [1/119], Loss: 22.6676\n",
      "Epoch [2/10], Step [101/119], Loss: 19.2844\n",
      "Epoch [2/10], Step [201/119], Loss: 17.5784\n",
      "Epoch [2/10], Step [301/119], Loss: 15.3524\n",
      "Epoch [2/10], Step [401/119], Loss: 12.3188\n",
      "Epoch [2/10], Step [501/119], Loss: 12.3556\n",
      "Epoch [2/10], Step [601/119], Loss: 9.3829\n",
      "Epoch [2/10], Step [701/119], Loss: 9.3668\n",
      "Epoch [2/10], Step [801/119], Loss: 4.9023\n",
      "Epoch [2/10], Step [901/119], Loss: 5.5854\n",
      "Epoch [2/10], Step [1001/119], Loss: 4.5594\n",
      "Epoch [2/10], Step [1101/119], Loss: 3.9908\n",
      "Epoch [2/10], Step [1201/119], Loss: 2.8445\n",
      "Epoch [2/10], Step [1301/119], Loss: 2.3338\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.6893\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.3113\n",
      "Epoch [2/10], Step [1601/119], Loss: 1.0338\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.8812\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.6914\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.5630\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.5070\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.7264\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.9878\n",
      "Epoch [2/10], Step [2301/119], Loss: 1.0073\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.0666\n",
      "Epoch [2/10], Step [2501/119], Loss: 1.0533\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.0377\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.0355\n",
      "Epoch [2/10], Step [2801/119], Loss: 1.0285\n",
      "Epoch [2/10], Step [2901/119], Loss: 0.9996\n",
      "Epoch [2/10], Step [3001/119], Loss: 0.9595\n",
      "Epoch [2/10], Step [3101/119], Loss: 0.9352\n",
      "Epoch [2/10], Step [3201/119], Loss: 0.9217\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.8987\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.8594\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.8485\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.8327\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.8224\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.7976\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.7916\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.7817\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.7665\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.7673\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.7531\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.7430\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.7388\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.7295\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.7216\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.7206\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.7121\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.7056\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.6904\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.6743\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.6632\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.6411\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.6133\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.5917\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.5528\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.5401\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.4974\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.4249\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.4180\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.3623\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.3249\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.3169\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.2708\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.2534\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.2506\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.2192\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.1785\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.1695\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.1517\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.1403\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.1335\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.1301\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0945\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.1045\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0848\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0833\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0708\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0653\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0569\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0597\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0554\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0420\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0378\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0367\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0354\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0331\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0295\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0307\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0227\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0270\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0228\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0197\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0221\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0207\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0225\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0179\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0224\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0150\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0196\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0116\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0164\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0135\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0194\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0148\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0165\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0110\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0109\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0132\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0129\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0161\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0109\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0110\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0109\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0120\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0083\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0093\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0106\n",
      "Epoch [3/10], Step [1/119], Loss: 19.5467\n",
      "Epoch [3/10], Step [101/119], Loss: 17.0386\n",
      "Epoch [3/10], Step [201/119], Loss: 14.9326\n",
      "Epoch [3/10], Step [301/119], Loss: 12.7993\n",
      "Epoch [3/10], Step [401/119], Loss: 10.6172\n",
      "Epoch [3/10], Step [501/119], Loss: 10.3197\n",
      "Epoch [3/10], Step [601/119], Loss: 7.4152\n",
      "Epoch [3/10], Step [701/119], Loss: 7.2406\n",
      "Epoch [3/10], Step [801/119], Loss: 3.6818\n",
      "Epoch [3/10], Step [901/119], Loss: 4.0286\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.8886\n",
      "Epoch [3/10], Step [1101/119], Loss: 2.1874\n",
      "Epoch [3/10], Step [1201/119], Loss: 1.3562\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.8294\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.5380\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.4006\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.3030\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.2367\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.2004\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1781\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1760\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.2634\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.2101\n",
      "Epoch [3/10], Step [2301/119], Loss: 2.3411\n",
      "Epoch [3/10], Step [2401/119], Loss: 2.5207\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.5311\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.4445\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.3729\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.4686\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.1688\n",
      "Epoch [3/10], Step [3001/119], Loss: 2.2030\n",
      "Epoch [3/10], Step [3101/119], Loss: 1.8002\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.7860\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.6859\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.6072\n",
      "Epoch [3/10], Step [3501/119], Loss: 1.4125\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.3471\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.4042\n",
      "Epoch [3/10], Step [3801/119], Loss: 1.0924\n",
      "Epoch [3/10], Step [3901/119], Loss: 1.0854\n",
      "Epoch [3/10], Step [4001/119], Loss: 1.0223\n",
      "Epoch [3/10], Step [4101/119], Loss: 1.0448\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.9514\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.8823\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.8592\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.8128\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.7870\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.7747\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.7587\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.7444\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.7264\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.7090\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.6992\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.6955\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.6842\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.6877\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.6716\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.6705\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.6637\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.6579\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.6550\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.6483\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.6367\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.6197\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.6032\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.5846\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.5678\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.5455\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.5109\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.4875\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.4670\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.4367\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.4065\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.3649\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.3716\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.3180\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.3150\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.2824\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.2693\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.2458\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.2359\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.2106\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.2010\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.1825\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.1582\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.1471\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.1266\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.1350\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.1244\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.1150\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.1112\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.1054\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0941\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0845\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0689\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0856\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0754\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0687\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0632\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0661\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0443\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0528\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0467\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0607\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0432\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0483\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0442\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0404\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0292\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0314\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0394\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0339\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0369\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0296\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0270\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0285\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0288\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0207\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0270\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0301\n",
      "Epoch [4/10], Step [1/119], Loss: 13.9164\n",
      "Epoch [4/10], Step [101/119], Loss: 11.7783\n",
      "Epoch [4/10], Step [201/119], Loss: 10.3414\n",
      "Epoch [4/10], Step [301/119], Loss: 8.4766\n",
      "Epoch [4/10], Step [401/119], Loss: 6.7491\n",
      "Epoch [4/10], Step [501/119], Loss: 5.9759\n",
      "Epoch [4/10], Step [601/119], Loss: 4.1394\n",
      "Epoch [4/10], Step [701/119], Loss: 3.0266\n",
      "Epoch [4/10], Step [801/119], Loss: 1.3503\n",
      "Epoch [4/10], Step [901/119], Loss: 0.8910\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.4623\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.2799\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.2361\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.1574\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.1444\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.1312\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.1063\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0815\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0781\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0661\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0790\n",
      "Epoch [4/10], Step [2101/119], Loss: 2.3505\n",
      "Epoch [4/10], Step [2201/119], Loss: 4.2357\n",
      "Epoch [4/10], Step [2301/119], Loss: 4.3999\n",
      "Epoch [4/10], Step [2401/119], Loss: 4.4469\n",
      "Epoch [4/10], Step [2501/119], Loss: 4.3293\n",
      "Epoch [4/10], Step [2601/119], Loss: 4.3180\n",
      "Epoch [4/10], Step [2701/119], Loss: 4.1594\n",
      "Epoch [4/10], Step [2801/119], Loss: 3.8695\n",
      "Epoch [4/10], Step [2901/119], Loss: 3.3462\n",
      "Epoch [4/10], Step [3001/119], Loss: 3.3135\n",
      "Epoch [4/10], Step [3101/119], Loss: 2.6210\n",
      "Epoch [4/10], Step [3201/119], Loss: 2.5538\n",
      "Epoch [4/10], Step [3301/119], Loss: 2.3582\n",
      "Epoch [4/10], Step [3401/119], Loss: 2.1638\n",
      "Epoch [4/10], Step [3501/119], Loss: 1.8218\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.6826\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.6462\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.2540\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.2075\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.1172\n",
      "Epoch [4/10], Step [4101/119], Loss: 1.1597\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.9687\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.8913\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.8554\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.8130\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.7508\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.7470\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.7314\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.7119\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.6821\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.6681\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.6571\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.6509\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.6423\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.6267\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.6259\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.6184\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.6145\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.6092\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.6071\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.6019\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.6006\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.5976\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.5929\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.5923\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.5908\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.5890\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.5862\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.5834\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.5820\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.5806\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.5775\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.5767\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.5733\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.5685\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.5717\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.5712\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.5668\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.5668\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.5616\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.5597\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.5594\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.5550\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.5548\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.5536\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.5536\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.5498\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.5503\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.5462\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.5418\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.5407\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.5385\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.5404\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.5316\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.5360\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.5323\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.5232\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.5285\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.5222\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.5168\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.5141\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.5124\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.5115\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.5092\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.5031\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.5069\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.5022\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.4899\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.4962\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.4941\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.4864\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.4878\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.4832\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.4841\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.4707\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.4766\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.4657\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.4674\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.4678\n",
      "Epoch [5/10], Step [1/119], Loss: 1.0895\n",
      "Epoch [5/10], Step [101/119], Loss: 1.0721\n",
      "Epoch [5/10], Step [201/119], Loss: 1.0615\n",
      "Epoch [5/10], Step [301/119], Loss: 1.0531\n",
      "Epoch [5/10], Step [401/119], Loss: 1.0252\n",
      "Epoch [5/10], Step [501/119], Loss: 1.0405\n",
      "Epoch [5/10], Step [601/119], Loss: 1.0211\n",
      "Epoch [5/10], Step [701/119], Loss: 1.0340\n",
      "Epoch [5/10], Step [801/119], Loss: 0.9974\n",
      "Epoch [5/10], Step [901/119], Loss: 1.0111\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.9920\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.9882\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.9766\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.9668\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.9504\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.9424\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.9327\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.9217\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.9103\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.9104\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.9037\n",
      "Epoch [5/10], Step [2101/119], Loss: 0.7124\n",
      "Epoch [5/10], Step [2201/119], Loss: 0.5317\n",
      "Epoch [5/10], Step [2301/119], Loss: 0.5372\n",
      "Epoch [5/10], Step [2401/119], Loss: 0.5388\n",
      "Epoch [5/10], Step [2501/119], Loss: 0.5375\n",
      "Epoch [5/10], Step [2601/119], Loss: 0.5417\n",
      "Epoch [5/10], Step [2701/119], Loss: 0.5431\n",
      "Epoch [5/10], Step [2801/119], Loss: 0.5421\n",
      "Epoch [5/10], Step [2901/119], Loss: 0.5422\n",
      "Epoch [5/10], Step [3001/119], Loss: 0.5452\n",
      "Epoch [5/10], Step [3101/119], Loss: 0.5443\n",
      "Epoch [5/10], Step [3201/119], Loss: 0.5428\n",
      "Epoch [5/10], Step [3301/119], Loss: 0.5437\n",
      "Epoch [5/10], Step [3401/119], Loss: 0.5423\n",
      "Epoch [5/10], Step [3501/119], Loss: 0.5425\n",
      "Epoch [5/10], Step [3601/119], Loss: 0.5443\n",
      "Epoch [5/10], Step [3701/119], Loss: 0.5396\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.5403\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.5384\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.5404\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.5366\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.5357\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.5353\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.5349\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.5303\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.5294\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.5222\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.5155\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.5054\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.4993\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.4813\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.4715\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.4489\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.4276\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.4089\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.3832\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.3424\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.3366\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.2955\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.2397\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.2425\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.1986\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.1815\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.1828\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.1447\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.1352\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.1331\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.1213\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.0915\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.0946\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.0835\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.0753\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.0717\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.0697\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.0475\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.0518\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.0404\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.0355\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.0370\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.0304\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.0275\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.0255\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.0211\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.0237\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.0203\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.0165\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.0155\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.0145\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.0155\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.0148\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.0118\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.0125\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.0113\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.0095\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.0107\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.0100\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.0114\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.0082\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.0096\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.0070\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.0090\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.0059\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.0082\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.0071\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.0082\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.0065\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.0081\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.0046\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.0052\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.0061\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.0076\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.0084\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.0067\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.0050\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.0055\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.0056\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.0045\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.0041\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0059\n",
      "Epoch [6/10], Step [1/119], Loss: 20.5667\n",
      "Epoch [6/10], Step [101/119], Loss: 17.1687\n",
      "Epoch [6/10], Step [201/119], Loss: 13.7118\n",
      "Epoch [6/10], Step [301/119], Loss: 9.5872\n",
      "Epoch [6/10], Step [401/119], Loss: 5.5342\n",
      "Epoch [6/10], Step [501/119], Loss: 2.5415\n",
      "Epoch [6/10], Step [601/119], Loss: 0.4489\n",
      "Epoch [6/10], Step [701/119], Loss: 0.1393\n",
      "Epoch [6/10], Step [801/119], Loss: 0.1159\n",
      "Epoch [6/10], Step [901/119], Loss: 0.0444\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.0375\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.0216\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.0160\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.0101\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.0125\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.0094\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.0065\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.0046\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.0049\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.0028\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.0049\n",
      "Epoch [6/10], Step [2101/119], Loss: 6.7814\n",
      "Epoch [6/10], Step [2201/119], Loss: 12.3811\n",
      "Epoch [6/10], Step [2301/119], Loss: 12.2109\n",
      "Epoch [6/10], Step [2401/119], Loss: 12.0373\n",
      "Epoch [6/10], Step [2501/119], Loss: 10.9897\n",
      "Epoch [6/10], Step [2601/119], Loss: 10.4402\n",
      "Epoch [6/10], Step [2701/119], Loss: 9.6024\n",
      "Epoch [6/10], Step [2801/119], Loss: 8.5063\n",
      "Epoch [6/10], Step [2901/119], Loss: 6.9331\n",
      "Epoch [6/10], Step [3001/119], Loss: 6.1510\n",
      "Epoch [6/10], Step [3101/119], Loss: 4.5505\n",
      "Epoch [6/10], Step [3201/119], Loss: 4.1946\n",
      "Epoch [6/10], Step [3301/119], Loss: 3.4387\n",
      "Epoch [6/10], Step [3401/119], Loss: 2.7942\n",
      "Epoch [6/10], Step [3501/119], Loss: 2.1255\n",
      "Epoch [6/10], Step [3601/119], Loss: 1.7442\n",
      "Epoch [6/10], Step [3701/119], Loss: 1.5673\n",
      "Epoch [6/10], Step [3801/119], Loss: 1.1811\n",
      "Epoch [6/10], Step [3901/119], Loss: 1.0126\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.8993\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.8551\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.7418\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.6765\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.6495\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.6173\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.5928\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.5822\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.5690\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.5548\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.5425\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.5367\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.5304\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.5269\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.5184\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.5195\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.5125\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.5103\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.5075\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.5044\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.5009\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.5010\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.4992\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.4986\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.4955\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.4929\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.4885\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.4911\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.4905\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.4885\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.4832\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.4825\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.4805\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.4824\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.4807\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.4737\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.4771\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.4717\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.4714\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.4701\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.4678\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.4679\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.4668\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.4598\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.4640\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.4595\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.4542\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.4531\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.4565\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.4505\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.4491\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.4474\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.4456\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.4497\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.4387\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.4411\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.4403\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.4337\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.4309\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.4270\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.4193\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.4272\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.4213\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.4172\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.4215\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.4075\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.4172\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.4147\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.4047\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.4077\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.4033\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.3962\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.3965\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.3926\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.4030\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.3837\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.3889\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.3841\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.3858\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.3723\n",
      "Epoch [7/10], Step [1/119], Loss: 1.1990\n",
      "Epoch [7/10], Step [101/119], Loss: 1.1899\n",
      "Epoch [7/10], Step [201/119], Loss: 1.1841\n",
      "Epoch [7/10], Step [301/119], Loss: 1.1803\n",
      "Epoch [7/10], Step [401/119], Loss: 1.1553\n",
      "Epoch [7/10], Step [501/119], Loss: 1.1910\n",
      "Epoch [7/10], Step [601/119], Loss: 1.1359\n",
      "Epoch [7/10], Step [701/119], Loss: 1.1770\n",
      "Epoch [7/10], Step [801/119], Loss: 1.1386\n",
      "Epoch [7/10], Step [901/119], Loss: 1.1536\n",
      "Epoch [7/10], Step [1001/119], Loss: 1.1096\n",
      "Epoch [7/10], Step [1101/119], Loss: 1.1094\n",
      "Epoch [7/10], Step [1201/119], Loss: 1.1180\n",
      "Epoch [7/10], Step [1301/119], Loss: 1.0762\n",
      "Epoch [7/10], Step [1401/119], Loss: 1.0727\n",
      "Epoch [7/10], Step [1501/119], Loss: 1.0779\n",
      "Epoch [7/10], Step [1601/119], Loss: 1.0605\n",
      "Epoch [7/10], Step [1701/119], Loss: 1.0482\n",
      "Epoch [7/10], Step [1801/119], Loss: 1.0411\n",
      "Epoch [7/10], Step [1901/119], Loss: 1.0417\n",
      "Epoch [7/10], Step [2001/119], Loss: 1.0311\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.7295\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.4437\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.4503\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.4484\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.4511\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.4602\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.4595\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.4616\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.4607\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.4661\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.4608\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.4613\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.4616\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.4641\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.4615\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.4617\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.4608\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.4591\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.4568\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.4571\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.4562\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.4514\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.4531\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.4505\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.4500\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.4505\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.4459\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.4491\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.4476\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.4492\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.4416\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.4426\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.4388\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.4376\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.4378\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.4372\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.4330\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.4295\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.4299\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.4200\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.4123\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.4015\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.3833\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.3712\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.3508\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.3333\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.3271\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.2942\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.2643\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.2586\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.2297\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.2150\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.1932\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.1866\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.1485\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.1541\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.1317\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.1242\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.1088\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.1052\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.0902\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.0843\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.0754\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.0644\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.0623\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.0476\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.0551\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.0503\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.0459\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.0457\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.0390\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.0359\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.0320\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.0276\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.0337\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.0270\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.0289\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.0248\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.0252\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.0151\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.0216\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.0176\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.0228\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.0170\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0219\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.0184\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0180\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0114\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.0129\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0148\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.0152\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0169\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0131\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0118\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.0128\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.0156\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.0098\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0111\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0147\n",
      "Epoch [8/10], Step [1/119], Loss: 16.4277\n",
      "Epoch [8/10], Step [101/119], Loss: 13.5688\n",
      "Epoch [8/10], Step [201/119], Loss: 11.1152\n",
      "Epoch [8/10], Step [301/119], Loss: 7.9649\n",
      "Epoch [8/10], Step [401/119], Loss: 5.3566\n",
      "Epoch [8/10], Step [501/119], Loss: 3.5383\n",
      "Epoch [8/10], Step [601/119], Loss: 1.0860\n",
      "Epoch [8/10], Step [701/119], Loss: 0.3270\n",
      "Epoch [8/10], Step [801/119], Loss: 0.2513\n",
      "Epoch [8/10], Step [901/119], Loss: 0.1209\n",
      "Epoch [8/10], Step [1001/119], Loss: 0.1027\n",
      "Epoch [8/10], Step [1101/119], Loss: 0.0592\n",
      "Epoch [8/10], Step [1201/119], Loss: 0.0532\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.0288\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.0317\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.0330\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.0232\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.0175\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.0187\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.0111\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.0162\n",
      "Epoch [8/10], Step [2101/119], Loss: 5.1366\n",
      "Epoch [8/10], Step [2201/119], Loss: 9.4486\n",
      "Epoch [8/10], Step [2301/119], Loss: 9.7502\n",
      "Epoch [8/10], Step [2401/119], Loss: 9.6964\n",
      "Epoch [8/10], Step [2501/119], Loss: 8.8382\n",
      "Epoch [8/10], Step [2601/119], Loss: 8.4160\n",
      "Epoch [8/10], Step [2701/119], Loss: 7.8885\n",
      "Epoch [8/10], Step [2801/119], Loss: 7.2354\n",
      "Epoch [8/10], Step [2901/119], Loss: 6.0382\n",
      "Epoch [8/10], Step [3001/119], Loss: 5.4954\n",
      "Epoch [8/10], Step [3101/119], Loss: 4.1878\n",
      "Epoch [8/10], Step [3201/119], Loss: 3.8442\n",
      "Epoch [8/10], Step [3301/119], Loss: 3.3115\n",
      "Epoch [8/10], Step [3401/119], Loss: 2.9097\n",
      "Epoch [8/10], Step [3501/119], Loss: 2.3079\n",
      "Epoch [8/10], Step [3601/119], Loss: 1.8956\n",
      "Epoch [8/10], Step [3701/119], Loss: 1.8643\n",
      "Epoch [8/10], Step [3801/119], Loss: 1.2609\n",
      "Epoch [8/10], Step [3901/119], Loss: 1.1075\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.9783\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.9766\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.7648\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.6650\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.6200\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.5763\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.5336\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.5125\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.4951\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.4763\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.4612\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.4480\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.4425\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.4299\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.4270\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.4235\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.4191\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.4120\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.4103\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.4052\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.4013\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.3981\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.3982\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.3980\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.3912\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.3946\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.3871\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.3912\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.3889\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.3820\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.3820\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.3749\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.3759\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.3770\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.3750\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.3593\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.3693\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.3696\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.3598\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.3633\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.3547\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.3565\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.3529\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.3472\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.3436\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.3432\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.3414\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.3390\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.3424\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.3383\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.3306\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.3276\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.3181\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.3340\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.3162\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.3220\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.3129\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.3122\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.3091\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.3022\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.2928\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.3087\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.2924\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.2975\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.2931\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.2720\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.2860\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.2801\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.2674\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.2799\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.2687\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.2682\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.2609\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.2552\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.2654\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.2559\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.2556\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.2544\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.2559\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.2345\n",
      "Epoch [9/10], Step [1/119], Loss: 1.7677\n",
      "Epoch [9/10], Step [101/119], Loss: 1.7222\n",
      "Epoch [9/10], Step [201/119], Loss: 1.6569\n",
      "Epoch [9/10], Step [301/119], Loss: 1.6335\n",
      "Epoch [9/10], Step [401/119], Loss: 1.5645\n",
      "Epoch [9/10], Step [501/119], Loss: 1.6200\n",
      "Epoch [9/10], Step [601/119], Loss: 1.5346\n",
      "Epoch [9/10], Step [701/119], Loss: 1.6017\n",
      "Epoch [9/10], Step [801/119], Loss: 1.4426\n",
      "Epoch [9/10], Step [901/119], Loss: 1.4886\n",
      "Epoch [9/10], Step [1001/119], Loss: 1.4176\n",
      "Epoch [9/10], Step [1101/119], Loss: 1.4027\n",
      "Epoch [9/10], Step [1201/119], Loss: 1.3705\n",
      "Epoch [9/10], Step [1301/119], Loss: 1.3054\n",
      "Epoch [9/10], Step [1401/119], Loss: 1.2672\n",
      "Epoch [9/10], Step [1501/119], Loss: 1.2654\n",
      "Epoch [9/10], Step [1601/119], Loss: 1.2284\n",
      "Epoch [9/10], Step [1701/119], Loss: 1.1964\n",
      "Epoch [9/10], Step [1801/119], Loss: 1.1600\n",
      "Epoch [9/10], Step [1901/119], Loss: 1.1611\n",
      "Epoch [9/10], Step [2001/119], Loss: 1.1385\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.7541\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.3878\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.3913\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.3939\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.3960\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.4075\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.4047\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.4088\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.4082\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.4126\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.4108\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.4087\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.4046\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.4120\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.4138\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.4097\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.4118\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.4079\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.4068\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.4060\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.4076\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.4065\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.4042\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.4036\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.4025\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.4051\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.3988\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4007\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4006\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4010\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.3982\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.3968\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.3998\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.3958\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.3939\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.3914\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.3901\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.3885\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.3900\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.3876\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.3826\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.3894\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.3834\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.3810\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.3827\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.3715\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.3666\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.3550\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.3433\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.3388\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.3156\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.3053\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.2757\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.2749\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.2380\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.2439\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.2264\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.1980\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.1858\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.1816\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.1488\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.1484\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.1304\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.1119\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.1061\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.0839\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.0890\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.0834\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.0751\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.0707\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.0592\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.0594\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.0470\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.0421\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.0492\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.0412\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.0384\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.0336\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.0327\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0232\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0261\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0189\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0258\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0197\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0199\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0202\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0173\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0117\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0131\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0123\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0134\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0168\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0092\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0084\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0091\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0085\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0059\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0083\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0071\n",
      "Epoch [10/10], Step [1/119], Loss: 16.8567\n",
      "Epoch [10/10], Step [101/119], Loss: 14.2369\n",
      "Epoch [10/10], Step [201/119], Loss: 10.6667\n",
      "Epoch [10/10], Step [301/119], Loss: 6.9432\n",
      "Epoch [10/10], Step [401/119], Loss: 2.9354\n",
      "Epoch [10/10], Step [501/119], Loss: 0.5755\n",
      "Epoch [10/10], Step [601/119], Loss: 0.2136\n",
      "Epoch [10/10], Step [701/119], Loss: 0.0963\n",
      "Epoch [10/10], Step [801/119], Loss: 0.0991\n",
      "Epoch [10/10], Step [901/119], Loss: 0.0360\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.0346\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.0278\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0160\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0075\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0099\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0084\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0059\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0052\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0065\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0025\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0042\n",
      "Epoch [10/10], Step [2101/119], Loss: 7.4782\n",
      "Epoch [10/10], Step [2201/119], Loss: 12.8091\n",
      "Epoch [10/10], Step [2301/119], Loss: 13.2748\n",
      "Epoch [10/10], Step [2401/119], Loss: 12.3434\n",
      "Epoch [10/10], Step [2501/119], Loss: 11.4309\n",
      "Epoch [10/10], Step [2601/119], Loss: 10.5261\n",
      "Epoch [10/10], Step [2701/119], Loss: 9.5818\n",
      "Epoch [10/10], Step [2801/119], Loss: 8.6684\n",
      "Epoch [10/10], Step [2901/119], Loss: 7.1304\n",
      "Epoch [10/10], Step [3001/119], Loss: 6.4017\n",
      "Epoch [10/10], Step [3101/119], Loss: 4.8606\n",
      "Epoch [10/10], Step [3201/119], Loss: 4.4105\n",
      "Epoch [10/10], Step [3301/119], Loss: 3.7080\n",
      "Epoch [10/10], Step [3401/119], Loss: 3.1413\n",
      "Epoch [10/10], Step [3501/119], Loss: 2.5209\n",
      "Epoch [10/10], Step [3601/119], Loss: 1.8797\n",
      "Epoch [10/10], Step [3701/119], Loss: 1.7695\n",
      "Epoch [10/10], Step [3801/119], Loss: 1.1783\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.9789\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.8227\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.7872\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.6277\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.5370\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.4841\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.4509\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.4128\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.3915\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.3797\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.3627\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.3523\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.3423\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.3374\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.3262\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.3227\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.3183\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.3160\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.3078\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.3081\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.3073\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.2891\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.2942\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.2860\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.2759\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.2751\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.2588\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.2501\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.2469\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.2195\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.2062\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.1964\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.1771\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.1685\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.1487\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.1507\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.1177\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.1249\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.1078\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.0983\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.0882\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.0855\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.0726\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.0701\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.0618\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.0521\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.0477\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.0394\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.0450\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.0388\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.0382\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.0381\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.0314\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.0297\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.0245\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.0229\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.0243\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.0211\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.0231\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.0196\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.0214\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.0125\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.0189\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.0119\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.0174\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.0145\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.0163\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.0156\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.0135\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.0085\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.0111\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.0146\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.0109\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.0127\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.0111\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.0107\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.0099\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.0127\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.0075\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.0079\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.0087\n",
      "Epoch [1/10], Step [1/119], Loss: 0.6973\n",
      "Epoch [1/10], Step [101/119], Loss: 0.5153\n",
      "Epoch [1/10], Step [201/119], Loss: 0.3995\n",
      "Epoch [1/10], Step [301/119], Loss: 0.3262\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2669\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1580\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1582\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1075\n",
      "Epoch [1/10], Step [801/119], Loss: 0.1176\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0628\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0565\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0366\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0290\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0171\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0150\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0123\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0075\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0054\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0045\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0026\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0026\n",
      "Epoch [1/10], Step [2101/119], Loss: 8.3553\n",
      "Epoch [1/10], Step [2201/119], Loss: 14.0530\n",
      "Epoch [1/10], Step [2301/119], Loss: 13.4092\n",
      "Epoch [1/10], Step [2401/119], Loss: 12.0798\n",
      "Epoch [1/10], Step [2501/119], Loss: 10.6321\n",
      "Epoch [1/10], Step [2601/119], Loss: 9.0691\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.6213\n",
      "Epoch [1/10], Step [2801/119], Loss: 6.2836\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.5874\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.2928\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.7565\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.7547\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.1394\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9020\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.7655\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.7361\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.6820\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.6768\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.6691\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.6611\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.6571\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.6590\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.6546\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.6600\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.6501\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.6440\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.6381\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.6332\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.6276\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.6262\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.6094\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.6040\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.5873\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.5722\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.5548\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.5421\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.5075\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.5073\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.4798\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.4646\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.4628\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.4220\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.3975\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.3919\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.3706\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.3559\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.3457\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.3130\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.2882\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.2860\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.2565\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.2407\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.2254\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.2206\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.1804\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.1865\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.1670\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.1575\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.1476\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.1383\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.1227\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.1212\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.1107\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.0903\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0852\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.0784\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0801\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0738\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0691\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0691\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0581\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0580\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0493\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0396\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0480\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0430\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0416\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0401\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0425\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0257\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0340\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0256\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0370\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0253\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0292\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0252\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0221\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0170\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0195\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0191\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0191\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0176\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0147\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0148\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0150\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0147\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0107\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0115\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0114\n",
      "Epoch [2/10], Step [1/119], Loss: 17.6158\n",
      "Epoch [2/10], Step [101/119], Loss: 15.5727\n",
      "Epoch [2/10], Step [201/119], Loss: 13.7879\n",
      "Epoch [2/10], Step [301/119], Loss: 12.0761\n",
      "Epoch [2/10], Step [401/119], Loss: 10.0774\n",
      "Epoch [2/10], Step [501/119], Loss: 10.1007\n",
      "Epoch [2/10], Step [601/119], Loss: 8.0265\n",
      "Epoch [2/10], Step [701/119], Loss: 7.8514\n",
      "Epoch [2/10], Step [801/119], Loss: 4.4501\n",
      "Epoch [2/10], Step [901/119], Loss: 5.0186\n",
      "Epoch [2/10], Step [1001/119], Loss: 4.4704\n",
      "Epoch [2/10], Step [1101/119], Loss: 3.9643\n",
      "Epoch [2/10], Step [1201/119], Loss: 2.6378\n",
      "Epoch [2/10], Step [1301/119], Loss: 2.4082\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.7802\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.3332\n",
      "Epoch [2/10], Step [1601/119], Loss: 1.0950\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.8970\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.6358\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.5572\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.4786\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.7433\n",
      "Epoch [2/10], Step [2201/119], Loss: 1.1478\n",
      "Epoch [2/10], Step [2301/119], Loss: 1.2057\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.3388\n",
      "Epoch [2/10], Step [2501/119], Loss: 1.4041\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.3738\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.4540\n",
      "Epoch [2/10], Step [2801/119], Loss: 1.4302\n",
      "Epoch [2/10], Step [2901/119], Loss: 1.3657\n",
      "Epoch [2/10], Step [3001/119], Loss: 1.2750\n",
      "Epoch [2/10], Step [3101/119], Loss: 1.3219\n",
      "Epoch [2/10], Step [3201/119], Loss: 1.2769\n",
      "Epoch [2/10], Step [3301/119], Loss: 1.0994\n",
      "Epoch [2/10], Step [3401/119], Loss: 1.1420\n",
      "Epoch [2/10], Step [3501/119], Loss: 1.1552\n",
      "Epoch [2/10], Step [3601/119], Loss: 1.0774\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.9853\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.9929\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.9568\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.9832\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.8980\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.8818\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.8816\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.8340\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.7823\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.7528\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.7441\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.7466\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.7126\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.6771\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.6698\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.6522\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.6196\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.5872\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.5675\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.5550\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.4857\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.4731\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.4399\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.3954\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.3887\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.3361\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.3025\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.2997\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.2618\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.2433\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.2317\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.1995\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.1712\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.1677\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.1490\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.1367\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.1271\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.1239\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0920\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.0979\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0829\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0764\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0668\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0677\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0561\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0517\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0490\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0415\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0377\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0321\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0359\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0310\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0306\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0264\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0224\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0259\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0190\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0162\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0196\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0188\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0199\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0156\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0158\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0117\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0155\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0112\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0154\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0118\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0146\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0114\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0114\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0074\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0088\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0098\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0108\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0102\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0077\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0083\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0075\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0093\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0052\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0065\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0085\n",
      "Epoch [3/10], Step [1/119], Loss: 19.8776\n",
      "Epoch [3/10], Step [101/119], Loss: 17.9386\n",
      "Epoch [3/10], Step [201/119], Loss: 15.2281\n",
      "Epoch [3/10], Step [301/119], Loss: 12.3676\n",
      "Epoch [3/10], Step [401/119], Loss: 10.0514\n",
      "Epoch [3/10], Step [501/119], Loss: 9.5626\n",
      "Epoch [3/10], Step [601/119], Loss: 7.0197\n",
      "Epoch [3/10], Step [701/119], Loss: 6.4306\n",
      "Epoch [3/10], Step [801/119], Loss: 3.2604\n",
      "Epoch [3/10], Step [901/119], Loss: 3.1521\n",
      "Epoch [3/10], Step [1001/119], Loss: 1.9832\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.4479\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.7734\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.5221\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.3702\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.2984\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.2289\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.1787\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.1666\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1410\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1493\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.4905\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.5166\n",
      "Epoch [3/10], Step [2301/119], Loss: 2.7027\n",
      "Epoch [3/10], Step [2401/119], Loss: 2.7952\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.8969\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.7368\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.6853\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.5990\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.3652\n",
      "Epoch [3/10], Step [3001/119], Loss: 2.1001\n",
      "Epoch [3/10], Step [3101/119], Loss: 2.1838\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.9259\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.4953\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.5216\n",
      "Epoch [3/10], Step [3501/119], Loss: 1.4206\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.2737\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.1552\n",
      "Epoch [3/10], Step [3801/119], Loss: 1.0858\n",
      "Epoch [3/10], Step [3901/119], Loss: 1.0222\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.9994\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.9113\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.8611\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.8239\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.8333\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.7448\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.7046\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.6794\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.6572\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.6464\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.6263\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.6214\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.6093\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.6012\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.5885\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.5891\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.5768\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.5658\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.5647\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.5533\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.5541\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.5511\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.5442\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.5343\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.5283\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.5321\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.5268\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.5267\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.5199\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.5116\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.5099\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.5020\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.5040\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.4919\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.4898\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.4797\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.4787\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.4801\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.4723\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.4661\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.4625\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.4468\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.4462\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.4489\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.4372\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.4304\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.4155\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.4164\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.4227\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.4257\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.4059\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.4047\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.3873\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.3993\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.3796\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.3840\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.3831\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.3631\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.3604\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.3597\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.3323\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.3353\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.3484\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.3536\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.3255\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.3177\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.3224\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.3077\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.2827\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.3028\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.3002\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.2959\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.2834\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.2714\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.2903\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.2795\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.2834\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.2510\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.2663\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.2767\n",
      "Epoch [4/10], Step [1/119], Loss: 2.3014\n",
      "Epoch [4/10], Step [101/119], Loss: 2.1466\n",
      "Epoch [4/10], Step [201/119], Loss: 2.0286\n",
      "Epoch [4/10], Step [301/119], Loss: 1.8799\n",
      "Epoch [4/10], Step [401/119], Loss: 1.8245\n",
      "Epoch [4/10], Step [501/119], Loss: 1.8499\n",
      "Epoch [4/10], Step [601/119], Loss: 1.6623\n",
      "Epoch [4/10], Step [701/119], Loss: 1.7026\n",
      "Epoch [4/10], Step [801/119], Loss: 1.3859\n",
      "Epoch [4/10], Step [901/119], Loss: 1.4802\n",
      "Epoch [4/10], Step [1001/119], Loss: 1.3511\n",
      "Epoch [4/10], Step [1101/119], Loss: 1.3165\n",
      "Epoch [4/10], Step [1201/119], Loss: 1.2162\n",
      "Epoch [4/10], Step [1301/119], Loss: 1.1740\n",
      "Epoch [4/10], Step [1401/119], Loss: 1.1157\n",
      "Epoch [4/10], Step [1501/119], Loss: 1.0585\n",
      "Epoch [4/10], Step [1601/119], Loss: 1.0266\n",
      "Epoch [4/10], Step [1701/119], Loss: 1.0004\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.9766\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.9548\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.9333\n",
      "Epoch [4/10], Step [2101/119], Loss: 0.7160\n",
      "Epoch [4/10], Step [2201/119], Loss: 0.5218\n",
      "Epoch [4/10], Step [2301/119], Loss: 0.5275\n",
      "Epoch [4/10], Step [2401/119], Loss: 0.5339\n",
      "Epoch [4/10], Step [2501/119], Loss: 0.5357\n",
      "Epoch [4/10], Step [2601/119], Loss: 0.5428\n",
      "Epoch [4/10], Step [2701/119], Loss: 0.5418\n",
      "Epoch [4/10], Step [2801/119], Loss: 0.5455\n",
      "Epoch [4/10], Step [2901/119], Loss: 0.5441\n",
      "Epoch [4/10], Step [3001/119], Loss: 0.5481\n",
      "Epoch [4/10], Step [3101/119], Loss: 0.5449\n",
      "Epoch [4/10], Step [3201/119], Loss: 0.5465\n",
      "Epoch [4/10], Step [3301/119], Loss: 0.5467\n",
      "Epoch [4/10], Step [3401/119], Loss: 0.5483\n",
      "Epoch [4/10], Step [3501/119], Loss: 0.5479\n",
      "Epoch [4/10], Step [3601/119], Loss: 0.5429\n",
      "Epoch [4/10], Step [3701/119], Loss: 0.5430\n",
      "Epoch [4/10], Step [3801/119], Loss: 0.5458\n",
      "Epoch [4/10], Step [3901/119], Loss: 0.5438\n",
      "Epoch [4/10], Step [4001/119], Loss: 0.5431\n",
      "Epoch [4/10], Step [4101/119], Loss: 0.5441\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.5393\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.5393\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.5359\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.5365\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.5357\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.5321\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.5349\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.5295\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.5312\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.5289\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.5249\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.5233\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.5220\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.5202\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.5189\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.5105\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.5054\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.4880\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.4772\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.4574\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.4382\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.4106\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.3853\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.3496\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.3328\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.3111\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.2684\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.2361\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.2204\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.1853\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.1684\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.1498\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.1471\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.1069\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.1111\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.0920\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.0826\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.0772\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.0648\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.0581\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.0550\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.0452\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.0400\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.0363\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.0294\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.0313\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.0266\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.0225\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.0245\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.0208\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.0208\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.0168\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.0139\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.0169\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.0162\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.0152\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.0119\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.0136\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0083\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.0130\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0098\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.0105\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0091\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0101\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0100\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0101\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0051\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0070\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0088\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0094\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0104\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0054\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0060\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0066\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0071\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0039\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0054\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0080\n",
      "Epoch [5/10], Step [1/119], Loss: 20.2087\n",
      "Epoch [5/10], Step [101/119], Loss: 16.2719\n",
      "Epoch [5/10], Step [201/119], Loss: 13.7815\n",
      "Epoch [5/10], Step [301/119], Loss: 11.4702\n",
      "Epoch [5/10], Step [401/119], Loss: 8.3193\n",
      "Epoch [5/10], Step [501/119], Loss: 6.6169\n",
      "Epoch [5/10], Step [601/119], Loss: 3.7112\n",
      "Epoch [5/10], Step [701/119], Loss: 2.2520\n",
      "Epoch [5/10], Step [801/119], Loss: 0.6988\n",
      "Epoch [5/10], Step [901/119], Loss: 0.2978\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.1891\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.1245\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.1106\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.0680\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.0668\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.0680\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.0498\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.0364\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.0385\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.0272\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.0369\n",
      "Epoch [5/10], Step [2101/119], Loss: 3.2841\n",
      "Epoch [5/10], Step [2201/119], Loss: 5.9819\n",
      "Epoch [5/10], Step [2301/119], Loss: 5.9578\n",
      "Epoch [5/10], Step [2401/119], Loss: 6.0712\n",
      "Epoch [5/10], Step [2501/119], Loss: 5.8020\n",
      "Epoch [5/10], Step [2601/119], Loss: 5.4394\n",
      "Epoch [5/10], Step [2701/119], Loss: 5.2010\n",
      "Epoch [5/10], Step [2801/119], Loss: 4.6726\n",
      "Epoch [5/10], Step [2901/119], Loss: 3.9511\n",
      "Epoch [5/10], Step [3001/119], Loss: 3.3658\n",
      "Epoch [5/10], Step [3101/119], Loss: 3.2863\n",
      "Epoch [5/10], Step [3201/119], Loss: 2.6523\n",
      "Epoch [5/10], Step [3301/119], Loss: 1.9760\n",
      "Epoch [5/10], Step [3401/119], Loss: 1.8289\n",
      "Epoch [5/10], Step [3501/119], Loss: 1.6643\n",
      "Epoch [5/10], Step [3601/119], Loss: 1.3859\n",
      "Epoch [5/10], Step [3701/119], Loss: 1.1860\n",
      "Epoch [5/10], Step [3801/119], Loss: 1.1036\n",
      "Epoch [5/10], Step [3901/119], Loss: 1.0116\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.9573\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.8562\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.8007\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.7632\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.7434\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.6918\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.6591\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.6519\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.6275\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.6153\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.6107\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.6030\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.5968\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.5926\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.5853\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.5841\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.5805\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.5782\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.5760\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.5720\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.5703\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.5708\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.5659\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.5640\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.5607\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.5593\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.5569\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.5556\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.5550\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.5526\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.5507\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.5487\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.5475\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.5452\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.5445\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.5508\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.5405\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.5387\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.5381\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.5337\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.5353\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.5323\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.5311\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.5286\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.5284\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.5269\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.5254\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.5235\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.5227\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.5208\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.5191\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.5189\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.5175\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.5156\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.5139\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.5134\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.5080\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.5080\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.5084\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.5057\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.5058\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.5042\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.5022\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.5013\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.4996\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.4952\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.4975\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.4949\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.4946\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.4940\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.4909\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.4906\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.4906\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.4872\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.4881\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.4853\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.4827\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.4835\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.4803\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.4766\n",
      "Epoch [6/10], Step [1/119], Loss: 0.9647\n",
      "Epoch [6/10], Step [101/119], Loss: 0.9655\n",
      "Epoch [6/10], Step [201/119], Loss: 0.9713\n",
      "Epoch [6/10], Step [301/119], Loss: 0.9714\n",
      "Epoch [6/10], Step [401/119], Loss: 0.9705\n",
      "Epoch [6/10], Step [501/119], Loss: 0.9693\n",
      "Epoch [6/10], Step [601/119], Loss: 0.9691\n",
      "Epoch [6/10], Step [701/119], Loss: 0.9668\n",
      "Epoch [6/10], Step [801/119], Loss: 0.9691\n",
      "Epoch [6/10], Step [901/119], Loss: 0.9658\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.9631\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.9646\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.9634\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.9587\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.9576\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.9553\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.9547\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.9469\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.9471\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.9461\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.9443\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.7186\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.4970\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.4988\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.4994\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.4994\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.5014\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.5002\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.5023\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.5008\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.5005\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.5021\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.4993\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.5008\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.5007\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.4997\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.4972\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.4973\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.4950\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.4974\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.4941\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.4947\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.4900\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.4921\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.4892\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.4912\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.4884\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.4863\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.4859\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.4858\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.4844\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.4834\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.4807\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.4770\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.4795\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.4768\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.4790\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.4759\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.4741\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.4735\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.4739\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.4687\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.4692\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.4687\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.4665\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.4672\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.4652\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.4628\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.4623\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.4607\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.4588\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.4574\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.4572\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.4549\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.4517\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.4491\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.4520\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.4505\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.4472\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.4430\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.4436\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.4380\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.4277\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.4158\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.4056\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.3846\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.3564\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.3399\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.3235\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.3035\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.2723\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.2504\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.2128\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.1944\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.1532\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.1630\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.1278\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.1097\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.0990\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.0925\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.0640\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0651\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.0550\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0613\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.0474\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.0456\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.0382\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0323\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0227\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.0230\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.0253\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.0225\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.0227\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0148\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.0151\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.0158\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.0146\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0095\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0109\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0117\n",
      "Epoch [7/10], Step [1/119], Loss: 17.6098\n",
      "Epoch [7/10], Step [101/119], Loss: 14.5637\n",
      "Epoch [7/10], Step [201/119], Loss: 12.5877\n",
      "Epoch [7/10], Step [301/119], Loss: 9.4197\n",
      "Epoch [7/10], Step [401/119], Loss: 6.6725\n",
      "Epoch [7/10], Step [501/119], Loss: 5.2015\n",
      "Epoch [7/10], Step [601/119], Loss: 2.5771\n",
      "Epoch [7/10], Step [701/119], Loss: 0.9567\n",
      "Epoch [7/10], Step [801/119], Loss: 0.4794\n",
      "Epoch [7/10], Step [901/119], Loss: 0.2389\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.1808\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.1217\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.1203\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.0710\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.0714\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.0771\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.0583\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.0464\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0467\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.0386\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.0430\n",
      "Epoch [7/10], Step [2101/119], Loss: 3.2909\n",
      "Epoch [7/10], Step [2201/119], Loss: 6.2294\n",
      "Epoch [7/10], Step [2301/119], Loss: 6.0343\n",
      "Epoch [7/10], Step [2401/119], Loss: 6.0844\n",
      "Epoch [7/10], Step [2501/119], Loss: 5.4804\n",
      "Epoch [7/10], Step [2601/119], Loss: 5.2145\n",
      "Epoch [7/10], Step [2701/119], Loss: 4.7258\n",
      "Epoch [7/10], Step [2801/119], Loss: 4.3430\n",
      "Epoch [7/10], Step [2901/119], Loss: 3.6688\n",
      "Epoch [7/10], Step [3001/119], Loss: 2.7758\n",
      "Epoch [7/10], Step [3101/119], Loss: 2.9287\n",
      "Epoch [7/10], Step [3201/119], Loss: 2.2793\n",
      "Epoch [7/10], Step [3301/119], Loss: 1.5736\n",
      "Epoch [7/10], Step [3401/119], Loss: 1.4534\n",
      "Epoch [7/10], Step [3501/119], Loss: 1.2447\n",
      "Epoch [7/10], Step [3601/119], Loss: 1.0500\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.8609\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.7770\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.7125\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.6642\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.6151\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.5765\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.5478\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.5459\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.5226\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.5100\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.5055\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.5006\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.4959\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.4936\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.4908\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.4874\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.4925\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.4839\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.4833\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.4793\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.4801\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.4775\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.4750\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.4728\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.4717\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.4701\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.4689\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.4679\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.4660\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.4638\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.4630\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.4612\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.4600\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.4586\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.4582\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.4558\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.4546\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.4541\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.4651\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.4509\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.4505\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.4485\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.4475\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.4448\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.4455\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.4447\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.4437\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.4408\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.4393\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.4383\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.4352\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.4361\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.4343\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.4334\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.4313\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.4319\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.4300\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.4284\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.4278\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.4256\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.4221\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.4239\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.4227\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.4209\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.4211\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.4193\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.4181\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.4171\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.4175\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.4149\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.4127\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.4120\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.4117\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.4102\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.4092\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.4080\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.4054\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.4045\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.4044\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.4027\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.4025\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.4019\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.3973\n",
      "Epoch [8/10], Step [1/119], Loss: 1.1140\n",
      "Epoch [8/10], Step [101/119], Loss: 1.1129\n",
      "Epoch [8/10], Step [201/119], Loss: 1.1156\n",
      "Epoch [8/10], Step [301/119], Loss: 1.1124\n",
      "Epoch [8/10], Step [401/119], Loss: 1.1171\n",
      "Epoch [8/10], Step [501/119], Loss: 1.1157\n",
      "Epoch [8/10], Step [601/119], Loss: 1.1160\n",
      "Epoch [8/10], Step [701/119], Loss: 1.1127\n",
      "Epoch [8/10], Step [801/119], Loss: 1.1113\n",
      "Epoch [8/10], Step [901/119], Loss: 1.1101\n",
      "Epoch [8/10], Step [1001/119], Loss: 1.1062\n",
      "Epoch [8/10], Step [1101/119], Loss: 1.1019\n",
      "Epoch [8/10], Step [1201/119], Loss: 1.1043\n",
      "Epoch [8/10], Step [1301/119], Loss: 1.0988\n",
      "Epoch [8/10], Step [1401/119], Loss: 1.0929\n",
      "Epoch [8/10], Step [1501/119], Loss: 1.0913\n",
      "Epoch [8/10], Step [1601/119], Loss: 1.0906\n",
      "Epoch [8/10], Step [1701/119], Loss: 1.0884\n",
      "Epoch [8/10], Step [1801/119], Loss: 1.0831\n",
      "Epoch [8/10], Step [1901/119], Loss: 1.0785\n",
      "Epoch [8/10], Step [2001/119], Loss: 1.0775\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.7437\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.4206\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.4208\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.4226\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.4241\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.4249\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.4265\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.4235\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.4264\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.4265\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.4266\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.4251\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.4266\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.4241\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.4243\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.4238\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.4236\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.4233\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.4232\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.4218\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.4202\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.4202\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.4194\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.4162\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.4178\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.4176\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.4152\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.4151\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.4138\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.4124\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.4134\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.4110\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.4081\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.4078\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.4088\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.4073\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.4066\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.4044\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.4038\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.4029\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.4002\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.4019\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.4002\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.3978\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.3979\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.3947\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.3926\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.3846\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.3727\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.3602\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.3406\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.3201\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.2804\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.2788\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.2376\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.2354\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.2056\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.1842\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.1640\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.1476\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.1270\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.1176\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.1029\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.0853\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.0750\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.0617\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.0646\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.0583\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.0535\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.0484\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.0406\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.0379\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.0346\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.0279\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.0326\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.0268\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.0255\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.0217\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.0235\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.0158\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.0199\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.0156\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.0187\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.0143\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.0171\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.0155\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.0151\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.0095\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.0112\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.0122\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.0116\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.0133\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.0102\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.0100\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.0096\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.0109\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0076\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0092\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0106\n",
      "Epoch [9/10], Step [1/119], Loss: 16.7570\n",
      "Epoch [9/10], Step [101/119], Loss: 14.1211\n",
      "Epoch [9/10], Step [201/119], Loss: 11.9706\n",
      "Epoch [9/10], Step [301/119], Loss: 9.8770\n",
      "Epoch [9/10], Step [401/119], Loss: 7.0802\n",
      "Epoch [9/10], Step [501/119], Loss: 5.6527\n",
      "Epoch [9/10], Step [601/119], Loss: 3.2778\n",
      "Epoch [9/10], Step [701/119], Loss: 1.7044\n",
      "Epoch [9/10], Step [801/119], Loss: 0.7011\n",
      "Epoch [9/10], Step [901/119], Loss: 0.3286\n",
      "Epoch [9/10], Step [1001/119], Loss: 0.2281\n",
      "Epoch [9/10], Step [1101/119], Loss: 0.1459\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.1280\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.0792\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.0776\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.0770\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.0640\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.0448\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.0451\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.0300\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.0429\n",
      "Epoch [9/10], Step [2101/119], Loss: 3.5249\n",
      "Epoch [9/10], Step [2201/119], Loss: 6.1205\n",
      "Epoch [9/10], Step [2301/119], Loss: 6.2346\n",
      "Epoch [9/10], Step [2401/119], Loss: 6.3047\n",
      "Epoch [9/10], Step [2501/119], Loss: 5.9317\n",
      "Epoch [9/10], Step [2601/119], Loss: 5.5711\n",
      "Epoch [9/10], Step [2701/119], Loss: 5.2341\n",
      "Epoch [9/10], Step [2801/119], Loss: 4.8542\n",
      "Epoch [9/10], Step [2901/119], Loss: 4.1620\n",
      "Epoch [9/10], Step [3001/119], Loss: 3.3761\n",
      "Epoch [9/10], Step [3101/119], Loss: 3.4650\n",
      "Epoch [9/10], Step [3201/119], Loss: 2.6537\n",
      "Epoch [9/10], Step [3301/119], Loss: 1.9458\n",
      "Epoch [9/10], Step [3401/119], Loss: 1.8352\n",
      "Epoch [9/10], Step [3501/119], Loss: 1.7363\n",
      "Epoch [9/10], Step [3601/119], Loss: 1.3026\n",
      "Epoch [9/10], Step [3701/119], Loss: 1.0730\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.9907\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.8664\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.7987\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.7076\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.6182\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.5942\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.5671\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.5110\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.4707\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.4633\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4460\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4382\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4303\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.4267\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.4278\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.4192\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.4139\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.4141\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.4117\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.4080\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.4073\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.4036\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.4018\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.4030\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.3995\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.3984\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.3996\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.3964\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.3967\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.3939\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.3924\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.3914\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.3913\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.3893\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.3890\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.3878\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.3865\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.3895\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.3841\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.3831\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.3842\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.3835\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.3816\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.3804\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.3805\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.3758\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.3776\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.3789\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.3760\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.3755\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.3739\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.3740\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.3731\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.3731\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.3717\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.3707\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.3684\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.3683\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.3680\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.3650\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.3663\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.3658\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.3649\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.3639\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.3624\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.3623\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.3608\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.3582\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.3580\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.3591\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.3573\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.3559\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.3563\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.3554\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.3544\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.3542\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.3510\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.3524\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.3521\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.3507\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.3505\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.3486\n",
      "Epoch [10/10], Step [1/119], Loss: 1.2215\n",
      "Epoch [10/10], Step [101/119], Loss: 1.2220\n",
      "Epoch [10/10], Step [201/119], Loss: 1.2254\n",
      "Epoch [10/10], Step [301/119], Loss: 1.2249\n",
      "Epoch [10/10], Step [401/119], Loss: 1.2228\n",
      "Epoch [10/10], Step [501/119], Loss: 1.2244\n",
      "Epoch [10/10], Step [601/119], Loss: 1.2228\n",
      "Epoch [10/10], Step [701/119], Loss: 1.2213\n",
      "Epoch [10/10], Step [801/119], Loss: 1.2207\n",
      "Epoch [10/10], Step [901/119], Loss: 1.2177\n",
      "Epoch [10/10], Step [1001/119], Loss: 1.2124\n",
      "Epoch [10/10], Step [1101/119], Loss: 1.2119\n",
      "Epoch [10/10], Step [1201/119], Loss: 1.2091\n",
      "Epoch [10/10], Step [1301/119], Loss: 1.2081\n",
      "Epoch [10/10], Step [1401/119], Loss: 1.2054\n",
      "Epoch [10/10], Step [1501/119], Loss: 1.2011\n",
      "Epoch [10/10], Step [1601/119], Loss: 1.1980\n",
      "Epoch [10/10], Step [1701/119], Loss: 1.1954\n",
      "Epoch [10/10], Step [1801/119], Loss: 1.1924\n",
      "Epoch [10/10], Step [1901/119], Loss: 1.1900\n",
      "Epoch [10/10], Step [2001/119], Loss: 1.1877\n",
      "Epoch [10/10], Step [2101/119], Loss: 0.7740\n",
      "Epoch [10/10], Step [2201/119], Loss: 0.3670\n",
      "Epoch [10/10], Step [2301/119], Loss: 0.3693\n",
      "Epoch [10/10], Step [2401/119], Loss: 0.3688\n",
      "Epoch [10/10], Step [2501/119], Loss: 0.3705\n",
      "Epoch [10/10], Step [2601/119], Loss: 0.3712\n",
      "Epoch [10/10], Step [2701/119], Loss: 0.3700\n",
      "Epoch [10/10], Step [2801/119], Loss: 0.3693\n",
      "Epoch [10/10], Step [2901/119], Loss: 0.3723\n",
      "Epoch [10/10], Step [3001/119], Loss: 0.3727\n",
      "Epoch [10/10], Step [3101/119], Loss: 0.3722\n",
      "Epoch [10/10], Step [3201/119], Loss: 0.3724\n",
      "Epoch [10/10], Step [3301/119], Loss: 0.3713\n",
      "Epoch [10/10], Step [3401/119], Loss: 0.3715\n",
      "Epoch [10/10], Step [3501/119], Loss: 0.3717\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.3701\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.3714\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.3700\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.3712\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.3695\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.3678\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.3675\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.3677\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.3654\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.3664\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.3664\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.3643\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.3647\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.3635\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.3649\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.3622\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.3595\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.3524\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.3479\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.3444\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.3316\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.3103\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.3058\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.2799\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.2579\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.2534\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.2228\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.2022\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.1968\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.1714\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.1639\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.1518\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.1341\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.1121\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.1138\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.0985\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.0838\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.0806\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.0791\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.0580\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.0617\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.0534\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.0496\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.0432\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.0427\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.0416\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.0390\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.0319\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.0259\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.0271\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.0217\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.0228\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.0212\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.0192\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.0222\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.0179\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.0178\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.0151\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.0132\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.0150\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.0133\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.0145\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.0114\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.0133\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.0086\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.0127\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.0088\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.0133\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.0096\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.0106\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.0110\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.0101\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.0057\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.0077\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.0085\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.0088\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.0114\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.0093\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.0078\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.0072\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.0080\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.0048\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.0064\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.0055\n",
      "Epoch [1/10], Step [1/119], Loss: 0.7383\n",
      "Epoch [1/10], Step [101/119], Loss: 0.5593\n",
      "Epoch [1/10], Step [201/119], Loss: 0.4493\n",
      "Epoch [1/10], Step [301/119], Loss: 0.3586\n",
      "Epoch [1/10], Step [401/119], Loss: 0.3056\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1953\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1912\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1286\n",
      "Epoch [1/10], Step [801/119], Loss: 0.1480\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0779\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0692\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0462\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0413\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0238\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0209\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0192\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0116\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0081\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0064\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0035\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0042\n",
      "Epoch [1/10], Step [2101/119], Loss: 7.3299\n",
      "Epoch [1/10], Step [2201/119], Loss: 12.9225\n",
      "Epoch [1/10], Step [2301/119], Loss: 12.4806\n",
      "Epoch [1/10], Step [2401/119], Loss: 11.3685\n",
      "Epoch [1/10], Step [2501/119], Loss: 9.5796\n",
      "Epoch [1/10], Step [2601/119], Loss: 8.2742\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.1638\n",
      "Epoch [1/10], Step [2801/119], Loss: 5.7787\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.3457\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.0683\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.6718\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.7310\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.1733\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9565\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.8215\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.7472\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.7136\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.7026\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.6851\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.6825\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.6715\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.6708\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.6690\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.6726\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.6608\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.6561\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.6553\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.6537\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.6446\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.6449\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.6400\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.6400\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.6301\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.6278\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.6184\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.6105\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.5897\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.5704\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.5425\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.5242\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.4970\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.4617\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.4462\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.3958\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.3629\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.3525\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.3048\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.2911\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.2679\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.2451\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.2050\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.1932\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.1903\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.1631\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.1599\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.1643\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.1390\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.1147\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.1004\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.1014\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.0875\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.0691\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.0857\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.0795\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0555\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.0602\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0508\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0608\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0467\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0436\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0362\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0340\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0294\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0257\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0289\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0270\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0250\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0195\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0231\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0154\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0212\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0158\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0230\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0151\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0179\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0149\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0129\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0086\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0085\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0122\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0114\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0113\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0082\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0089\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0080\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0078\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0049\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0064\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0064\n",
      "Epoch [2/10], Step [1/119], Loss: 21.2174\n",
      "Epoch [2/10], Step [101/119], Loss: 18.7465\n",
      "Epoch [2/10], Step [201/119], Loss: 16.9105\n",
      "Epoch [2/10], Step [301/119], Loss: 14.6397\n",
      "Epoch [2/10], Step [401/119], Loss: 12.2803\n",
      "Epoch [2/10], Step [501/119], Loss: 12.4652\n",
      "Epoch [2/10], Step [601/119], Loss: 9.5795\n",
      "Epoch [2/10], Step [701/119], Loss: 9.3358\n",
      "Epoch [2/10], Step [801/119], Loss: 5.1046\n",
      "Epoch [2/10], Step [901/119], Loss: 5.6422\n",
      "Epoch [2/10], Step [1001/119], Loss: 4.9025\n",
      "Epoch [2/10], Step [1101/119], Loss: 4.1856\n",
      "Epoch [2/10], Step [1201/119], Loss: 2.7828\n",
      "Epoch [2/10], Step [1301/119], Loss: 2.4697\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.7920\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.4172\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.9296\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.8132\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.6492\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.4844\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.4502\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.7698\n",
      "Epoch [2/10], Step [2201/119], Loss: 1.1518\n",
      "Epoch [2/10], Step [2301/119], Loss: 1.2025\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.3423\n",
      "Epoch [2/10], Step [2501/119], Loss: 1.2440\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.2930\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.2621\n",
      "Epoch [2/10], Step [2801/119], Loss: 1.2638\n",
      "Epoch [2/10], Step [2901/119], Loss: 1.1807\n",
      "Epoch [2/10], Step [3001/119], Loss: 1.1571\n",
      "Epoch [2/10], Step [3101/119], Loss: 1.1612\n",
      "Epoch [2/10], Step [3201/119], Loss: 1.0983\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.9367\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.9183\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.9288\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.8671\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.8082\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.8058\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.7645\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.7445\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.7229\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.6965\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.6774\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.6690\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.6574\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.6430\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.6335\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.6244\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.6102\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.5938\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.5771\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.5607\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.5268\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.4960\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.4884\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.4558\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.3857\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.3858\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.3413\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.3393\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.3032\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.2846\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.2906\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.2556\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.2333\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.2262\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.1941\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.1891\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.1732\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.1624\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.1428\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.1364\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.1403\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.1249\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.1169\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.1172\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0938\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0807\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0714\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0748\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0651\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0486\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0661\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0591\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0425\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0462\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0338\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0466\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0357\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0327\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0266\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0240\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0214\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0195\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0211\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0193\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0180\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0144\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0173\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0100\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0161\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0083\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0121\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0083\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0112\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0094\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0108\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0049\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0066\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0078\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0080\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0079\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0049\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0048\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0044\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0056\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0038\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0033\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0034\n",
      "Epoch [3/10], Step [1/119], Loss: 23.1022\n",
      "Epoch [3/10], Step [101/119], Loss: 20.7476\n",
      "Epoch [3/10], Step [201/119], Loss: 18.0848\n",
      "Epoch [3/10], Step [301/119], Loss: 15.7635\n",
      "Epoch [3/10], Step [401/119], Loss: 12.5325\n",
      "Epoch [3/10], Step [501/119], Loss: 11.8278\n",
      "Epoch [3/10], Step [601/119], Loss: 8.5426\n",
      "Epoch [3/10], Step [701/119], Loss: 8.3557\n",
      "Epoch [3/10], Step [801/119], Loss: 4.0784\n",
      "Epoch [3/10], Step [901/119], Loss: 4.2567\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.8544\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.9170\n",
      "Epoch [3/10], Step [1201/119], Loss: 1.0535\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.5623\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.3776\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.3023\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.2291\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.1746\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.1537\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1347\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1390\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.5632\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.7059\n",
      "Epoch [3/10], Step [2301/119], Loss: 2.8238\n",
      "Epoch [3/10], Step [2401/119], Loss: 2.8957\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.9701\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.8648\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.7842\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.7537\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.4377\n",
      "Epoch [3/10], Step [3001/119], Loss: 2.1810\n",
      "Epoch [3/10], Step [3101/119], Loss: 2.1904\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.8929\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.5472\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.5129\n",
      "Epoch [3/10], Step [3501/119], Loss: 1.4493\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.3260\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.2184\n",
      "Epoch [3/10], Step [3801/119], Loss: 1.1209\n",
      "Epoch [3/10], Step [3901/119], Loss: 1.0769\n",
      "Epoch [3/10], Step [4001/119], Loss: 1.0393\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.9732\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.9104\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.8697\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.8831\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.7943\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.7280\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.7070\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.6778\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.6407\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.6040\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.5771\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.5508\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.5099\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.4658\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.4616\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.4253\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.3629\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.3615\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.3077\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.3081\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.2808\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.2655\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.2717\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.2356\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.2179\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.2163\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.1802\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.1785\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.1739\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.1602\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.1316\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.1349\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.1365\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.1258\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.1249\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.1210\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.1060\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.0984\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.0920\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.0874\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.0778\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0654\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0832\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0803\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0609\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0671\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0535\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0656\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0531\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0522\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0463\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0447\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0420\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0351\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0452\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0387\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0384\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0363\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0399\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0265\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0361\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0264\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0344\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0313\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0337\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0308\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0317\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0218\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0235\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0287\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0252\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0287\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0216\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0232\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0235\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0252\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0171\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0219\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0202\n",
      "Epoch [4/10], Step [1/119], Loss: 14.3653\n",
      "Epoch [4/10], Step [101/119], Loss: 12.2868\n",
      "Epoch [4/10], Step [201/119], Loss: 11.0639\n",
      "Epoch [4/10], Step [301/119], Loss: 9.1825\n",
      "Epoch [4/10], Step [401/119], Loss: 7.2010\n",
      "Epoch [4/10], Step [501/119], Loss: 6.4909\n",
      "Epoch [4/10], Step [601/119], Loss: 4.3855\n",
      "Epoch [4/10], Step [701/119], Loss: 3.6834\n",
      "Epoch [4/10], Step [801/119], Loss: 1.6685\n",
      "Epoch [4/10], Step [901/119], Loss: 1.0418\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.5088\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.2979\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.2385\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.1482\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.1417\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.1316\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.1077\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0771\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0771\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0613\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0746\n",
      "Epoch [4/10], Step [2101/119], Loss: 2.6078\n",
      "Epoch [4/10], Step [2201/119], Loss: 4.6300\n",
      "Epoch [4/10], Step [2301/119], Loss: 4.6780\n",
      "Epoch [4/10], Step [2401/119], Loss: 5.0049\n",
      "Epoch [4/10], Step [2501/119], Loss: 4.7563\n",
      "Epoch [4/10], Step [2601/119], Loss: 4.7103\n",
      "Epoch [4/10], Step [2701/119], Loss: 4.3809\n",
      "Epoch [4/10], Step [2801/119], Loss: 4.4010\n",
      "Epoch [4/10], Step [2901/119], Loss: 3.7651\n",
      "Epoch [4/10], Step [3001/119], Loss: 3.2802\n",
      "Epoch [4/10], Step [3101/119], Loss: 3.5192\n",
      "Epoch [4/10], Step [3201/119], Loss: 2.8322\n",
      "Epoch [4/10], Step [3301/119], Loss: 2.2395\n",
      "Epoch [4/10], Step [3401/119], Loss: 2.2816\n",
      "Epoch [4/10], Step [3501/119], Loss: 2.0898\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.7095\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.5912\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.4165\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.3690\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.3038\n",
      "Epoch [4/10], Step [4101/119], Loss: 1.0920\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.9946\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.9712\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.8946\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.7931\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.6784\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.6416\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.6050\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.5683\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.5299\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.5024\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.4667\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.4371\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.3859\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.3921\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.3673\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.3045\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.3184\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.2757\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.2825\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.2563\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.2431\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.2507\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.2205\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.2101\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.1996\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.1709\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.1725\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.1691\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.1617\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.1340\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.1368\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.1327\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.1281\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.1262\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.1269\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.1049\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.0988\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.0904\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.0905\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.0833\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.0667\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.0873\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.0771\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.0622\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.0675\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.0597\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.0729\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.0547\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.0546\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.0476\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.0487\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.0418\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.0365\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.0430\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.0386\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.0369\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.0352\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.0399\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0267\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.0347\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0276\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.0370\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0273\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0327\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0328\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0269\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0198\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0208\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0274\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0243\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0281\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0203\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0218\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0215\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0230\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0165\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0214\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0161\n",
      "Epoch [5/10], Step [1/119], Loss: 14.0962\n",
      "Epoch [5/10], Step [101/119], Loss: 12.1057\n",
      "Epoch [5/10], Step [201/119], Loss: 10.2316\n",
      "Epoch [5/10], Step [301/119], Loss: 8.5272\n",
      "Epoch [5/10], Step [401/119], Loss: 6.0818\n",
      "Epoch [5/10], Step [501/119], Loss: 4.9476\n",
      "Epoch [5/10], Step [601/119], Loss: 2.7858\n",
      "Epoch [5/10], Step [701/119], Loss: 1.3195\n",
      "Epoch [5/10], Step [801/119], Loss: 0.5833\n",
      "Epoch [5/10], Step [901/119], Loss: 0.2556\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.1725\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.1202\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.1001\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.0598\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.0635\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.0604\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.0471\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.0326\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.0333\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.0243\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.0355\n",
      "Epoch [5/10], Step [2101/119], Loss: 3.9675\n",
      "Epoch [5/10], Step [2201/119], Loss: 6.8913\n",
      "Epoch [5/10], Step [2301/119], Loss: 7.2533\n",
      "Epoch [5/10], Step [2401/119], Loss: 7.1938\n",
      "Epoch [5/10], Step [2501/119], Loss: 6.6226\n",
      "Epoch [5/10], Step [2601/119], Loss: 6.6802\n",
      "Epoch [5/10], Step [2701/119], Loss: 6.3925\n",
      "Epoch [5/10], Step [2801/119], Loss: 5.8674\n",
      "Epoch [5/10], Step [2901/119], Loss: 4.9546\n",
      "Epoch [5/10], Step [3001/119], Loss: 4.1772\n",
      "Epoch [5/10], Step [3101/119], Loss: 4.3375\n",
      "Epoch [5/10], Step [3201/119], Loss: 3.4358\n",
      "Epoch [5/10], Step [3301/119], Loss: 2.6337\n",
      "Epoch [5/10], Step [3401/119], Loss: 2.5958\n",
      "Epoch [5/10], Step [3501/119], Loss: 2.2608\n",
      "Epoch [5/10], Step [3601/119], Loss: 1.8351\n",
      "Epoch [5/10], Step [3701/119], Loss: 1.5957\n",
      "Epoch [5/10], Step [3801/119], Loss: 1.3609\n",
      "Epoch [5/10], Step [3901/119], Loss: 1.2846\n",
      "Epoch [5/10], Step [4001/119], Loss: 1.1902\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.9471\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.8519\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.7444\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.6862\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.6297\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.5675\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.5227\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.4903\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.4666\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.4586\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.4421\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.4375\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.4131\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.3903\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.3910\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.3851\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.3579\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.3619\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.3262\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.3500\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.3303\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.3223\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.3273\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.3023\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.2944\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.2852\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.2658\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.2679\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.2502\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.2416\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.2012\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.2036\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.2049\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.1904\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.1830\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.1861\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.1640\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.1382\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.1317\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.1310\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.1143\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.0947\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.1135\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.1004\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.0824\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.0869\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.0714\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.0868\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.0662\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.0637\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.0561\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.0515\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.0463\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.0404\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.0445\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.0386\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.0354\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.0304\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.0355\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.0244\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.0283\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.0227\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.0263\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.0207\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.0216\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.0203\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.0212\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.0144\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.0145\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.0184\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.0161\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.0153\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.0127\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.0105\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.0122\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.0105\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.0066\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.0079\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0085\n",
      "Epoch [6/10], Step [1/119], Loss: 19.5276\n",
      "Epoch [6/10], Step [101/119], Loss: 15.9358\n",
      "Epoch [6/10], Step [201/119], Loss: 11.9881\n",
      "Epoch [6/10], Step [301/119], Loss: 9.4935\n",
      "Epoch [6/10], Step [401/119], Loss: 5.7475\n",
      "Epoch [6/10], Step [501/119], Loss: 3.1042\n",
      "Epoch [6/10], Step [601/119], Loss: 0.6200\n",
      "Epoch [6/10], Step [701/119], Loss: 0.2064\n",
      "Epoch [6/10], Step [801/119], Loss: 0.1557\n",
      "Epoch [6/10], Step [901/119], Loss: 0.0650\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.0553\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.0299\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.0266\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.0150\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.0147\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.0144\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.0111\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.0093\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.0090\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.0040\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.0068\n",
      "Epoch [6/10], Step [2101/119], Loss: 6.3695\n",
      "Epoch [6/10], Step [2201/119], Loss: 11.7376\n",
      "Epoch [6/10], Step [2301/119], Loss: 11.9109\n",
      "Epoch [6/10], Step [2401/119], Loss: 12.2993\n",
      "Epoch [6/10], Step [2501/119], Loss: 10.9563\n",
      "Epoch [6/10], Step [2601/119], Loss: 10.3860\n",
      "Epoch [6/10], Step [2701/119], Loss: 9.1519\n",
      "Epoch [6/10], Step [2801/119], Loss: 8.5627\n",
      "Epoch [6/10], Step [2901/119], Loss: 7.0045\n",
      "Epoch [6/10], Step [3001/119], Loss: 5.5055\n",
      "Epoch [6/10], Step [3101/119], Loss: 5.7364\n",
      "Epoch [6/10], Step [3201/119], Loss: 4.5072\n",
      "Epoch [6/10], Step [3301/119], Loss: 3.0422\n",
      "Epoch [6/10], Step [3401/119], Loss: 2.8951\n",
      "Epoch [6/10], Step [3501/119], Loss: 2.4962\n",
      "Epoch [6/10], Step [3601/119], Loss: 2.0183\n",
      "Epoch [6/10], Step [3701/119], Loss: 1.6466\n",
      "Epoch [6/10], Step [3801/119], Loss: 1.3187\n",
      "Epoch [6/10], Step [3901/119], Loss: 1.2193\n",
      "Epoch [6/10], Step [4001/119], Loss: 1.1390\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.8869\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.7283\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.6688\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.6218\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.5205\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.4705\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.4376\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.4088\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.3864\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.3735\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.3573\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.3505\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.3348\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.3084\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.3231\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.3121\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.2685\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.2895\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.2724\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.2833\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.2680\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.2745\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.2798\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.2632\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.2625\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.2652\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.2470\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.2623\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.2505\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.2508\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.2275\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.2281\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.2418\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.2318\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.2408\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.2401\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.2293\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.2212\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.2113\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.2213\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.2173\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.2033\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.2162\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.2162\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.2007\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.2158\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.2026\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.2176\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.2023\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.1901\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.1973\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.1835\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.1945\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.1826\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.1838\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.1765\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.1740\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.1761\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.1823\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.1523\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.1691\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.1607\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.1710\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.1657\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.1569\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.1593\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.1402\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.1263\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.1290\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.1296\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.1242\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.1246\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0990\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.1100\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.1022\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.1006\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0690\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0826\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0744\n",
      "Epoch [7/10], Step [1/119], Loss: 6.4524\n",
      "Epoch [7/10], Step [101/119], Loss: 5.8850\n",
      "Epoch [7/10], Step [201/119], Loss: 5.2163\n",
      "Epoch [7/10], Step [301/119], Loss: 4.5214\n",
      "Epoch [7/10], Step [401/119], Loss: 3.7829\n",
      "Epoch [7/10], Step [501/119], Loss: 3.6846\n",
      "Epoch [7/10], Step [601/119], Loss: 2.9662\n",
      "Epoch [7/10], Step [701/119], Loss: 2.9313\n",
      "Epoch [7/10], Step [801/119], Loss: 2.0032\n",
      "Epoch [7/10], Step [901/119], Loss: 2.1999\n",
      "Epoch [7/10], Step [1001/119], Loss: 1.8282\n",
      "Epoch [7/10], Step [1101/119], Loss: 1.7533\n",
      "Epoch [7/10], Step [1201/119], Loss: 1.4445\n",
      "Epoch [7/10], Step [1301/119], Loss: 1.3123\n",
      "Epoch [7/10], Step [1401/119], Loss: 1.2223\n",
      "Epoch [7/10], Step [1501/119], Loss: 1.1129\n",
      "Epoch [7/10], Step [1601/119], Loss: 1.0834\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.9895\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.9724\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.9185\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.8933\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.6897\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.5325\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.5477\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.5487\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.5621\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.5578\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.5547\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.5599\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.5607\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.5460\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.5439\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.5394\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.5207\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.5209\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.5162\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.5125\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.5184\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.5108\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.5090\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.5046\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.5084\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.4999\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.5053\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.5050\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.5031\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.4997\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.4943\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.4947\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.4904\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.4911\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.4858\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.4857\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.4842\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.4855\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.4810\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.4804\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.4777\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.4766\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.4763\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.4769\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.4701\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.4676\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.4654\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.4661\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.4638\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.4609\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.4575\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.4595\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.4560\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.4535\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.4532\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.4503\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.4486\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.4454\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.4471\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.4437\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.4399\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.4424\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.4397\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.4438\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.4359\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.4353\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.4317\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.4309\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.4348\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.4281\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.4245\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.4240\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.4227\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.4249\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.4202\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.4172\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.4171\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.4139\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.4126\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.4125\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.4040\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.4051\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.4035\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.4015\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.4055\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.4002\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.3969\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.4008\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.3866\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.3975\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.3934\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.3911\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.3889\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.3879\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.3851\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.3863\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.3780\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.3841\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.3780\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.3739\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.3789\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.3771\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.3535\n",
      "Epoch [8/10], Step [1/119], Loss: 1.1639\n",
      "Epoch [8/10], Step [101/119], Loss: 1.1602\n",
      "Epoch [8/10], Step [201/119], Loss: 1.1547\n",
      "Epoch [8/10], Step [301/119], Loss: 1.1668\n",
      "Epoch [8/10], Step [401/119], Loss: 1.1660\n",
      "Epoch [8/10], Step [501/119], Loss: 1.1696\n",
      "Epoch [8/10], Step [601/119], Loss: 1.1452\n",
      "Epoch [8/10], Step [701/119], Loss: 1.1629\n",
      "Epoch [8/10], Step [801/119], Loss: 1.1644\n",
      "Epoch [8/10], Step [901/119], Loss: 1.1477\n",
      "Epoch [8/10], Step [1001/119], Loss: 1.1302\n",
      "Epoch [8/10], Step [1101/119], Loss: 1.1343\n",
      "Epoch [8/10], Step [1201/119], Loss: 1.1469\n",
      "Epoch [8/10], Step [1301/119], Loss: 1.1230\n",
      "Epoch [8/10], Step [1401/119], Loss: 1.1191\n",
      "Epoch [8/10], Step [1501/119], Loss: 1.1307\n",
      "Epoch [8/10], Step [1601/119], Loss: 1.1147\n",
      "Epoch [8/10], Step [1701/119], Loss: 1.1060\n",
      "Epoch [8/10], Step [1801/119], Loss: 1.0917\n",
      "Epoch [8/10], Step [1901/119], Loss: 1.0967\n",
      "Epoch [8/10], Step [2001/119], Loss: 1.0902\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.7432\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.4099\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.4126\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.4138\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.4131\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.4238\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.4198\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.4202\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.4218\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.4176\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.4200\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.4176\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.4183\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.4224\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.4186\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.4138\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.4166\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.4181\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.4150\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.4155\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.4119\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.4134\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.4124\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.4133\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.4117\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.4102\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.4053\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.4055\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.4101\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.4009\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.4028\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.4010\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.3993\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.3944\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.3932\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.3939\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.3923\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.3872\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.3842\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.3832\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.3782\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.3667\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.3563\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.3441\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.3378\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.3183\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.2915\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.2868\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.2592\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.2520\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.2106\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.2076\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.1946\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.1744\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.1680\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.1549\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.1324\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.1115\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.0989\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.0974\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.0851\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.0677\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.0829\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.0708\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.0505\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.0572\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.0468\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.0546\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.0399\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.0411\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.0319\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.0326\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.0236\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.0208\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.0275\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.0223\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.0213\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.0198\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.0193\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.0152\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.0162\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.0120\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.0165\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.0126\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.0150\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.0132\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.0126\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.0093\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.0096\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.0117\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.0093\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.0122\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.0086\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.0083\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.0092\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.0101\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0065\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0080\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0118\n",
      "Epoch [9/10], Step [1/119], Loss: 17.5938\n",
      "Epoch [9/10], Step [101/119], Loss: 14.4487\n",
      "Epoch [9/10], Step [201/119], Loss: 11.6252\n",
      "Epoch [9/10], Step [301/119], Loss: 8.1389\n",
      "Epoch [9/10], Step [401/119], Loss: 5.1176\n",
      "Epoch [9/10], Step [501/119], Loss: 2.7622\n",
      "Epoch [9/10], Step [601/119], Loss: 0.6655\n",
      "Epoch [9/10], Step [701/119], Loss: 0.2410\n",
      "Epoch [9/10], Step [801/119], Loss: 0.2063\n",
      "Epoch [9/10], Step [901/119], Loss: 0.0809\n",
      "Epoch [9/10], Step [1001/119], Loss: 0.0765\n",
      "Epoch [9/10], Step [1101/119], Loss: 0.0440\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.0369\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.0191\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.0250\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.0229\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.0181\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.0113\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.0134\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.0091\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.0119\n",
      "Epoch [9/10], Step [2101/119], Loss: 5.3979\n",
      "Epoch [9/10], Step [2201/119], Loss: 10.4383\n",
      "Epoch [9/10], Step [2301/119], Loss: 10.1095\n",
      "Epoch [9/10], Step [2401/119], Loss: 10.4395\n",
      "Epoch [9/10], Step [2501/119], Loss: 9.2063\n",
      "Epoch [9/10], Step [2601/119], Loss: 8.8989\n",
      "Epoch [9/10], Step [2701/119], Loss: 8.0124\n",
      "Epoch [9/10], Step [2801/119], Loss: 7.4328\n",
      "Epoch [9/10], Step [2901/119], Loss: 6.2678\n",
      "Epoch [9/10], Step [3001/119], Loss: 4.8820\n",
      "Epoch [9/10], Step [3101/119], Loss: 5.3226\n",
      "Epoch [9/10], Step [3201/119], Loss: 3.9194\n",
      "Epoch [9/10], Step [3301/119], Loss: 2.7035\n",
      "Epoch [9/10], Step [3401/119], Loss: 2.6776\n",
      "Epoch [9/10], Step [3501/119], Loss: 2.3730\n",
      "Epoch [9/10], Step [3601/119], Loss: 1.8362\n",
      "Epoch [9/10], Step [3701/119], Loss: 1.5610\n",
      "Epoch [9/10], Step [3801/119], Loss: 1.2591\n",
      "Epoch [9/10], Step [3901/119], Loss: 1.1794\n",
      "Epoch [9/10], Step [4001/119], Loss: 1.0879\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.8560\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.7476\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.7272\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.6384\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.5847\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.5227\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.4946\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4833\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4576\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4379\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.4314\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.4184\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.4101\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.4036\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.4005\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.3959\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.3958\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.3903\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.3835\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.3879\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.3848\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.3776\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.3755\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.3738\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.3764\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.3761\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.3704\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.3684\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.3675\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.3674\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.3604\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.3557\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.3613\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.3607\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.3605\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.3566\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.3508\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.3504\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.3446\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.3445\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.3354\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.3165\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.3129\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.2978\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.2824\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.2783\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.2563\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.2531\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.2310\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.2089\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.1963\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.1739\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.1664\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.1413\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.1490\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.1238\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.1117\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.1036\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.1019\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0770\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0813\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0748\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0766\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0626\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0634\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0592\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0476\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0369\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0407\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0456\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0402\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0382\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0306\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0332\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0306\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0298\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0210\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0268\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0274\n",
      "Epoch [10/10], Step [1/119], Loss: 11.2233\n",
      "Epoch [10/10], Step [101/119], Loss: 9.5403\n",
      "Epoch [10/10], Step [201/119], Loss: 7.3250\n",
      "Epoch [10/10], Step [301/119], Loss: 5.6030\n",
      "Epoch [10/10], Step [401/119], Loss: 3.5900\n",
      "Epoch [10/10], Step [501/119], Loss: 2.0474\n",
      "Epoch [10/10], Step [601/119], Loss: 0.6677\n",
      "Epoch [10/10], Step [701/119], Loss: 0.3129\n",
      "Epoch [10/10], Step [801/119], Loss: 0.2928\n",
      "Epoch [10/10], Step [901/119], Loss: 0.1550\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.1295\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.0908\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0811\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0474\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0518\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0512\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0404\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0329\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0290\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0210\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0280\n",
      "Epoch [10/10], Step [2101/119], Loss: 4.3474\n",
      "Epoch [10/10], Step [2201/119], Loss: 7.8912\n",
      "Epoch [10/10], Step [2301/119], Loss: 7.9227\n",
      "Epoch [10/10], Step [2401/119], Loss: 7.6018\n",
      "Epoch [10/10], Step [2501/119], Loss: 7.4147\n",
      "Epoch [10/10], Step [2601/119], Loss: 6.7850\n",
      "Epoch [10/10], Step [2701/119], Loss: 6.3364\n",
      "Epoch [10/10], Step [2801/119], Loss: 5.9590\n",
      "Epoch [10/10], Step [2901/119], Loss: 4.6669\n",
      "Epoch [10/10], Step [3001/119], Loss: 3.8449\n",
      "Epoch [10/10], Step [3101/119], Loss: 3.8157\n",
      "Epoch [10/10], Step [3201/119], Loss: 2.8552\n",
      "Epoch [10/10], Step [3301/119], Loss: 2.0015\n",
      "Epoch [10/10], Step [3401/119], Loss: 1.8928\n",
      "Epoch [10/10], Step [3501/119], Loss: 1.5713\n",
      "Epoch [10/10], Step [3601/119], Loss: 1.2675\n",
      "Epoch [10/10], Step [3701/119], Loss: 1.0080\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.8777\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.7621\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.7168\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.5837\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.5188\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.4900\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.4447\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.4257\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.3939\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.3741\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.3640\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.3562\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.3415\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.3446\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.3353\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.3268\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.3183\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.3218\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.3192\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.3158\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.3056\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.2998\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.3145\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.3099\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.3015\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.3034\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.2962\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.3044\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.3003\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.2900\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.2928\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.2916\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.2899\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.2826\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.2829\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.2846\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.2816\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.2807\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.2747\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.2701\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.2719\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.2696\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.2717\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.2700\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.2662\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.2573\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.2649\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.2579\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.2679\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.2461\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.2544\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.2615\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.2460\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.2473\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.2371\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.2511\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.2363\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.2426\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.2426\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.2291\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.2272\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.2240\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.2192\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.2341\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.2200\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.2260\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.2197\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.2121\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.2223\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.2153\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.2046\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.2081\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.2090\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.1971\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.2022\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.1878\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.2018\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.1950\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.1995\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.1894\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.2007\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.1971\n",
      "Epoch [1/10], Step [1/119], Loss: 0.6133\n",
      "Epoch [1/10], Step [101/119], Loss: 0.4503\n",
      "Epoch [1/10], Step [201/119], Loss: 0.3559\n",
      "Epoch [1/10], Step [301/119], Loss: 0.2840\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2292\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1380\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1375\n",
      "Epoch [1/10], Step [701/119], Loss: 0.0906\n",
      "Epoch [1/10], Step [801/119], Loss: 0.1083\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0521\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0488\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0373\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0241\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0144\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0137\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0116\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0081\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0044\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0038\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0028\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0029\n",
      "Epoch [1/10], Step [2101/119], Loss: 8.0184\n",
      "Epoch [1/10], Step [2201/119], Loss: 14.1145\n",
      "Epoch [1/10], Step [2301/119], Loss: 13.6401\n",
      "Epoch [1/10], Step [2401/119], Loss: 12.4046\n",
      "Epoch [1/10], Step [2501/119], Loss: 10.6461\n",
      "Epoch [1/10], Step [2601/119], Loss: 9.0097\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.7126\n",
      "Epoch [1/10], Step [2801/119], Loss: 6.4860\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.8385\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.3404\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.8859\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.9191\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.2154\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9930\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.8495\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.8025\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.7715\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.7534\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.7417\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.7340\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.7278\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.7249\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.7214\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.7343\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.7138\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.7023\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.6990\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.6998\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.6939\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.6860\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.6735\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.6644\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.6515\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.6349\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.6233\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.6053\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.5652\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.5583\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.5354\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.5286\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.4895\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.4766\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.4668\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.4251\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.4129\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.4029\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.3567\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.3605\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.3312\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.3163\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.2815\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.2677\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.2744\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.2379\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.2296\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.2347\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.1978\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.1754\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.1536\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.1521\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.1377\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.1130\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.1413\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.1205\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0963\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.1051\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0866\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0967\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0701\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0572\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0683\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0409\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0501\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0610\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0330\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0350\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0319\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0440\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0231\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0282\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0298\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0227\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0239\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0234\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0186\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0163\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0111\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0102\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0121\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0085\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0119\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0071\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0053\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0071\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0056\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0047\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0044\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0042\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0051\n",
      "Epoch [2/10], Step [1/119], Loss: 24.1154\n",
      "Epoch [2/10], Step [101/119], Loss: 20.2869\n",
      "Epoch [2/10], Step [201/119], Loss: 18.1881\n",
      "Epoch [2/10], Step [301/119], Loss: 16.4325\n",
      "Epoch [2/10], Step [401/119], Loss: 13.2865\n",
      "Epoch [2/10], Step [501/119], Loss: 13.6033\n",
      "Epoch [2/10], Step [601/119], Loss: 10.3067\n",
      "Epoch [2/10], Step [701/119], Loss: 10.1748\n",
      "Epoch [2/10], Step [801/119], Loss: 5.3886\n",
      "Epoch [2/10], Step [901/119], Loss: 6.1900\n",
      "Epoch [2/10], Step [1001/119], Loss: 5.3170\n",
      "Epoch [2/10], Step [1101/119], Loss: 4.5682\n",
      "Epoch [2/10], Step [1201/119], Loss: 3.1652\n",
      "Epoch [2/10], Step [1301/119], Loss: 2.6275\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.9071\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.3786\n",
      "Epoch [2/10], Step [1601/119], Loss: 1.0898\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.7270\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.5883\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.4427\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.4030\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.8387\n",
      "Epoch [2/10], Step [2201/119], Loss: 1.2909\n",
      "Epoch [2/10], Step [2301/119], Loss: 1.3500\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.4877\n",
      "Epoch [2/10], Step [2501/119], Loss: 1.5546\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.5138\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.5054\n",
      "Epoch [2/10], Step [2801/119], Loss: 1.5343\n",
      "Epoch [2/10], Step [2901/119], Loss: 1.4316\n",
      "Epoch [2/10], Step [3001/119], Loss: 1.3498\n",
      "Epoch [2/10], Step [3101/119], Loss: 1.4159\n",
      "Epoch [2/10], Step [3201/119], Loss: 1.3273\n",
      "Epoch [2/10], Step [3301/119], Loss: 1.1719\n",
      "Epoch [2/10], Step [3401/119], Loss: 1.1497\n",
      "Epoch [2/10], Step [3501/119], Loss: 1.0952\n",
      "Epoch [2/10], Step [3601/119], Loss: 1.0524\n",
      "Epoch [2/10], Step [3701/119], Loss: 1.0052\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.9614\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.9323\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.9259\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.8795\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.8290\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.8226\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.8092\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.7391\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.7014\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.6684\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.6227\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.5867\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.5706\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.5287\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.4983\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.4579\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.3960\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.4107\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.3632\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.2886\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.3039\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.2468\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.2540\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.2103\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.2127\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.2128\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.1725\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.1508\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.1508\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.1141\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.1141\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.1008\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.0952\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.0718\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.0771\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.0704\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.0638\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0638\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.0574\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0417\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0395\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0316\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0343\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0296\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0223\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0286\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0248\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0171\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0179\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0128\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0194\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0128\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0085\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0114\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0080\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0113\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0108\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0068\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0073\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0069\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0097\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0054\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0082\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0093\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0068\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0078\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0089\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0085\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0075\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0046\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0040\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0053\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0036\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0071\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0032\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0029\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0044\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0028\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0034\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0032\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0032\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0022\n",
      "Epoch [3/10], Step [1/119], Loss: 24.4973\n",
      "Epoch [3/10], Step [101/119], Loss: 21.1480\n",
      "Epoch [3/10], Step [201/119], Loss: 17.7666\n",
      "Epoch [3/10], Step [301/119], Loss: 15.5525\n",
      "Epoch [3/10], Step [401/119], Loss: 12.8010\n",
      "Epoch [3/10], Step [501/119], Loss: 12.2924\n",
      "Epoch [3/10], Step [601/119], Loss: 8.5481\n",
      "Epoch [3/10], Step [701/119], Loss: 8.0533\n",
      "Epoch [3/10], Step [801/119], Loss: 3.9719\n",
      "Epoch [3/10], Step [901/119], Loss: 4.0860\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.8741\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.8628\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.9410\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.5145\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.3464\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.2724\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.2148\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.1601\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.1484\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1175\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1313\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.5364\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.7931\n",
      "Epoch [3/10], Step [2301/119], Loss: 2.8840\n",
      "Epoch [3/10], Step [2401/119], Loss: 3.0355\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.8562\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.8210\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.6806\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.6635\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.2372\n",
      "Epoch [3/10], Step [3001/119], Loss: 2.0861\n",
      "Epoch [3/10], Step [3101/119], Loss: 2.1293\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.8386\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.4090\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.3793\n",
      "Epoch [3/10], Step [3501/119], Loss: 1.3109\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.1502\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.0327\n",
      "Epoch [3/10], Step [3801/119], Loss: 0.9888\n",
      "Epoch [3/10], Step [3901/119], Loss: 0.9241\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.8767\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.8185\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.7782\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.7382\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.7647\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.6810\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.6610\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.6496\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.6254\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.6128\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.6032\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.5894\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.5871\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.5728\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.5531\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.5574\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.5443\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.5120\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.5194\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.4950\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.4966\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.4822\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.4638\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.4582\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.4224\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.4088\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.3901\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.3464\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.3382\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.3085\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.2850\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.2361\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.2236\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.2204\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.1873\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.1746\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.1756\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.1397\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.1199\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.1032\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.1008\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.0870\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0642\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0802\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0660\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0531\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0484\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0361\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0470\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0308\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0232\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0276\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0175\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0212\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0208\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0146\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0163\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0119\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0159\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0084\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0118\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0131\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0092\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0101\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0120\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0100\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0081\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0058\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0051\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0050\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0041\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0065\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0039\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0035\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0040\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0034\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0031\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0029\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0029\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0028\n",
      "Epoch [4/10], Step [1/119], Loss: 24.7099\n",
      "Epoch [4/10], Step [101/119], Loss: 21.0794\n",
      "Epoch [4/10], Step [201/119], Loss: 17.2311\n",
      "Epoch [4/10], Step [301/119], Loss: 14.3505\n",
      "Epoch [4/10], Step [401/119], Loss: 10.3196\n",
      "Epoch [4/10], Step [501/119], Loss: 8.9616\n",
      "Epoch [4/10], Step [601/119], Loss: 5.3177\n",
      "Epoch [4/10], Step [701/119], Loss: 3.6238\n",
      "Epoch [4/10], Step [801/119], Loss: 1.1525\n",
      "Epoch [4/10], Step [901/119], Loss: 0.3702\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.1992\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.1190\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.0986\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.0625\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.0560\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.0535\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.0409\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0304\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0286\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0227\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0293\n",
      "Epoch [4/10], Step [2101/119], Loss: 3.5628\n",
      "Epoch [4/10], Step [2201/119], Loss: 6.9466\n",
      "Epoch [4/10], Step [2301/119], Loss: 7.1373\n",
      "Epoch [4/10], Step [2401/119], Loss: 7.0622\n",
      "Epoch [4/10], Step [2501/119], Loss: 6.5687\n",
      "Epoch [4/10], Step [2601/119], Loss: 6.1481\n",
      "Epoch [4/10], Step [2701/119], Loss: 5.9313\n",
      "Epoch [4/10], Step [2801/119], Loss: 5.6050\n",
      "Epoch [4/10], Step [2901/119], Loss: 4.6285\n",
      "Epoch [4/10], Step [3001/119], Loss: 3.9914\n",
      "Epoch [4/10], Step [3101/119], Loss: 3.9449\n",
      "Epoch [4/10], Step [3201/119], Loss: 3.4037\n",
      "Epoch [4/10], Step [3301/119], Loss: 2.4265\n",
      "Epoch [4/10], Step [3401/119], Loss: 2.3441\n",
      "Epoch [4/10], Step [3501/119], Loss: 2.1421\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.7580\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.4864\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.2994\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.1872\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.1100\n",
      "Epoch [4/10], Step [4101/119], Loss: 0.9853\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.8927\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.8406\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.8288\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.7396\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.6859\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.6659\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.6474\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.6353\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.6208\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.6130\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.6066\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.6001\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.5968\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.5947\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.5895\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.5898\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.5851\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.5826\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.5820\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.5783\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.5782\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.5759\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.5725\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.5696\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.5687\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.5675\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.5624\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.5649\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.5622\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.5602\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.5561\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.5551\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.5492\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.5427\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.5311\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.5120\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.4866\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.4573\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.4420\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.4109\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.3634\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.3490\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.3099\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.2612\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.2524\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.2137\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.2133\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.1618\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.1215\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.1423\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.0878\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.0905\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.1021\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.0649\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.0661\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.0586\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.0675\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.0385\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0490\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.0428\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0329\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.0384\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0355\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0260\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0255\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0193\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0185\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0178\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0141\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0179\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0124\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0101\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0128\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0097\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0099\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0080\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0077\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0060\n",
      "Epoch [5/10], Step [1/119], Loss: 18.4412\n",
      "Epoch [5/10], Step [101/119], Loss: 16.2267\n",
      "Epoch [5/10], Step [201/119], Loss: 12.9202\n",
      "Epoch [5/10], Step [301/119], Loss: 10.1578\n",
      "Epoch [5/10], Step [401/119], Loss: 7.1653\n",
      "Epoch [5/10], Step [501/119], Loss: 5.3973\n",
      "Epoch [5/10], Step [601/119], Loss: 2.6067\n",
      "Epoch [5/10], Step [701/119], Loss: 0.8479\n",
      "Epoch [5/10], Step [801/119], Loss: 0.3908\n",
      "Epoch [5/10], Step [901/119], Loss: 0.1713\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.1234\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.0840\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.0756\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.0457\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.0444\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.0508\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.0383\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.0276\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.0261\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.0213\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.0281\n",
      "Epoch [5/10], Step [2101/119], Loss: 3.7869\n",
      "Epoch [5/10], Step [2201/119], Loss: 7.1273\n",
      "Epoch [5/10], Step [2301/119], Loss: 7.0307\n",
      "Epoch [5/10], Step [2401/119], Loss: 7.0149\n",
      "Epoch [5/10], Step [2501/119], Loss: 6.5844\n",
      "Epoch [5/10], Step [2601/119], Loss: 6.0574\n",
      "Epoch [5/10], Step [2701/119], Loss: 5.5794\n",
      "Epoch [5/10], Step [2801/119], Loss: 5.1327\n",
      "Epoch [5/10], Step [2901/119], Loss: 4.1646\n",
      "Epoch [5/10], Step [3001/119], Loss: 3.4556\n",
      "Epoch [5/10], Step [3101/119], Loss: 3.2929\n",
      "Epoch [5/10], Step [3201/119], Loss: 2.7333\n",
      "Epoch [5/10], Step [3301/119], Loss: 1.8775\n",
      "Epoch [5/10], Step [3401/119], Loss: 1.7039\n",
      "Epoch [5/10], Step [3501/119], Loss: 1.4929\n",
      "Epoch [5/10], Step [3601/119], Loss: 1.2095\n",
      "Epoch [5/10], Step [3701/119], Loss: 1.0295\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.9239\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.8098\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.7432\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.6950\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.6467\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.6250\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.6193\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.5972\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.5859\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.5823\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.5777\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.5749\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.5719\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.5692\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.5651\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.5635\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.5620\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.5611\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.5580\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.5540\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.5559\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.5529\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.5521\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.5504\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.5490\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.5459\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.5466\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.5447\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.5445\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.5427\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.5412\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.5408\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.5380\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.5390\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.5361\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.5349\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.5340\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.5320\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.5328\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.5296\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.5281\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.5285\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.5274\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.5256\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.5253\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.5235\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.5228\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.5211\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.5200\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.5196\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.5178\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.5163\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.5156\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.5141\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.5132\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.5106\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.5104\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.5082\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.5088\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.5081\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.5065\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.5062\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.5046\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.5024\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.5014\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.5003\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.5065\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.4927\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.4887\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.4811\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.4639\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.4599\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.4399\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.4230\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.3969\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.3760\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.3594\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.3296\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.2979\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.2944\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.2614\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.2668\n",
      "Epoch [6/10], Step [1/119], Loss: 2.6760\n",
      "Epoch [6/10], Step [101/119], Loss: 2.4581\n",
      "Epoch [6/10], Step [201/119], Loss: 2.3738\n",
      "Epoch [6/10], Step [301/119], Loss: 2.1271\n",
      "Epoch [6/10], Step [401/119], Loss: 1.9401\n",
      "Epoch [6/10], Step [501/119], Loss: 1.7763\n",
      "Epoch [6/10], Step [601/119], Loss: 1.6079\n",
      "Epoch [6/10], Step [701/119], Loss: 1.5432\n",
      "Epoch [6/10], Step [801/119], Loss: 1.2169\n",
      "Epoch [6/10], Step [901/119], Loss: 1.2468\n",
      "Epoch [6/10], Step [1001/119], Loss: 1.1602\n",
      "Epoch [6/10], Step [1101/119], Loss: 1.1039\n",
      "Epoch [6/10], Step [1201/119], Loss: 1.0225\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.9890\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.9560\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.9298\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.9063\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.8961\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.8799\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.8743\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.8654\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.7022\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.5392\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.5426\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.5440\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.5443\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.5455\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.5433\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.5447\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.5371\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.5338\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.5331\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.5282\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.5223\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.5200\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.5184\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.5161\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.5171\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.5149\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.5143\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.5132\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.5136\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.5125\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.5125\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.5092\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.5093\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.5096\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.5069\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.5024\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.4989\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.4923\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.4839\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.4776\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.4622\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.4405\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.4350\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.4161\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.3667\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.3593\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.3332\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.3236\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.2957\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.2720\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.2777\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.2392\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.2251\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.2124\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.1834\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.1832\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.1707\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.1634\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.1351\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.1321\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.1341\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.1211\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.1138\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.1173\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.1005\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.0880\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.0774\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.0762\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.0700\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.0582\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.0685\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.0654\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.0435\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.0556\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.0444\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.0567\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.0423\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.0333\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.0429\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.0272\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.0342\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.0409\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.0265\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.0294\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.0276\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.0307\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.0208\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.0295\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0314\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.0248\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0266\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.0274\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.0207\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.0238\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0174\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0191\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.0189\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.0161\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.0207\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.0157\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0117\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.0159\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.0132\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.0123\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0135\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0108\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0129\n",
      "Epoch [7/10], Step [1/119], Loss: 16.0568\n",
      "Epoch [7/10], Step [101/119], Loss: 13.9169\n",
      "Epoch [7/10], Step [201/119], Loss: 10.9858\n",
      "Epoch [7/10], Step [301/119], Loss: 8.3084\n",
      "Epoch [7/10], Step [401/119], Loss: 5.4997\n",
      "Epoch [7/10], Step [501/119], Loss: 3.5564\n",
      "Epoch [7/10], Step [601/119], Loss: 1.1084\n",
      "Epoch [7/10], Step [701/119], Loss: 0.3149\n",
      "Epoch [7/10], Step [801/119], Loss: 0.2410\n",
      "Epoch [7/10], Step [901/119], Loss: 0.1072\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.0829\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.0562\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.0466\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.0271\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.0278\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.0296\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.0218\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.0160\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0141\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.0096\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.0136\n",
      "Epoch [7/10], Step [2101/119], Loss: 5.4897\n",
      "Epoch [7/10], Step [2201/119], Loss: 10.0139\n",
      "Epoch [7/10], Step [2301/119], Loss: 10.3637\n",
      "Epoch [7/10], Step [2401/119], Loss: 10.8118\n",
      "Epoch [7/10], Step [2501/119], Loss: 9.6886\n",
      "Epoch [7/10], Step [2601/119], Loss: 9.4355\n",
      "Epoch [7/10], Step [2701/119], Loss: 8.9466\n",
      "Epoch [7/10], Step [2801/119], Loss: 8.1339\n",
      "Epoch [7/10], Step [2901/119], Loss: 6.7860\n",
      "Epoch [7/10], Step [3001/119], Loss: 5.8056\n",
      "Epoch [7/10], Step [3101/119], Loss: 5.6790\n",
      "Epoch [7/10], Step [3201/119], Loss: 4.5191\n",
      "Epoch [7/10], Step [3301/119], Loss: 3.1934\n",
      "Epoch [7/10], Step [3401/119], Loss: 3.2187\n",
      "Epoch [7/10], Step [3501/119], Loss: 2.8705\n",
      "Epoch [7/10], Step [3601/119], Loss: 2.1285\n",
      "Epoch [7/10], Step [3701/119], Loss: 1.7302\n",
      "Epoch [7/10], Step [3801/119], Loss: 1.5219\n",
      "Epoch [7/10], Step [3901/119], Loss: 1.3693\n",
      "Epoch [7/10], Step [4001/119], Loss: 1.1896\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.9269\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.7765\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.6962\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.6012\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.5222\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.4587\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.4328\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.3929\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.3678\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.3669\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.3527\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.3403\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.3196\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.2965\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.3088\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.2971\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.2632\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.2727\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.2558\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.2663\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.2543\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.2570\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.2682\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.2492\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.2487\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.2446\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.2297\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.2424\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.2307\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.2376\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.2191\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.2208\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.2318\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.2177\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.2227\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.2336\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.2189\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.2046\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.2059\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.2073\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.2022\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.1899\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.2067\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.2034\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.1956\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.1986\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.1910\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.2011\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.1805\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.1611\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.1879\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.1476\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.1518\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.1824\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.1425\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.1519\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.1480\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.1546\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.1258\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.1366\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.1227\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.1161\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.1125\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.1127\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0929\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.1006\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0766\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0851\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.0794\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0709\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.0701\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0637\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0552\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0507\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.0439\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.0417\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.0419\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0334\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0341\n",
      "Epoch [8/10], Step [1/119], Loss: 8.4943\n",
      "Epoch [8/10], Step [101/119], Loss: 7.6025\n",
      "Epoch [8/10], Step [201/119], Loss: 6.9026\n",
      "Epoch [8/10], Step [301/119], Loss: 5.8675\n",
      "Epoch [8/10], Step [401/119], Loss: 4.8611\n",
      "Epoch [8/10], Step [501/119], Loss: 4.7830\n",
      "Epoch [8/10], Step [601/119], Loss: 3.5782\n",
      "Epoch [8/10], Step [701/119], Loss: 3.4028\n",
      "Epoch [8/10], Step [801/119], Loss: 2.1087\n",
      "Epoch [8/10], Step [901/119], Loss: 2.0351\n",
      "Epoch [8/10], Step [1001/119], Loss: 1.6435\n",
      "Epoch [8/10], Step [1101/119], Loss: 1.3295\n",
      "Epoch [8/10], Step [1201/119], Loss: 1.0912\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.8769\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.7793\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.7049\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.6229\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.5619\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.5094\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.4881\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.4726\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.7447\n",
      "Epoch [8/10], Step [2201/119], Loss: 1.0445\n",
      "Epoch [8/10], Step [2301/119], Loss: 1.0398\n",
      "Epoch [8/10], Step [2401/119], Loss: 1.1294\n",
      "Epoch [8/10], Step [2501/119], Loss: 1.1111\n",
      "Epoch [8/10], Step [2601/119], Loss: 1.0468\n",
      "Epoch [8/10], Step [2701/119], Loss: 1.0098\n",
      "Epoch [8/10], Step [2801/119], Loss: 1.0621\n",
      "Epoch [8/10], Step [2901/119], Loss: 1.0089\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.8781\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.8821\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.8364\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.7239\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.7177\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.6846\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.6647\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.6250\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.6176\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.6016\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.5876\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.5871\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.5645\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.5653\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.5935\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.5502\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.5328\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.5388\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.5303\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.5203\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.5162\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.5140\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.5092\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.5075\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.5027\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.5010\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.4979\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.4908\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.4951\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.4933\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.4858\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.4837\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.4827\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.4795\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.4752\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.4729\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.4720\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.4704\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.4714\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.4681\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.4668\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.4632\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.4643\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.4641\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.4597\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.4580\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.4567\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.4559\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.4550\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.4497\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.4504\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.4500\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.4459\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.4492\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.4465\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.4448\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.4424\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.4426\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.4417\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.4380\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.4384\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.4361\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.4333\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.4331\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.4342\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.4286\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.4282\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.4222\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.4153\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.4002\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.3897\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.3629\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.3499\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.3213\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.3183\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.2746\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.2659\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.2399\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.2241\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.2156\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.1865\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.1749\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.1556\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.1292\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.1255\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.1067\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.0954\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0970\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0828\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0868\n",
      "Epoch [9/10], Step [1/119], Loss: 5.9822\n",
      "Epoch [9/10], Step [101/119], Loss: 5.4430\n",
      "Epoch [9/10], Step [201/119], Loss: 4.9557\n",
      "Epoch [9/10], Step [301/119], Loss: 4.3246\n",
      "Epoch [9/10], Step [401/119], Loss: 3.5123\n",
      "Epoch [9/10], Step [501/119], Loss: 3.3710\n",
      "Epoch [9/10], Step [601/119], Loss: 2.6844\n",
      "Epoch [9/10], Step [701/119], Loss: 2.3617\n",
      "Epoch [9/10], Step [801/119], Loss: 1.6237\n",
      "Epoch [9/10], Step [901/119], Loss: 1.5451\n",
      "Epoch [9/10], Step [1001/119], Loss: 1.2993\n",
      "Epoch [9/10], Step [1101/119], Loss: 1.1264\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.9472\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.8463\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.7896\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.7440\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.6804\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.6267\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.5983\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.5630\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.5468\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.7012\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.8859\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.8823\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.9653\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.9528\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.9329\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.9207\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.9550\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.8588\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.7724\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.7989\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.7254\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.6328\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.6191\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.5876\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.5726\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.5543\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.5210\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.5035\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.4857\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.4728\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.4670\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.4640\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.4594\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.4502\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.4457\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.4513\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4440\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4404\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4406\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.4384\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.4362\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.4362\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.4342\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.4335\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.4337\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.4324\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.4302\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.4335\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.4273\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.4214\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.4130\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.4022\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.3904\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.3716\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.3562\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.3279\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.3195\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.2939\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.2720\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.2397\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.2264\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.2202\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.1964\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.1822\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.1809\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.1535\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.1359\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.1169\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.1138\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.0973\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.0819\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.0977\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.0845\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.0649\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.0723\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.0563\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.0699\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.0501\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.0406\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.0499\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.0313\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.0352\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.0436\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.0307\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.0321\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.0294\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.0345\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.0203\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0303\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0280\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0239\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0261\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0269\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0208\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0197\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0167\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0181\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0165\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0137\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0172\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0135\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0116\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0139\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0137\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0117\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0115\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0103\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0089\n",
      "Epoch [10/10], Step [1/119], Loss: 15.4363\n",
      "Epoch [10/10], Step [101/119], Loss: 12.9202\n",
      "Epoch [10/10], Step [201/119], Loss: 10.3842\n",
      "Epoch [10/10], Step [301/119], Loss: 8.0825\n",
      "Epoch [10/10], Step [401/119], Loss: 5.5274\n",
      "Epoch [10/10], Step [501/119], Loss: 3.7043\n",
      "Epoch [10/10], Step [601/119], Loss: 1.2666\n",
      "Epoch [10/10], Step [701/119], Loss: 0.3728\n",
      "Epoch [10/10], Step [801/119], Loss: 0.3015\n",
      "Epoch [10/10], Step [901/119], Loss: 0.1330\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.1124\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.0811\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0712\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0365\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0436\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0405\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0302\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0226\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0199\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0161\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0229\n",
      "Epoch [10/10], Step [2101/119], Loss: 4.8124\n",
      "Epoch [10/10], Step [2201/119], Loss: 8.6329\n",
      "Epoch [10/10], Step [2301/119], Loss: 8.8509\n",
      "Epoch [10/10], Step [2401/119], Loss: 8.6725\n",
      "Epoch [10/10], Step [2501/119], Loss: 8.0009\n",
      "Epoch [10/10], Step [2601/119], Loss: 7.5640\n",
      "Epoch [10/10], Step [2701/119], Loss: 7.1835\n",
      "Epoch [10/10], Step [2801/119], Loss: 6.5939\n",
      "Epoch [10/10], Step [2901/119], Loss: 5.3338\n",
      "Epoch [10/10], Step [3001/119], Loss: 4.5100\n",
      "Epoch [10/10], Step [3101/119], Loss: 4.5350\n",
      "Epoch [10/10], Step [3201/119], Loss: 3.5045\n",
      "Epoch [10/10], Step [3301/119], Loss: 2.4292\n",
      "Epoch [10/10], Step [3401/119], Loss: 2.3434\n",
      "Epoch [10/10], Step [3501/119], Loss: 2.0079\n",
      "Epoch [10/10], Step [3601/119], Loss: 1.6274\n",
      "Epoch [10/10], Step [3701/119], Loss: 1.3060\n",
      "Epoch [10/10], Step [3801/119], Loss: 1.1343\n",
      "Epoch [10/10], Step [3901/119], Loss: 1.0141\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.9534\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.7779\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.6732\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.6386\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.6088\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.5383\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.4932\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.4699\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.4594\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.4397\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.4319\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.4222\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.4160\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.4113\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.4079\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.4032\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.4001\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.3984\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.3969\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.3945\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.3928\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.3911\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.3905\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.3894\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.3887\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.3870\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.3870\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.3862\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.3842\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.3837\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.3830\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.3824\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.3808\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.3799\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.3793\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.3785\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.3780\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.3776\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.3771\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.3769\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.3762\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.3741\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.3739\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.3724\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.3719\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.3719\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.3715\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.3700\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.3700\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.3693\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.3680\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.3658\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.3676\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.3660\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.3636\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.3657\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.3631\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.3637\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.3635\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.3628\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.3610\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.3614\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.3600\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.3603\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.3546\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.3586\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.3579\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.3564\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.3556\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.3544\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.3530\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.3524\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.3534\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.3494\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.3507\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.3507\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.3489\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.3474\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.3480\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.3444\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming your data is loaded into X_train, y_train, X_test, y_test\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 5000\n",
    "hidden_size = 100\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define KFold Cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "accuracies = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    \n",
    "    # Create an instance of the classifier and define loss and optimizer\n",
    "    model = TextClassifier(input_size, hidden_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train_tensor[i:i+batch_size]\n",
    "            y_batch = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train)//batch_size}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = (predicted == y_val_tensor).sum().item() / len(y_val_tensor)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "# Plotting the accuracies\n",
    "plt.plot(range(1, n_splits + 1), accuracies, marker='o')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Each Fold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2785234899328859, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/119], Loss: 0.6633\n",
      "Epoch [1/10], Step [101/119], Loss: 0.5168\n",
      "Epoch [1/10], Step [201/119], Loss: 0.4063\n",
      "Epoch [1/10], Step [301/119], Loss: 0.3432\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2535\n",
      "Epoch [1/10], Step [501/119], Loss: 0.2021\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1388\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1007\n",
      "Epoch [1/10], Step [801/119], Loss: 0.0810\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0638\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0511\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0272\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0169\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0099\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0141\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0066\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0086\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0048\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0030\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0029\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0020\n",
      "Epoch [1/10], Step [2101/119], Loss: 0.0032\n",
      "Epoch [1/10], Step [2201/119], Loss: 0.0012\n",
      "Epoch [1/10], Step [2301/119], Loss: 0.0012\n",
      "Epoch [1/10], Step [2401/119], Loss: 0.0007\n",
      "Epoch [1/10], Step [2501/119], Loss: 0.0010\n",
      "Epoch [1/10], Step [2601/119], Loss: 0.0006\n",
      "Epoch [1/10], Step [2701/119], Loss: 0.0009\n",
      "Epoch [1/10], Step [2801/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [2901/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [3001/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [3101/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [3201/119], Loss: 0.0008\n",
      "Epoch [1/10], Step [3301/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.0011\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.0014\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.0009\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.0007\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.0011\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.0008\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.0035\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.0005\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.0014\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.0029\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.0007\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0004\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0002\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0019\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0003\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0001\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [501/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [601/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [801/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1001/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.0013\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2501/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3001/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [3101/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [3201/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.0005\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.0010\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.0014\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.0009\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.0006\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.0027\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.0012\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.0015\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0002\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0015\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0001\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [401/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.0006\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2101/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3201/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.0004\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.0006\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.0005\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.0005\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.0002\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.0002\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.0032\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.0002\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.0005\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.0012\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.0003\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0002\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0009\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0001\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.0006\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3201/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4101/119], Loss: 0.0002\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.0004\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.0005\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.0004\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.0003\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.0016\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.0003\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.0006\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.0002\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0003\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0001\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.0005\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.0002\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.0003\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.0003\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.0005\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.0002\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.0016\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.0002\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.0004\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.0001\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.0003\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.0002\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.0011\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.0006\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.0001\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0002\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.0001\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.0009\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.0001\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0002\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.0002\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.0002\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.0006\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.0001\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.0004\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.0001\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.0001\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.0004\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.0001\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.0001\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0001\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [2901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.0001\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.0005\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.0002\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.0001\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.0000\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.0000\n",
      "Epoch [1/10], Step [1/119], Loss: 0.6874\n",
      "Epoch [1/10], Step [101/119], Loss: 0.4780\n",
      "Epoch [1/10], Step [201/119], Loss: 0.3646\n",
      "Epoch [1/10], Step [301/119], Loss: 0.2866\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2322\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1429\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1451\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1013\n",
      "Epoch [1/10], Step [801/119], Loss: 0.1069\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0527\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0512\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0337\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0283\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0156\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0148\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0140\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0091\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0056\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0052\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0037\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0038\n",
      "Epoch [1/10], Step [2101/119], Loss: 7.6116\n",
      "Epoch [1/10], Step [2201/119], Loss: 12.7270\n",
      "Epoch [1/10], Step [2301/119], Loss: 12.2356\n",
      "Epoch [1/10], Step [2401/119], Loss: 11.1235\n",
      "Epoch [1/10], Step [2501/119], Loss: 9.7332\n",
      "Epoch [1/10], Step [2601/119], Loss: 8.4438\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.2853\n",
      "Epoch [1/10], Step [2801/119], Loss: 6.1937\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.4125\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.5851\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.2830\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.7511\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.2731\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9239\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.8001\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.7573\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.7375\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.7299\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.7232\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.7125\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.7102\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.7084\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.7014\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.6989\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.6883\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.6833\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.6762\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.6591\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.6506\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.6348\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.6307\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.6094\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.5869\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.5727\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.5593\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.5425\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.5155\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.5141\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.4828\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.4432\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.4351\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.4033\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.3742\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.3754\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.3428\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.3391\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.3287\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.3065\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.2816\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.2730\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.2511\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.2380\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.2224\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.2308\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.1883\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.2001\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.1809\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.1652\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.1581\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.1585\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.1351\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.1478\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.1351\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.1158\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.1090\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.0970\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.1097\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0994\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0972\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0870\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0806\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0760\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0677\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0615\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0691\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0606\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0534\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0499\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0546\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0354\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0443\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0385\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0440\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0340\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0372\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0344\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0312\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0204\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0231\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0246\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0213\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0264\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0183\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0177\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0192\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0188\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0121\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0147\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0139\n",
      "Epoch [2/10], Step [1/119], Loss: 16.9886\n",
      "Epoch [2/10], Step [101/119], Loss: 14.8054\n",
      "Epoch [2/10], Step [201/119], Loss: 13.1108\n",
      "Epoch [2/10], Step [301/119], Loss: 12.2136\n",
      "Epoch [2/10], Step [401/119], Loss: 10.2295\n",
      "Epoch [2/10], Step [501/119], Loss: 10.2211\n",
      "Epoch [2/10], Step [601/119], Loss: 8.5017\n",
      "Epoch [2/10], Step [701/119], Loss: 8.6091\n",
      "Epoch [2/10], Step [801/119], Loss: 4.7269\n",
      "Epoch [2/10], Step [901/119], Loss: 5.7860\n",
      "Epoch [2/10], Step [1001/119], Loss: 4.9190\n",
      "Epoch [2/10], Step [1101/119], Loss: 4.7058\n",
      "Epoch [2/10], Step [1201/119], Loss: 3.1725\n",
      "Epoch [2/10], Step [1301/119], Loss: 3.1715\n",
      "Epoch [2/10], Step [1401/119], Loss: 2.4093\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.9351\n",
      "Epoch [2/10], Step [1601/119], Loss: 1.5869\n",
      "Epoch [2/10], Step [1701/119], Loss: 1.3231\n",
      "Epoch [2/10], Step [1801/119], Loss: 1.0418\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.8804\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.6756\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.7201\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.9422\n",
      "Epoch [2/10], Step [2301/119], Loss: 0.9798\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.0647\n",
      "Epoch [2/10], Step [2501/119], Loss: 1.0947\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.1665\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.1817\n",
      "Epoch [2/10], Step [2801/119], Loss: 1.2088\n",
      "Epoch [2/10], Step [2901/119], Loss: 1.1576\n",
      "Epoch [2/10], Step [3001/119], Loss: 1.2083\n",
      "Epoch [2/10], Step [3101/119], Loss: 1.0781\n",
      "Epoch [2/10], Step [3201/119], Loss: 1.0960\n",
      "Epoch [2/10], Step [3301/119], Loss: 1.0747\n",
      "Epoch [2/10], Step [3401/119], Loss: 1.0702\n",
      "Epoch [2/10], Step [3501/119], Loss: 1.0373\n",
      "Epoch [2/10], Step [3601/119], Loss: 1.0038\n",
      "Epoch [2/10], Step [3701/119], Loss: 1.0055\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.9042\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.8974\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.8628\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.8768\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.8425\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.8042\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.7881\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.7677\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.7364\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.7407\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.7388\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.6985\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.6975\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.6631\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.6431\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.6212\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.5913\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.5624\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.5224\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.4971\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.4973\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.4442\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.3863\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.3777\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.3402\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.3123\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.3129\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.2791\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.2643\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.2653\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.2308\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.2061\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.2016\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.1743\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.1680\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.1602\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.1538\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.1163\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.1355\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.1192\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.1126\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0973\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0929\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0844\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0816\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0710\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0624\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0578\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0482\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0560\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0474\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0424\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0420\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0361\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0355\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0292\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0246\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0298\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0259\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0221\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0233\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0230\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0133\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0203\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0140\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0161\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0147\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0176\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0130\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0137\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0076\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0082\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0099\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0095\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0115\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0080\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0073\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0076\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0071\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0048\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0054\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0060\n",
      "Epoch [3/10], Step [1/119], Loss: 20.9262\n",
      "Epoch [3/10], Step [101/119], Loss: 18.4545\n",
      "Epoch [3/10], Step [201/119], Loss: 16.1205\n",
      "Epoch [3/10], Step [301/119], Loss: 13.8852\n",
      "Epoch [3/10], Step [401/119], Loss: 11.1038\n",
      "Epoch [3/10], Step [501/119], Loss: 10.7442\n",
      "Epoch [3/10], Step [601/119], Loss: 7.9340\n",
      "Epoch [3/10], Step [701/119], Loss: 7.3939\n",
      "Epoch [3/10], Step [801/119], Loss: 3.7052\n",
      "Epoch [3/10], Step [901/119], Loss: 3.9464\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.8204\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.9075\n",
      "Epoch [3/10], Step [1201/119], Loss: 1.0207\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.6827\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.4778\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.3578\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.2579\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.2058\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.1750\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1550\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1580\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.4468\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.4408\n",
      "Epoch [3/10], Step [2301/119], Loss: 2.7295\n",
      "Epoch [3/10], Step [2401/119], Loss: 2.7494\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.6662\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.6619\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.5619\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.6188\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.2398\n",
      "Epoch [3/10], Step [3001/119], Loss: 2.1548\n",
      "Epoch [3/10], Step [3101/119], Loss: 1.8334\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.8209\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.6758\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.5957\n",
      "Epoch [3/10], Step [3501/119], Loss: 1.4017\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.2599\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.2742\n",
      "Epoch [3/10], Step [3801/119], Loss: 1.0421\n",
      "Epoch [3/10], Step [3901/119], Loss: 0.9844\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.9305\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.9278\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.8320\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.7830\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.7462\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.7256\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.6919\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.6845\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.6559\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.6324\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.6144\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.5974\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.5841\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.5613\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.5561\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.5479\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.5332\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.5254\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.5253\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.5094\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.4868\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.4888\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.4703\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.4601\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.4483\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.4273\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.4221\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.4154\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.3835\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.3539\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.3424\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.3275\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.3005\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.2675\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.2781\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.2267\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.2438\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.2039\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.1909\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.1695\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.1691\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.1485\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.1438\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.1264\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.1084\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.1007\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0837\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0848\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0785\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0719\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0678\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0601\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0535\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0431\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0375\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0452\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0374\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0387\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0305\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0328\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0218\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0284\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0227\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0257\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0203\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0214\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0193\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0177\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0123\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0153\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0146\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0132\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0176\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0118\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0093\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0103\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0117\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0075\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0074\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0078\n",
      "Epoch [4/10], Step [1/119], Loss: 19.3474\n",
      "Epoch [4/10], Step [101/119], Loss: 16.8965\n",
      "Epoch [4/10], Step [201/119], Loss: 14.0000\n",
      "Epoch [4/10], Step [301/119], Loss: 11.8065\n",
      "Epoch [4/10], Step [401/119], Loss: 8.9914\n",
      "Epoch [4/10], Step [501/119], Loss: 8.1645\n",
      "Epoch [4/10], Step [601/119], Loss: 5.3326\n",
      "Epoch [4/10], Step [701/119], Loss: 4.1457\n",
      "Epoch [4/10], Step [801/119], Loss: 1.8083\n",
      "Epoch [4/10], Step [901/119], Loss: 1.0144\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.4740\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.2660\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.2185\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.1291\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.1212\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.1160\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.0887\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0667\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0697\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0538\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0634\n",
      "Epoch [4/10], Step [2101/119], Loss: 2.5301\n",
      "Epoch [4/10], Step [2201/119], Loss: 4.6430\n",
      "Epoch [4/10], Step [2301/119], Loss: 4.8292\n",
      "Epoch [4/10], Step [2401/119], Loss: 4.8344\n",
      "Epoch [4/10], Step [2501/119], Loss: 4.6588\n",
      "Epoch [4/10], Step [2601/119], Loss: 4.5721\n",
      "Epoch [4/10], Step [2701/119], Loss: 4.2447\n",
      "Epoch [4/10], Step [2801/119], Loss: 4.1178\n",
      "Epoch [4/10], Step [2901/119], Loss: 3.4776\n",
      "Epoch [4/10], Step [3001/119], Loss: 3.2424\n",
      "Epoch [4/10], Step [3101/119], Loss: 2.6608\n",
      "Epoch [4/10], Step [3201/119], Loss: 2.5406\n",
      "Epoch [4/10], Step [3301/119], Loss: 2.2449\n",
      "Epoch [4/10], Step [3401/119], Loss: 2.0176\n",
      "Epoch [4/10], Step [3501/119], Loss: 1.7449\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.5400\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.5299\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.1452\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.1137\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.0280\n",
      "Epoch [4/10], Step [4101/119], Loss: 1.0414\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.8736\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.7998\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.7635\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.7204\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.6767\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.6740\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.6479\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.6175\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.6057\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.5881\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.5779\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.5629\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.5587\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.5462\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.5402\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.5309\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.5292\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.5172\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.5074\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.5044\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.4956\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.4826\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.4849\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.4784\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.4780\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.4839\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.4607\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.4608\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.4560\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.4395\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.4345\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.4151\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.4154\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.3762\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.3787\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.3515\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.3319\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.2977\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.2792\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.2511\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.2392\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.2129\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.1848\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.1662\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.1371\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.1386\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.1265\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.1242\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.1085\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.0955\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.0878\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.0706\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.0580\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.0692\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.0548\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.0543\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.0488\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.0511\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0315\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.0367\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0296\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.0394\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0273\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0316\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0291\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0260\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0159\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0195\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0223\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0205\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0209\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0191\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0152\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0163\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0171\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0110\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0133\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0134\n",
      "Epoch [5/10], Step [1/119], Loss: 14.6728\n",
      "Epoch [5/10], Step [101/119], Loss: 13.4686\n",
      "Epoch [5/10], Step [201/119], Loss: 11.2104\n",
      "Epoch [5/10], Step [301/119], Loss: 9.2970\n",
      "Epoch [5/10], Step [401/119], Loss: 6.9430\n",
      "Epoch [5/10], Step [501/119], Loss: 5.6646\n",
      "Epoch [5/10], Step [601/119], Loss: 3.2584\n",
      "Epoch [5/10], Step [701/119], Loss: 2.1397\n",
      "Epoch [5/10], Step [801/119], Loss: 0.8476\n",
      "Epoch [5/10], Step [901/119], Loss: 0.3980\n",
      "Epoch [5/10], Step [1001/119], Loss: 0.2498\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.1717\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.1542\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.0963\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.0977\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.0979\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.0807\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.0567\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.0586\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.0455\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.0549\n",
      "Epoch [5/10], Step [2101/119], Loss: 2.6476\n",
      "Epoch [5/10], Step [2201/119], Loss: 4.7345\n",
      "Epoch [5/10], Step [2301/119], Loss: 4.8802\n",
      "Epoch [5/10], Step [2401/119], Loss: 4.9046\n",
      "Epoch [5/10], Step [2501/119], Loss: 4.5681\n",
      "Epoch [5/10], Step [2601/119], Loss: 4.2475\n",
      "Epoch [5/10], Step [2701/119], Loss: 3.8966\n",
      "Epoch [5/10], Step [2801/119], Loss: 3.6967\n",
      "Epoch [5/10], Step [2901/119], Loss: 2.9408\n",
      "Epoch [5/10], Step [3001/119], Loss: 2.7555\n",
      "Epoch [5/10], Step [3101/119], Loss: 2.2315\n",
      "Epoch [5/10], Step [3201/119], Loss: 2.0699\n",
      "Epoch [5/10], Step [3301/119], Loss: 1.7468\n",
      "Epoch [5/10], Step [3401/119], Loss: 1.5791\n",
      "Epoch [5/10], Step [3501/119], Loss: 1.3173\n",
      "Epoch [5/10], Step [3601/119], Loss: 1.1403\n",
      "Epoch [5/10], Step [3701/119], Loss: 1.1029\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.9508\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.8669\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.8100\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.7827\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.7274\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.6822\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.6564\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.6357\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.6141\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.6093\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.5944\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.5853\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.5746\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.5750\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.5689\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.5643\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.5601\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.5734\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.5545\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.5524\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.5498\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.5491\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.5459\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.5424\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.5409\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.5418\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.5388\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.5363\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.5336\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.5329\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.5311\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.5306\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.5296\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.5279\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.5262\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.5236\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.5231\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.5331\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.5201\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.5188\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.5154\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.5168\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.5145\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.5116\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.5105\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.5075\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.5081\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.5072\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.5055\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.5041\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.5033\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.5022\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.4990\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.4959\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.4965\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.4982\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.4923\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.4921\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.4927\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.4864\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.4870\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.4830\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.4846\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.4834\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.4811\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.4808\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.4773\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.4734\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.4748\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.4752\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.4699\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.4716\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.4677\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.4679\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.4633\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.4642\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.4644\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.4569\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.4554\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.4587\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.4564\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.4506\n",
      "Epoch [6/10], Step [1/119], Loss: 1.0196\n",
      "Epoch [6/10], Step [101/119], Loss: 1.0185\n",
      "Epoch [6/10], Step [201/119], Loss: 1.0127\n",
      "Epoch [6/10], Step [301/119], Loss: 1.0130\n",
      "Epoch [6/10], Step [401/119], Loss: 1.0107\n",
      "Epoch [6/10], Step [501/119], Loss: 1.0166\n",
      "Epoch [6/10], Step [601/119], Loss: 1.0033\n",
      "Epoch [6/10], Step [701/119], Loss: 1.0153\n",
      "Epoch [6/10], Step [801/119], Loss: 1.0086\n",
      "Epoch [6/10], Step [901/119], Loss: 1.0070\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.9980\n",
      "Epoch [6/10], Step [1101/119], Loss: 1.0000\n",
      "Epoch [6/10], Step [1201/119], Loss: 1.0000\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.9903\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.9847\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.9902\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.9786\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.9803\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.9726\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.9700\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.9636\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.7188\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.4818\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.4814\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.4828\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.4844\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.4882\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.4886\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.4884\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.4853\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.4896\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.4871\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.4855\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.4856\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.4871\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.4878\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.4861\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.4836\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.4859\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.4831\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.4818\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.4820\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.4768\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.4769\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.4774\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.4753\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.4749\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.4712\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.4729\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.4695\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.4661\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.4574\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.4480\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.4292\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.4123\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.3957\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.3830\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.3565\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.3457\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.3105\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.2731\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.2603\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.2296\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.2070\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.2046\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.1727\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.1633\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.1680\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.1419\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.1168\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.1156\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.1008\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.0973\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.0862\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.0878\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.0644\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.0714\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.0583\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.0507\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.0500\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.0493\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.0443\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.0391\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.0360\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.0326\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.0268\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.0222\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.0257\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.0240\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.0216\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.0215\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.0182\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.0163\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.0160\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.0117\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.0129\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.0111\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.0124\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.0105\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.0106\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.0076\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0091\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.0061\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0102\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.0066\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.0071\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.0051\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0065\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0033\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.0033\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.0050\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.0047\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.0052\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0028\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.0024\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.0024\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.0033\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0020\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0022\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0026\n",
      "Epoch [7/10], Step [1/119], Loss: 25.6195\n",
      "Epoch [7/10], Step [101/119], Loss: 20.4358\n",
      "Epoch [7/10], Step [201/119], Loss: 16.4985\n",
      "Epoch [7/10], Step [301/119], Loss: 12.0649\n",
      "Epoch [7/10], Step [401/119], Loss: 7.4012\n",
      "Epoch [7/10], Step [501/119], Loss: 3.8739\n",
      "Epoch [7/10], Step [601/119], Loss: 0.7569\n",
      "Epoch [7/10], Step [701/119], Loss: 0.1808\n",
      "Epoch [7/10], Step [801/119], Loss: 0.1376\n",
      "Epoch [7/10], Step [901/119], Loss: 0.0517\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.0433\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.0253\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.0178\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.0091\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.0107\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.0101\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.0062\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.0049\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0062\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.0032\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.0054\n",
      "Epoch [7/10], Step [2101/119], Loss: 6.7946\n",
      "Epoch [7/10], Step [2201/119], Loss: 11.9130\n",
      "Epoch [7/10], Step [2301/119], Loss: 12.5041\n",
      "Epoch [7/10], Step [2401/119], Loss: 12.0604\n",
      "Epoch [7/10], Step [2501/119], Loss: 10.9364\n",
      "Epoch [7/10], Step [2601/119], Loss: 10.5989\n",
      "Epoch [7/10], Step [2701/119], Loss: 9.5387\n",
      "Epoch [7/10], Step [2801/119], Loss: 8.7181\n",
      "Epoch [7/10], Step [2901/119], Loss: 6.9856\n",
      "Epoch [7/10], Step [3001/119], Loss: 6.4734\n",
      "Epoch [7/10], Step [3101/119], Loss: 4.7587\n",
      "Epoch [7/10], Step [3201/119], Loss: 4.2485\n",
      "Epoch [7/10], Step [3301/119], Loss: 3.6781\n",
      "Epoch [7/10], Step [3401/119], Loss: 3.1778\n",
      "Epoch [7/10], Step [3501/119], Loss: 2.3350\n",
      "Epoch [7/10], Step [3601/119], Loss: 1.9908\n",
      "Epoch [7/10], Step [3701/119], Loss: 1.9316\n",
      "Epoch [7/10], Step [3801/119], Loss: 1.3400\n",
      "Epoch [7/10], Step [3901/119], Loss: 1.1950\n",
      "Epoch [7/10], Step [4001/119], Loss: 1.0758\n",
      "Epoch [7/10], Step [4101/119], Loss: 1.0654\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.8552\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.7368\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.6888\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.6407\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.5895\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.5806\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.5561\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.5445\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.5106\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.5010\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.4896\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.4835\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.4732\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.4676\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.4669\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.4605\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.4571\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.4516\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.4517\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.4488\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.4469\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.4438\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.4416\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.4418\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.4389\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.4388\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.4375\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.4353\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.4321\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.4301\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.4311\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.4317\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.4286\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.4224\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.4262\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.4247\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.4232\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.4222\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.4186\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.4188\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.4197\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.4131\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.4144\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.4137\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.4107\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.4092\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.4112\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.4086\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.4062\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.4044\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.4027\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.4051\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.3991\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.4026\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.4013\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.3939\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.3916\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.3916\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.3894\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.3891\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.3882\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.3885\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.3870\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.3801\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.3829\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.3803\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.3748\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.3771\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.3728\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.3736\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.3733\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.3691\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.3710\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.3662\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.3661\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.3638\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.3598\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.3583\n",
      "Epoch [8/10], Step [1/119], Loss: 1.2780\n",
      "Epoch [8/10], Step [101/119], Loss: 1.2441\n",
      "Epoch [8/10], Step [201/119], Loss: 1.2256\n",
      "Epoch [8/10], Step [301/119], Loss: 1.2127\n",
      "Epoch [8/10], Step [401/119], Loss: 1.1926\n",
      "Epoch [8/10], Step [501/119], Loss: 1.2223\n",
      "Epoch [8/10], Step [601/119], Loss: 1.1819\n",
      "Epoch [8/10], Step [701/119], Loss: 1.2031\n",
      "Epoch [8/10], Step [801/119], Loss: 1.1863\n",
      "Epoch [8/10], Step [901/119], Loss: 1.1847\n",
      "Epoch [8/10], Step [1001/119], Loss: 1.1630\n",
      "Epoch [8/10], Step [1101/119], Loss: 1.1653\n",
      "Epoch [8/10], Step [1201/119], Loss: 1.1664\n",
      "Epoch [8/10], Step [1301/119], Loss: 1.1516\n",
      "Epoch [8/10], Step [1401/119], Loss: 1.1439\n",
      "Epoch [8/10], Step [1501/119], Loss: 1.1378\n",
      "Epoch [8/10], Step [1601/119], Loss: 1.1407\n",
      "Epoch [8/10], Step [1701/119], Loss: 1.1249\n",
      "Epoch [8/10], Step [1801/119], Loss: 1.1166\n",
      "Epoch [8/10], Step [1901/119], Loss: 1.1118\n",
      "Epoch [8/10], Step [2001/119], Loss: 1.1048\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.7512\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.4044\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.4082\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.4079\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.4070\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.4119\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.4131\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.4133\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.4163\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.4155\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.4121\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.4123\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.4141\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.4133\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.4146\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.4130\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.4135\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.4124\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.4127\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.4109\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.4128\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.4080\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.4062\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.4063\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.4055\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.4052\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.4032\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.4019\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.4032\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.4036\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.3987\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.4015\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.3957\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.3984\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.3950\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.3943\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.3915\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.3916\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.3922\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.3885\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.3863\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.3888\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.3872\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.3851\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.3840\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.3790\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.3817\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.3803\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.3778\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.3758\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.3761\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.3738\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.3773\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.3740\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.3667\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.3714\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.3682\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.3676\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.3652\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.3628\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.3625\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.3615\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.3569\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.3581\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.3592\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.3525\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.3505\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.3546\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.3493\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.3490\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.3460\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.3432\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.3492\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.3385\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.3384\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.3412\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.3317\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.3319\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.3288\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.3248\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.3285\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.3191\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.3152\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.3028\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.2846\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.2782\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.2544\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.2315\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.2235\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.2006\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.1856\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.1703\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.1454\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.1492\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.1261\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.1232\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0929\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0995\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0896\n",
      "Epoch [9/10], Step [1/119], Loss: 5.3364\n",
      "Epoch [9/10], Step [101/119], Loss: 4.9018\n",
      "Epoch [9/10], Step [201/119], Loss: 4.2275\n",
      "Epoch [9/10], Step [301/119], Loss: 3.8642\n",
      "Epoch [9/10], Step [401/119], Loss: 3.2184\n",
      "Epoch [9/10], Step [501/119], Loss: 3.1741\n",
      "Epoch [9/10], Step [601/119], Loss: 2.5210\n",
      "Epoch [9/10], Step [701/119], Loss: 2.3108\n",
      "Epoch [9/10], Step [801/119], Loss: 1.6996\n",
      "Epoch [9/10], Step [901/119], Loss: 1.6101\n",
      "Epoch [9/10], Step [1001/119], Loss: 1.4093\n",
      "Epoch [9/10], Step [1101/119], Loss: 1.3091\n",
      "Epoch [9/10], Step [1201/119], Loss: 1.1643\n",
      "Epoch [9/10], Step [1301/119], Loss: 1.0666\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.9944\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.9447\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.9057\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.8627\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.8257\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.8080\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.7782\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.6853\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.5994\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.6097\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.6334\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.6351\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.6348\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.6413\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.6398\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.6109\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.5890\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.5735\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.5728\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.5427\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.5264\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.5116\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.4942\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.4813\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.4729\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.4668\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.4629\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.4572\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.4542\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.4530\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.4520\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.4502\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.4484\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.4467\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4467\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4444\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4434\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.4412\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.4396\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.4402\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.4372\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.4360\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.4349\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.4354\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.4343\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.4321\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.4315\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.4305\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.4280\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.4266\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.4258\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.4249\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.4258\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.4215\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.4222\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.4192\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.4196\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.4179\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.4161\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.4139\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.4148\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.4120\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.4111\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.4098\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.4107\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.4050\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.4052\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.4034\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.4008\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.3931\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.3840\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.3759\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.3545\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.3483\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.3333\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.3212\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.2913\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.2797\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.2468\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.2421\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.2062\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.2109\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.1787\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.1659\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.1571\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.1471\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.1137\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.1137\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.1060\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.1102\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0933\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0893\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0794\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0710\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0530\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0560\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0617\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0528\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0536\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0398\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0464\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0450\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0410\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0272\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0358\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0318\n",
      "Epoch [10/10], Step [1/119], Loss: 10.4774\n",
      "Epoch [10/10], Step [101/119], Loss: 9.4958\n",
      "Epoch [10/10], Step [201/119], Loss: 7.6569\n",
      "Epoch [10/10], Step [301/119], Loss: 6.2440\n",
      "Epoch [10/10], Step [401/119], Loss: 4.5691\n",
      "Epoch [10/10], Step [501/119], Loss: 3.6227\n",
      "Epoch [10/10], Step [601/119], Loss: 2.2261\n",
      "Epoch [10/10], Step [701/119], Loss: 1.1251\n",
      "Epoch [10/10], Step [801/119], Loss: 0.7110\n",
      "Epoch [10/10], Step [901/119], Loss: 0.3920\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.3166\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.2397\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.2254\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.1479\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.1582\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.1659\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.1309\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0981\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0960\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0835\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.1048\n",
      "Epoch [10/10], Step [2101/119], Loss: 2.3535\n",
      "Epoch [10/10], Step [2201/119], Loss: 4.1491\n",
      "Epoch [10/10], Step [2301/119], Loss: 4.3023\n",
      "Epoch [10/10], Step [2401/119], Loss: 4.3312\n",
      "Epoch [10/10], Step [2501/119], Loss: 4.2232\n",
      "Epoch [10/10], Step [2601/119], Loss: 3.9328\n",
      "Epoch [10/10], Step [2701/119], Loss: 3.6261\n",
      "Epoch [10/10], Step [2801/119], Loss: 3.3940\n",
      "Epoch [10/10], Step [2901/119], Loss: 2.8472\n",
      "Epoch [10/10], Step [3001/119], Loss: 2.4307\n",
      "Epoch [10/10], Step [3101/119], Loss: 1.9330\n",
      "Epoch [10/10], Step [3201/119], Loss: 1.8025\n",
      "Epoch [10/10], Step [3301/119], Loss: 1.5768\n",
      "Epoch [10/10], Step [3401/119], Loss: 1.3590\n",
      "Epoch [10/10], Step [3501/119], Loss: 1.0392\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.9253\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.8983\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.6957\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.6305\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.5615\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.5399\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.4996\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.4694\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.4501\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.4354\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.4233\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.4209\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.4109\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.4066\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.4004\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.3991\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.3984\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.3942\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.3943\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.3952\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.3934\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.3905\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.3879\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.3873\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.3867\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.3862\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.3852\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.3841\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.3817\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.3816\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.3796\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.3795\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.3788\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.3777\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.3760\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.3754\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.3746\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.3748\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.3733\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.3762\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.3716\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.3703\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.3704\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.3729\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.3685\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.3666\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.3659\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.3650\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.3655\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.3643\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.3630\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.3614\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.3620\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.3601\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.3594\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.3587\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.3580\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.3574\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.3573\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.3573\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.3546\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.3547\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.3533\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.3532\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.3517\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.3502\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.3488\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.3502\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.3483\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.3472\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.3486\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.3453\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.3451\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.3454\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.3439\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.3419\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.3419\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.3410\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.3410\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.3403\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.3392\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.3375\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.3372\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.3367\n",
      "Epoch [1/10], Step [1/119], Loss: 0.6213\n",
      "Epoch [1/10], Step [101/119], Loss: 0.4362\n",
      "Epoch [1/10], Step [201/119], Loss: 0.3226\n",
      "Epoch [1/10], Step [301/119], Loss: 0.2626\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2118\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1247\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1324\n",
      "Epoch [1/10], Step [701/119], Loss: 0.0839\n",
      "Epoch [1/10], Step [801/119], Loss: 0.0966\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0477\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0493\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0290\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0242\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0123\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0130\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0101\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0082\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0049\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0032\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0020\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0024\n",
      "Epoch [1/10], Step [2101/119], Loss: 8.1397\n",
      "Epoch [1/10], Step [2201/119], Loss: 14.0989\n",
      "Epoch [1/10], Step [2301/119], Loss: 13.4423\n",
      "Epoch [1/10], Step [2401/119], Loss: 12.2513\n",
      "Epoch [1/10], Step [2501/119], Loss: 10.5375\n",
      "Epoch [1/10], Step [2601/119], Loss: 8.9831\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.8832\n",
      "Epoch [1/10], Step [2801/119], Loss: 6.3227\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.3711\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.2302\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.6293\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.8470\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.1720\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9511\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.8619\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.8169\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.8022\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.7880\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.7694\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.7632\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.7564\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.7583\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.7448\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.7466\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.7402\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.7398\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.7332\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.7265\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.7293\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.7241\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.7186\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.7160\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.7093\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.7085\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.7079\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.7027\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.6965\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.6950\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.6921\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.6869\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.6817\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.6801\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.6807\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.6738\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.6703\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.6678\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.6598\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.6572\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.6579\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.6564\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.6493\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.6471\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.6392\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.6403\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.6344\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.6307\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.6238\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.6220\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.6208\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.6137\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.6164\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.6066\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.6023\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.6023\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.6027\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.6003\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.5923\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.5942\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.5874\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.5843\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.5793\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.5790\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.5718\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.5723\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.5630\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.5542\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.5363\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.5136\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.4975\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.4526\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.4254\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.4101\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.3905\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.3380\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.2983\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.2899\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.2453\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.1933\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.1979\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.1841\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.1658\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.1509\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.1245\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.1305\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.1173\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.1060\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0760\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0914\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0791\n",
      "Epoch [2/10], Step [1/119], Loss: 7.8038\n",
      "Epoch [2/10], Step [101/119], Loss: 7.0268\n",
      "Epoch [2/10], Step [201/119], Loss: 6.6984\n",
      "Epoch [2/10], Step [301/119], Loss: 5.6080\n",
      "Epoch [2/10], Step [401/119], Loss: 4.8557\n",
      "Epoch [2/10], Step [501/119], Loss: 4.7907\n",
      "Epoch [2/10], Step [601/119], Loss: 3.7971\n",
      "Epoch [2/10], Step [701/119], Loss: 3.8362\n",
      "Epoch [2/10], Step [801/119], Loss: 2.2431\n",
      "Epoch [2/10], Step [901/119], Loss: 2.5792\n",
      "Epoch [2/10], Step [1001/119], Loss: 2.1768\n",
      "Epoch [2/10], Step [1101/119], Loss: 1.9888\n",
      "Epoch [2/10], Step [1201/119], Loss: 1.5327\n",
      "Epoch [2/10], Step [1301/119], Loss: 1.4172\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.1788\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.0709\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.9809\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.8918\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.8237\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.7768\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.7348\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.6848\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.6778\n",
      "Epoch [2/10], Step [2301/119], Loss: 0.6811\n",
      "Epoch [2/10], Step [2401/119], Loss: 0.6948\n",
      "Epoch [2/10], Step [2501/119], Loss: 0.7005\n",
      "Epoch [2/10], Step [2601/119], Loss: 0.7010\n",
      "Epoch [2/10], Step [2701/119], Loss: 0.7046\n",
      "Epoch [2/10], Step [2801/119], Loss: 0.7019\n",
      "Epoch [2/10], Step [2901/119], Loss: 0.7037\n",
      "Epoch [2/10], Step [3001/119], Loss: 0.6946\n",
      "Epoch [2/10], Step [3101/119], Loss: 0.6950\n",
      "Epoch [2/10], Step [3201/119], Loss: 0.6925\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.6818\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.6768\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.6740\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.6668\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.6631\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.6584\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.6528\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.6492\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.6398\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.6189\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.5904\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.5521\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.5190\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.5006\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.4598\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.4019\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.3759\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.3487\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.3087\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.2878\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.2516\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.1805\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.2016\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.1643\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.1094\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.1252\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.0978\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.0858\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.0849\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.0592\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.0625\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.0626\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.0469\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.0407\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.0344\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.0413\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.0269\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.0341\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.0277\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.0229\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.0257\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.0232\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0138\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.0207\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0134\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0100\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0104\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0096\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0119\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0087\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0080\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0060\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0059\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0053\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0052\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0045\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0038\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0043\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0040\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0044\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0042\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0033\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0040\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0042\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0060\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0043\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0045\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0042\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0049\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0024\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0031\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0027\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0051\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0042\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0063\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0023\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0018\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0038\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0028\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0031\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0027\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0025\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0021\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0032\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0023\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0021\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0021\n",
      "Epoch [3/10], Step [1/119], Loss: 25.4105\n",
      "Epoch [3/10], Step [101/119], Loss: 22.5005\n",
      "Epoch [3/10], Step [201/119], Loss: 19.7291\n",
      "Epoch [3/10], Step [301/119], Loss: 16.2315\n",
      "Epoch [3/10], Step [401/119], Loss: 12.3040\n",
      "Epoch [3/10], Step [501/119], Loss: 12.1648\n",
      "Epoch [3/10], Step [601/119], Loss: 8.3382\n",
      "Epoch [3/10], Step [701/119], Loss: 7.5366\n",
      "Epoch [3/10], Step [801/119], Loss: 3.8511\n",
      "Epoch [3/10], Step [901/119], Loss: 3.4868\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.3065\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.5765\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.7045\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.4437\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.3162\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.2583\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.1889\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.1469\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.1316\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1092\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1306\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.5626\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.7990\n",
      "Epoch [3/10], Step [2301/119], Loss: 3.0309\n",
      "Epoch [3/10], Step [2401/119], Loss: 3.0288\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.8286\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.6872\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.5933\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.4544\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.1796\n",
      "Epoch [3/10], Step [3001/119], Loss: 1.8800\n",
      "Epoch [3/10], Step [3101/119], Loss: 1.7797\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.5367\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.2003\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.1001\n",
      "Epoch [3/10], Step [3501/119], Loss: 0.9824\n",
      "Epoch [3/10], Step [3601/119], Loss: 0.8327\n",
      "Epoch [3/10], Step [3701/119], Loss: 0.7213\n",
      "Epoch [3/10], Step [3801/119], Loss: 0.6566\n",
      "Epoch [3/10], Step [3901/119], Loss: 0.5504\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.4902\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.4429\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.3936\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.3406\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.3175\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.2827\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.2642\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.2463\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.1926\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.1800\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.1681\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.1524\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.1438\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.1294\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.0765\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.1032\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.0779\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.0517\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.0646\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.0483\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.0438\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.0461\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.0332\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.0355\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.0399\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.0284\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.0292\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.0251\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.0278\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.0197\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.0224\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.0219\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.0178\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.0190\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.0195\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.0132\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.0193\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.0125\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.0099\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.0101\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.0096\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.0116\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0097\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0063\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0080\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0070\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0064\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0062\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0053\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0058\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0071\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0042\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0060\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0049\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0039\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0054\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0045\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0059\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0059\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0056\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0039\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0059\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0029\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0044\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0045\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0060\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0049\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0064\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0026\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0030\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0044\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0043\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0047\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0043\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0035\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0041\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0038\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0029\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0028\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0041\n",
      "Epoch [4/10], Step [1/119], Loss: 24.0912\n",
      "Epoch [4/10], Step [101/119], Loss: 21.0162\n",
      "Epoch [4/10], Step [201/119], Loss: 18.2772\n",
      "Epoch [4/10], Step [301/119], Loss: 15.7787\n",
      "Epoch [4/10], Step [401/119], Loss: 12.7157\n",
      "Epoch [4/10], Step [501/119], Loss: 11.6789\n",
      "Epoch [4/10], Step [601/119], Loss: 8.4850\n",
      "Epoch [4/10], Step [701/119], Loss: 7.7604\n",
      "Epoch [4/10], Step [801/119], Loss: 3.8292\n",
      "Epoch [4/10], Step [901/119], Loss: 3.6666\n",
      "Epoch [4/10], Step [1001/119], Loss: 2.3019\n",
      "Epoch [4/10], Step [1101/119], Loss: 1.3602\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.6557\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.3333\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.2686\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.2134\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.1682\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.1232\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.1135\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0977\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.1085\n",
      "Epoch [4/10], Step [2101/119], Loss: 1.8283\n",
      "Epoch [4/10], Step [2201/119], Loss: 3.2341\n",
      "Epoch [4/10], Step [2301/119], Loss: 3.3790\n",
      "Epoch [4/10], Step [2401/119], Loss: 3.5556\n",
      "Epoch [4/10], Step [2501/119], Loss: 3.3462\n",
      "Epoch [4/10], Step [2601/119], Loss: 3.2553\n",
      "Epoch [4/10], Step [2701/119], Loss: 3.1529\n",
      "Epoch [4/10], Step [2801/119], Loss: 3.1980\n",
      "Epoch [4/10], Step [2901/119], Loss: 2.6817\n",
      "Epoch [4/10], Step [3001/119], Loss: 2.4330\n",
      "Epoch [4/10], Step [3101/119], Loss: 2.5565\n",
      "Epoch [4/10], Step [3201/119], Loss: 2.2307\n",
      "Epoch [4/10], Step [3301/119], Loss: 1.6741\n",
      "Epoch [4/10], Step [3401/119], Loss: 1.6862\n",
      "Epoch [4/10], Step [3501/119], Loss: 1.6082\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.3940\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.2820\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.1797\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.0438\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.0441\n",
      "Epoch [4/10], Step [4101/119], Loss: 0.9390\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.8825\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.8337\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.8550\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.7531\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.7081\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.6927\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.6754\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.6651\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.6543\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.6490\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.6463\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.6376\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.6305\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.6272\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.6198\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.6168\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.6180\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.6134\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.6102\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.6074\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.6054\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.6028\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.6036\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.5984\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.5962\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.5941\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.5894\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.5888\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.5877\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.5840\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.5836\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.5824\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.5801\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.5749\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.5698\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.5647\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.5614\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.5517\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.5338\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.5106\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.4889\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.4641\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.4339\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.4121\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.3707\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.3543\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.3323\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.3113\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.2736\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.2617\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.2210\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.2084\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.1762\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.1946\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.1599\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.1427\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.1364\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.1377\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.0951\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.1051\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.0997\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.1072\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.0891\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.0859\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.0804\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.0729\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.0521\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.0552\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.0608\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.0568\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.0652\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.0408\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.0495\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.0444\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.0423\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.0313\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.0335\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.0358\n",
      "Epoch [5/10], Step [1/119], Loss: 11.0653\n",
      "Epoch [5/10], Step [101/119], Loss: 10.3206\n",
      "Epoch [5/10], Step [201/119], Loss: 8.9305\n",
      "Epoch [5/10], Step [301/119], Loss: 7.7670\n",
      "Epoch [5/10], Step [401/119], Loss: 6.1544\n",
      "Epoch [5/10], Step [501/119], Loss: 6.0332\n",
      "Epoch [5/10], Step [601/119], Loss: 4.3481\n",
      "Epoch [5/10], Step [701/119], Loss: 3.7350\n",
      "Epoch [5/10], Step [801/119], Loss: 2.0583\n",
      "Epoch [5/10], Step [901/119], Loss: 1.9468\n",
      "Epoch [5/10], Step [1001/119], Loss: 1.2391\n",
      "Epoch [5/10], Step [1101/119], Loss: 0.8776\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.6007\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.4102\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.3583\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.3060\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.2645\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.2021\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.1918\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.1712\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.1822\n",
      "Epoch [5/10], Step [2101/119], Loss: 1.2964\n",
      "Epoch [5/10], Step [2201/119], Loss: 2.2150\n",
      "Epoch [5/10], Step [2301/119], Loss: 2.3033\n",
      "Epoch [5/10], Step [2401/119], Loss: 2.4975\n",
      "Epoch [5/10], Step [2501/119], Loss: 2.3618\n",
      "Epoch [5/10], Step [2601/119], Loss: 2.3125\n",
      "Epoch [5/10], Step [2701/119], Loss: 2.1839\n",
      "Epoch [5/10], Step [2801/119], Loss: 2.2081\n",
      "Epoch [5/10], Step [2901/119], Loss: 1.9470\n",
      "Epoch [5/10], Step [3001/119], Loss: 1.7611\n",
      "Epoch [5/10], Step [3101/119], Loss: 1.9145\n",
      "Epoch [5/10], Step [3201/119], Loss: 1.5337\n",
      "Epoch [5/10], Step [3301/119], Loss: 1.2864\n",
      "Epoch [5/10], Step [3401/119], Loss: 1.3094\n",
      "Epoch [5/10], Step [3501/119], Loss: 1.2110\n",
      "Epoch [5/10], Step [3601/119], Loss: 1.0985\n",
      "Epoch [5/10], Step [3701/119], Loss: 1.0584\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.9657\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.9280\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.8884\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.8210\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.7883\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.7541\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.7668\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.7197\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.6814\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.6665\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.6596\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.6357\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.6369\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.6282\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.6176\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.6112\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.6094\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.6062\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.6003\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.5964\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.5943\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.5922\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.5921\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.5883\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.5853\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.5835\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.5808\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.5801\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.5801\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.5769\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.5746\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.5745\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.5715\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.5717\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.5691\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.5672\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.5651\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.5649\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.5640\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.5612\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.5612\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.5619\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.5571\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.5569\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.5527\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.5538\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.5526\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.5490\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.5485\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.5482\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.5448\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.5442\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.5425\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.5420\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.5399\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.5393\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.5374\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.5374\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.5345\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.5337\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.5322\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.5315\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.5294\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.5288\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.5291\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.5265\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.5251\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.5249\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.5214\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.5207\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.5183\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.5189\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.5151\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.5127\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.5103\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.5043\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.4968\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.4904\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.4788\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.4611\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.4463\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.4305\n",
      "Epoch [6/10], Step [1/119], Loss: 1.2879\n",
      "Epoch [6/10], Step [101/119], Loss: 1.2342\n",
      "Epoch [6/10], Step [201/119], Loss: 1.2000\n",
      "Epoch [6/10], Step [301/119], Loss: 1.1324\n",
      "Epoch [6/10], Step [401/119], Loss: 1.0833\n",
      "Epoch [6/10], Step [501/119], Loss: 1.0488\n",
      "Epoch [6/10], Step [601/119], Loss: 1.0051\n",
      "Epoch [6/10], Step [701/119], Loss: 0.9954\n",
      "Epoch [6/10], Step [801/119], Loss: 0.9481\n",
      "Epoch [6/10], Step [901/119], Loss: 0.9444\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.9282\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.9182\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.9168\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.9134\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.9147\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.9126\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.9092\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.9066\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.9022\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.9014\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.8974\n",
      "Epoch [6/10], Step [2101/119], Loss: 0.7091\n",
      "Epoch [6/10], Step [2201/119], Loss: 0.5249\n",
      "Epoch [6/10], Step [2301/119], Loss: 0.5268\n",
      "Epoch [6/10], Step [2401/119], Loss: 0.5275\n",
      "Epoch [6/10], Step [2501/119], Loss: 0.5274\n",
      "Epoch [6/10], Step [2601/119], Loss: 0.5291\n",
      "Epoch [6/10], Step [2701/119], Loss: 0.5293\n",
      "Epoch [6/10], Step [2801/119], Loss: 0.5312\n",
      "Epoch [6/10], Step [2901/119], Loss: 0.5303\n",
      "Epoch [6/10], Step [3001/119], Loss: 0.5280\n",
      "Epoch [6/10], Step [3101/119], Loss: 0.5276\n",
      "Epoch [6/10], Step [3201/119], Loss: 0.5282\n",
      "Epoch [6/10], Step [3301/119], Loss: 0.5289\n",
      "Epoch [6/10], Step [3401/119], Loss: 0.5284\n",
      "Epoch [6/10], Step [3501/119], Loss: 0.5272\n",
      "Epoch [6/10], Step [3601/119], Loss: 0.5238\n",
      "Epoch [6/10], Step [3701/119], Loss: 0.5230\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.5230\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.5233\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.5222\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.5240\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.5208\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.5193\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.5201\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.5173\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.5175\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.5152\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.5163\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.5127\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.5124\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.5116\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.5097\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.5070\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.5051\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.5025\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.5027\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.4982\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.4874\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.4787\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.4595\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.4483\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.4204\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.3803\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.3638\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.3250\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.3000\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.2791\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.2386\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.2041\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.1896\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.1638\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.1481\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.1331\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.1293\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.0937\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.0975\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.0776\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.0704\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.0629\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.0586\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.0464\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.0454\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.0399\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.0335\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.0317\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.0233\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.0270\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.0262\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.0222\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.0208\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.0187\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.0174\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.0149\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.0128\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.0144\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.0134\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.0131\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.0119\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.0121\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.0090\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.0117\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.0073\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.0091\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.0088\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.0089\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.0082\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.0085\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.0055\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.0059\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.0075\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.0066\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.0088\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.0059\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.0048\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.0060\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.0068\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.0043\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.0046\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.0068\n",
      "Epoch [7/10], Step [1/119], Loss: 19.9683\n",
      "Epoch [7/10], Step [101/119], Loss: 16.6902\n",
      "Epoch [7/10], Step [201/119], Loss: 13.0271\n",
      "Epoch [7/10], Step [301/119], Loss: 9.4754\n",
      "Epoch [7/10], Step [401/119], Loss: 5.6893\n",
      "Epoch [7/10], Step [501/119], Loss: 3.0544\n",
      "Epoch [7/10], Step [601/119], Loss: 0.5821\n",
      "Epoch [7/10], Step [701/119], Loss: 0.1677\n",
      "Epoch [7/10], Step [801/119], Loss: 0.1519\n",
      "Epoch [7/10], Step [901/119], Loss: 0.0538\n",
      "Epoch [7/10], Step [1001/119], Loss: 0.0483\n",
      "Epoch [7/10], Step [1101/119], Loss: 0.0288\n",
      "Epoch [7/10], Step [1201/119], Loss: 0.0256\n",
      "Epoch [7/10], Step [1301/119], Loss: 0.0132\n",
      "Epoch [7/10], Step [1401/119], Loss: 0.0149\n",
      "Epoch [7/10], Step [1501/119], Loss: 0.0163\n",
      "Epoch [7/10], Step [1601/119], Loss: 0.0102\n",
      "Epoch [7/10], Step [1701/119], Loss: 0.0079\n",
      "Epoch [7/10], Step [1801/119], Loss: 0.0077\n",
      "Epoch [7/10], Step [1901/119], Loss: 0.0045\n",
      "Epoch [7/10], Step [2001/119], Loss: 0.0066\n",
      "Epoch [7/10], Step [2101/119], Loss: 6.0920\n",
      "Epoch [7/10], Step [2201/119], Loss: 10.6658\n",
      "Epoch [7/10], Step [2301/119], Loss: 11.0792\n",
      "Epoch [7/10], Step [2401/119], Loss: 10.7286\n",
      "Epoch [7/10], Step [2501/119], Loss: 9.6068\n",
      "Epoch [7/10], Step [2601/119], Loss: 8.7491\n",
      "Epoch [7/10], Step [2701/119], Loss: 7.9491\n",
      "Epoch [7/10], Step [2801/119], Loss: 7.4339\n",
      "Epoch [7/10], Step [2901/119], Loss: 5.9234\n",
      "Epoch [7/10], Step [3001/119], Loss: 4.6829\n",
      "Epoch [7/10], Step [3101/119], Loss: 4.3765\n",
      "Epoch [7/10], Step [3201/119], Loss: 3.4552\n",
      "Epoch [7/10], Step [3301/119], Loss: 2.3990\n",
      "Epoch [7/10], Step [3401/119], Loss: 2.1096\n",
      "Epoch [7/10], Step [3501/119], Loss: 1.7462\n",
      "Epoch [7/10], Step [3601/119], Loss: 1.3903\n",
      "Epoch [7/10], Step [3701/119], Loss: 1.0726\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.9395\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.8313\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.7408\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.6704\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.6316\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.5995\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.6105\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.5636\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.5494\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.5437\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.5381\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.5306\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.5295\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.5237\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.5222\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.5205\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.5159\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.5149\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.5125\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.5125\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.5098\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.5074\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.5062\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.5035\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.5028\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.5012\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.4994\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.4986\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.4974\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.4956\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.4942\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.4942\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.4931\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.4910\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.4900\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.4876\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.4867\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.4872\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.4836\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.4836\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.4832\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.4791\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.4805\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.4791\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.4804\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.4746\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.4767\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.4755\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.4741\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.4733\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.4714\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.4711\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.4700\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.4674\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.4677\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.4667\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.4652\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.4639\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.4620\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.4612\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.4607\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.4588\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.4589\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.4585\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.4564\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.4560\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.4543\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.4507\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.4529\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.4504\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.4515\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.4485\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.4483\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.4460\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.4470\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.4463\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.4433\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.4428\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.4428\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.4408\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.4404\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.4388\n",
      "Epoch [8/10], Step [1/119], Loss: 1.0366\n",
      "Epoch [8/10], Step [101/119], Loss: 1.0365\n",
      "Epoch [8/10], Step [201/119], Loss: 1.0384\n",
      "Epoch [8/10], Step [301/119], Loss: 1.0385\n",
      "Epoch [8/10], Step [401/119], Loss: 1.0403\n",
      "Epoch [8/10], Step [501/119], Loss: 1.0404\n",
      "Epoch [8/10], Step [601/119], Loss: 1.0414\n",
      "Epoch [8/10], Step [701/119], Loss: 1.0378\n",
      "Epoch [8/10], Step [801/119], Loss: 1.0351\n",
      "Epoch [8/10], Step [901/119], Loss: 1.0353\n",
      "Epoch [8/10], Step [1001/119], Loss: 1.0318\n",
      "Epoch [8/10], Step [1101/119], Loss: 1.0326\n",
      "Epoch [8/10], Step [1201/119], Loss: 1.0307\n",
      "Epoch [8/10], Step [1301/119], Loss: 1.0255\n",
      "Epoch [8/10], Step [1401/119], Loss: 1.0241\n",
      "Epoch [8/10], Step [1501/119], Loss: 1.0230\n",
      "Epoch [8/10], Step [1601/119], Loss: 1.0207\n",
      "Epoch [8/10], Step [1701/119], Loss: 1.0185\n",
      "Epoch [8/10], Step [1801/119], Loss: 1.0154\n",
      "Epoch [8/10], Step [1901/119], Loss: 1.0148\n",
      "Epoch [8/10], Step [2001/119], Loss: 1.0126\n",
      "Epoch [8/10], Step [2101/119], Loss: 0.7313\n",
      "Epoch [8/10], Step [2201/119], Loss: 0.4550\n",
      "Epoch [8/10], Step [2301/119], Loss: 0.4564\n",
      "Epoch [8/10], Step [2401/119], Loss: 0.4575\n",
      "Epoch [8/10], Step [2501/119], Loss: 0.4570\n",
      "Epoch [8/10], Step [2601/119], Loss: 0.4582\n",
      "Epoch [8/10], Step [2701/119], Loss: 0.4578\n",
      "Epoch [8/10], Step [2801/119], Loss: 0.4582\n",
      "Epoch [8/10], Step [2901/119], Loss: 0.4594\n",
      "Epoch [8/10], Step [3001/119], Loss: 0.4597\n",
      "Epoch [8/10], Step [3101/119], Loss: 0.4575\n",
      "Epoch [8/10], Step [3201/119], Loss: 0.4583\n",
      "Epoch [8/10], Step [3301/119], Loss: 0.4584\n",
      "Epoch [8/10], Step [3401/119], Loss: 0.4581\n",
      "Epoch [8/10], Step [3501/119], Loss: 0.4578\n",
      "Epoch [8/10], Step [3601/119], Loss: 0.4554\n",
      "Epoch [8/10], Step [3701/119], Loss: 0.4557\n",
      "Epoch [8/10], Step [3801/119], Loss: 0.4561\n",
      "Epoch [8/10], Step [3901/119], Loss: 0.4551\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.4543\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.4551\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.4533\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.4528\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.4477\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.4482\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.4452\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.4372\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.4268\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.4153\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.4063\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.3914\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.3808\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.3547\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.3129\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.3163\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.2876\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.2367\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.2329\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.2010\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.1863\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.1924\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.1567\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.1413\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.1516\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.1222\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.1147\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.1120\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.1031\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.0867\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.0854\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.0756\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.0755\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.0672\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.0716\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.0499\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.0550\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.0491\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.0402\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.0387\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.0385\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.0349\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.0347\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.0326\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.0276\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.0248\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.0236\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.0234\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.0222\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.0209\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.0207\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.0190\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.0192\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.0177\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.0140\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.0171\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.0154\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.0174\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.0147\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.0165\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.0101\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.0165\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.0110\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.0152\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.0122\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.0144\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.0120\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.0130\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.0093\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.0097\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.0119\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.0105\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.0112\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.0091\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.0096\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.0100\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.0116\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.0073\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.0082\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.0111\n",
      "Epoch [9/10], Step [1/119], Loss: 17.3248\n",
      "Epoch [9/10], Step [101/119], Loss: 15.0727\n",
      "Epoch [9/10], Step [201/119], Loss: 12.0614\n",
      "Epoch [9/10], Step [301/119], Loss: 9.4406\n",
      "Epoch [9/10], Step [401/119], Loss: 6.1901\n",
      "Epoch [9/10], Step [501/119], Loss: 4.1957\n",
      "Epoch [9/10], Step [601/119], Loss: 1.6328\n",
      "Epoch [9/10], Step [701/119], Loss: 0.4059\n",
      "Epoch [9/10], Step [801/119], Loss: 0.2826\n",
      "Epoch [9/10], Step [901/119], Loss: 0.1261\n",
      "Epoch [9/10], Step [1001/119], Loss: 0.1005\n",
      "Epoch [9/10], Step [1101/119], Loss: 0.0666\n",
      "Epoch [9/10], Step [1201/119], Loss: 0.0577\n",
      "Epoch [9/10], Step [1301/119], Loss: 0.0320\n",
      "Epoch [9/10], Step [1401/119], Loss: 0.0343\n",
      "Epoch [9/10], Step [1501/119], Loss: 0.0340\n",
      "Epoch [9/10], Step [1601/119], Loss: 0.0240\n",
      "Epoch [9/10], Step [1701/119], Loss: 0.0179\n",
      "Epoch [9/10], Step [1801/119], Loss: 0.0199\n",
      "Epoch [9/10], Step [1901/119], Loss: 0.0101\n",
      "Epoch [9/10], Step [2001/119], Loss: 0.0175\n",
      "Epoch [9/10], Step [2101/119], Loss: 4.8948\n",
      "Epoch [9/10], Step [2201/119], Loss: 8.9033\n",
      "Epoch [9/10], Step [2301/119], Loss: 9.5255\n",
      "Epoch [9/10], Step [2401/119], Loss: 9.3974\n",
      "Epoch [9/10], Step [2501/119], Loss: 8.5957\n",
      "Epoch [9/10], Step [2601/119], Loss: 8.4817\n",
      "Epoch [9/10], Step [2701/119], Loss: 8.0749\n",
      "Epoch [9/10], Step [2801/119], Loss: 7.6183\n",
      "Epoch [9/10], Step [2901/119], Loss: 5.8953\n",
      "Epoch [9/10], Step [3001/119], Loss: 5.1905\n",
      "Epoch [9/10], Step [3101/119], Loss: 5.2337\n",
      "Epoch [9/10], Step [3201/119], Loss: 4.0065\n",
      "Epoch [9/10], Step [3301/119], Loss: 2.8203\n",
      "Epoch [9/10], Step [3401/119], Loss: 2.7316\n",
      "Epoch [9/10], Step [3501/119], Loss: 2.3863\n",
      "Epoch [9/10], Step [3601/119], Loss: 1.9988\n",
      "Epoch [9/10], Step [3701/119], Loss: 1.5920\n",
      "Epoch [9/10], Step [3801/119], Loss: 1.3658\n",
      "Epoch [9/10], Step [3901/119], Loss: 1.1799\n",
      "Epoch [9/10], Step [4001/119], Loss: 1.1042\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.8929\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.7683\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.7319\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.6852\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.5787\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.5196\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.4970\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4726\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4508\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4346\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.4220\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.4114\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.4007\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.3853\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.3916\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.3821\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.3639\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.3636\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.3560\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.3611\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.3572\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.3527\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.3471\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.3453\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.3458\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.3395\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.3458\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.3384\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.3354\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.3343\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.3251\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.3283\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.3263\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.3277\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.3133\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.3233\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.3152\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.3114\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.3072\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.3083\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.2956\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.3041\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.2958\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.2925\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.2863\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.2804\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.2803\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.2891\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.2871\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.2750\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.2777\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.2562\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.2749\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.2465\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.2500\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.2362\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.2239\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.2171\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.2088\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.1826\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.1750\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.1672\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.1715\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.1443\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.1326\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.1250\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.1103\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0839\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0876\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0841\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0755\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0774\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0560\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0630\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0551\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0551\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0397\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0453\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0470\n",
      "Epoch [10/10], Step [1/119], Loss: 8.7641\n",
      "Epoch [10/10], Step [101/119], Loss: 8.0308\n",
      "Epoch [10/10], Step [201/119], Loss: 6.7104\n",
      "Epoch [10/10], Step [301/119], Loss: 5.6249\n",
      "Epoch [10/10], Step [401/119], Loss: 4.5390\n",
      "Epoch [10/10], Step [501/119], Loss: 3.9677\n",
      "Epoch [10/10], Step [601/119], Loss: 2.7738\n",
      "Epoch [10/10], Step [701/119], Loss: 2.0999\n",
      "Epoch [10/10], Step [801/119], Loss: 1.2623\n",
      "Epoch [10/10], Step [901/119], Loss: 0.8881\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.6110\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.4603\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.4350\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.3006\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.3003\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.2884\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.2427\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.1935\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.1789\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.1563\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.1806\n",
      "Epoch [10/10], Step [2101/119], Loss: 1.4732\n",
      "Epoch [10/10], Step [2201/119], Loss: 2.4614\n",
      "Epoch [10/10], Step [2301/119], Loss: 2.5775\n",
      "Epoch [10/10], Step [2401/119], Loss: 2.5780\n",
      "Epoch [10/10], Step [2501/119], Loss: 2.5548\n",
      "Epoch [10/10], Step [2601/119], Loss: 2.2902\n",
      "Epoch [10/10], Step [2701/119], Loss: 2.0965\n",
      "Epoch [10/10], Step [2801/119], Loss: 2.0866\n",
      "Epoch [10/10], Step [2901/119], Loss: 1.7433\n",
      "Epoch [10/10], Step [3001/119], Loss: 1.3578\n",
      "Epoch [10/10], Step [3101/119], Loss: 1.4820\n",
      "Epoch [10/10], Step [3201/119], Loss: 1.1800\n",
      "Epoch [10/10], Step [3301/119], Loss: 0.9216\n",
      "Epoch [10/10], Step [3401/119], Loss: 0.8440\n",
      "Epoch [10/10], Step [3501/119], Loss: 0.7703\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.7115\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.6222\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.5941\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.5556\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.5211\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.5011\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.4921\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.4719\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.4906\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.4655\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.4572\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.4525\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.4491\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.4434\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.4429\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.4408\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.4382\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.4360\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.4341\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.4370\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.4302\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.4284\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.4296\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.4262\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.4264\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.4264\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.4222\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.4216\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.4209\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.4179\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.4208\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.4177\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.4155\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.4145\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.4140\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.4124\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.4114\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.4090\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.4096\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.4097\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.4054\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.4044\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.4055\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.4070\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.4030\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.4017\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.4004\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.3991\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.3983\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.3974\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.3966\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.3970\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.3948\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.3946\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.3926\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.3929\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.3917\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.3895\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.3893\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.3900\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.3871\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.3875\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.3849\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.3852\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.3846\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.3836\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.3825\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.3832\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.3810\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.3827\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.3788\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.3786\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.3765\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.3766\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.3745\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.3741\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.3722\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.3738\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.3721\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.3732\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.3712\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.3675\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.3694\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.3661\n",
      "Epoch [1/10], Step [1/119], Loss: 0.6844\n",
      "Epoch [1/10], Step [101/119], Loss: 0.5052\n",
      "Epoch [1/10], Step [201/119], Loss: 0.3944\n",
      "Epoch [1/10], Step [301/119], Loss: 0.3099\n",
      "Epoch [1/10], Step [401/119], Loss: 0.2565\n",
      "Epoch [1/10], Step [501/119], Loss: 0.1626\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1577\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1029\n",
      "Epoch [1/10], Step [801/119], Loss: 0.1146\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0616\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0542\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0321\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0320\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0167\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0168\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0159\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0095\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0063\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0053\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0033\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0035\n",
      "Epoch [1/10], Step [2101/119], Loss: 8.2199\n",
      "Epoch [1/10], Step [2201/119], Loss: 14.1083\n",
      "Epoch [1/10], Step [2301/119], Loss: 13.1348\n",
      "Epoch [1/10], Step [2401/119], Loss: 12.2706\n",
      "Epoch [1/10], Step [2501/119], Loss: 10.2865\n",
      "Epoch [1/10], Step [2601/119], Loss: 8.9715\n",
      "Epoch [1/10], Step [2701/119], Loss: 7.5464\n",
      "Epoch [1/10], Step [2801/119], Loss: 6.2435\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.7322\n",
      "Epoch [1/10], Step [3001/119], Loss: 3.3192\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.6826\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.8300\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.1625\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9575\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.8246\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.7710\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.7446\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.7212\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.7166\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.7127\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.7089\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.7029\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.7013\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.6963\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.6959\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.6845\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.6818\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.6803\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.6753\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.6748\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.6695\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.6644\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.6624\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.6553\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.6596\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.6532\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.6476\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.6485\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.6427\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.6407\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.6387\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.6313\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.6243\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.6262\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.6251\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.6214\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.6180\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.6103\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.6099\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.6072\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.6002\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.5989\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.5950\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.5860\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.5749\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.5685\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.5494\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.5249\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.4939\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.4730\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.4514\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.4093\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.3899\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.3584\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.3074\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.2984\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.2545\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.2501\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.1975\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.1740\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.1578\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.1321\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.1083\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0779\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.1034\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0707\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0670\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0552\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0515\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0334\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0388\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0288\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0317\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0251\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0255\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0199\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0183\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0093\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0113\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0127\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0087\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0117\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0098\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0060\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0077\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0068\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0049\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0044\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0057\n",
      "Epoch [2/10], Step [1/119], Loss: 23.2544\n",
      "Epoch [2/10], Step [101/119], Loss: 20.3762\n",
      "Epoch [2/10], Step [201/119], Loss: 17.5635\n",
      "Epoch [2/10], Step [301/119], Loss: 15.3309\n",
      "Epoch [2/10], Step [401/119], Loss: 12.5792\n",
      "Epoch [2/10], Step [501/119], Loss: 12.4339\n",
      "Epoch [2/10], Step [601/119], Loss: 9.9441\n",
      "Epoch [2/10], Step [701/119], Loss: 8.9274\n",
      "Epoch [2/10], Step [801/119], Loss: 4.9902\n",
      "Epoch [2/10], Step [901/119], Loss: 5.7396\n",
      "Epoch [2/10], Step [1001/119], Loss: 4.3693\n",
      "Epoch [2/10], Step [1101/119], Loss: 4.0276\n",
      "Epoch [2/10], Step [1201/119], Loss: 2.7167\n",
      "Epoch [2/10], Step [1301/119], Loss: 2.2497\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.7422\n",
      "Epoch [2/10], Step [1501/119], Loss: 1.2387\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.9595\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.7752\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.6844\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.5519\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.5035\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.7243\n",
      "Epoch [2/10], Step [2201/119], Loss: 0.9506\n",
      "Epoch [2/10], Step [2301/119], Loss: 0.9782\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.0137\n",
      "Epoch [2/10], Step [2501/119], Loss: 0.9999\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.0161\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.0022\n",
      "Epoch [2/10], Step [2801/119], Loss: 0.9858\n",
      "Epoch [2/10], Step [2901/119], Loss: 0.9742\n",
      "Epoch [2/10], Step [3001/119], Loss: 0.9351\n",
      "Epoch [2/10], Step [3101/119], Loss: 0.9529\n",
      "Epoch [2/10], Step [3201/119], Loss: 0.9040\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.8238\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.8186\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.7861\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.7591\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.7229\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.6908\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.6544\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.6184\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.5938\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.5552\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.5115\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.4899\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.4621\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.4457\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.4086\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.3629\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.3466\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.3353\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.3094\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.3031\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.2769\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.2099\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.2462\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.1957\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.1465\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.1681\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.1277\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.1341\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.1110\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.1253\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.1339\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.1091\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.0949\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.0994\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.0720\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.0754\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.0713\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.0608\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.0552\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.0586\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.0542\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.0505\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.0472\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.0467\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.0346\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.0350\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.0270\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.0282\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.0300\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.0194\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.0265\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.0264\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.0155\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.0187\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.0111\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.0198\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.0115\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0117\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.0097\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0115\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0084\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0080\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0079\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0060\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0090\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0071\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0082\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0048\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0075\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0043\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0056\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0038\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0050\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0045\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0056\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0023\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0025\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0050\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0038\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0050\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0031\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0025\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0025\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0032\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0018\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0018\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0028\n",
      "Epoch [3/10], Step [1/119], Loss: 28.2017\n",
      "Epoch [3/10], Step [101/119], Loss: 24.3560\n",
      "Epoch [3/10], Step [201/119], Loss: 20.4940\n",
      "Epoch [3/10], Step [301/119], Loss: 17.9004\n",
      "Epoch [3/10], Step [401/119], Loss: 13.9678\n",
      "Epoch [3/10], Step [501/119], Loss: 13.4122\n",
      "Epoch [3/10], Step [601/119], Loss: 9.4243\n",
      "Epoch [3/10], Step [701/119], Loss: 8.4075\n",
      "Epoch [3/10], Step [801/119], Loss: 4.0189\n",
      "Epoch [3/10], Step [901/119], Loss: 4.0927\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.3457\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.1089\n",
      "Epoch [3/10], Step [1201/119], Loss: 0.4702\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.2451\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.1793\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.1511\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.1164\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.0828\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.0766\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.0561\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.0709\n",
      "Epoch [3/10], Step [2101/119], Loss: 2.3358\n",
      "Epoch [3/10], Step [2201/119], Loss: 4.3606\n",
      "Epoch [3/10], Step [2301/119], Loss: 4.6394\n",
      "Epoch [3/10], Step [2401/119], Loss: 4.5917\n",
      "Epoch [3/10], Step [2501/119], Loss: 4.5464\n",
      "Epoch [3/10], Step [2601/119], Loss: 4.2593\n",
      "Epoch [3/10], Step [2701/119], Loss: 4.2876\n",
      "Epoch [3/10], Step [2801/119], Loss: 4.1494\n",
      "Epoch [3/10], Step [2901/119], Loss: 3.4484\n",
      "Epoch [3/10], Step [3001/119], Loss: 3.1597\n",
      "Epoch [3/10], Step [3101/119], Loss: 3.3624\n",
      "Epoch [3/10], Step [3201/119], Loss: 2.7225\n",
      "Epoch [3/10], Step [3301/119], Loss: 2.1506\n",
      "Epoch [3/10], Step [3401/119], Loss: 2.1907\n",
      "Epoch [3/10], Step [3501/119], Loss: 2.1099\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.7752\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.5746\n",
      "Epoch [3/10], Step [3801/119], Loss: 1.4661\n",
      "Epoch [3/10], Step [3901/119], Loss: 1.4405\n",
      "Epoch [3/10], Step [4001/119], Loss: 1.3429\n",
      "Epoch [3/10], Step [4101/119], Loss: 1.1837\n",
      "Epoch [3/10], Step [4201/119], Loss: 1.0667\n",
      "Epoch [3/10], Step [4301/119], Loss: 1.0839\n",
      "Epoch [3/10], Step [4401/119], Loss: 1.0585\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.9312\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.8105\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.7952\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.7653\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.7264\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.6827\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.6475\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.6249\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.5859\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.5409\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.5410\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.5038\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.4327\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.4403\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.3866\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.3896\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.3480\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.3296\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.3380\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.2886\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.2675\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.2631\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.2328\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.2289\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.2139\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.2080\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.1719\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.1687\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.1690\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.1556\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.1482\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.1500\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.1285\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.1114\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.1049\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.1039\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.0907\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0727\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0895\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0867\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0630\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0664\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0540\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0667\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0524\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0463\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0424\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0401\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0314\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0284\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0347\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0292\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0312\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0248\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0299\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0169\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0265\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0185\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0221\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0181\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0223\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0190\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0189\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0124\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0132\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0165\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0136\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0172\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0118\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0111\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0124\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0115\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0081\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0096\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0111\n",
      "Epoch [4/10], Step [1/119], Loss: 17.6281\n",
      "Epoch [4/10], Step [101/119], Loss: 15.6709\n",
      "Epoch [4/10], Step [201/119], Loss: 12.7847\n",
      "Epoch [4/10], Step [301/119], Loss: 10.6288\n",
      "Epoch [4/10], Step [401/119], Loss: 8.2026\n",
      "Epoch [4/10], Step [501/119], Loss: 7.2403\n",
      "Epoch [4/10], Step [601/119], Loss: 4.5572\n",
      "Epoch [4/10], Step [701/119], Loss: 3.3715\n",
      "Epoch [4/10], Step [801/119], Loss: 1.1885\n",
      "Epoch [4/10], Step [901/119], Loss: 0.5454\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.2944\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.1720\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.1449\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.0884\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.0812\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.0850\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.0664\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0515\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0471\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0328\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0470\n",
      "Epoch [4/10], Step [2101/119], Loss: 2.8542\n",
      "Epoch [4/10], Step [2201/119], Loss: 5.2955\n",
      "Epoch [4/10], Step [2301/119], Loss: 5.4181\n",
      "Epoch [4/10], Step [2401/119], Loss: 5.6801\n",
      "Epoch [4/10], Step [2501/119], Loss: 5.2701\n",
      "Epoch [4/10], Step [2601/119], Loss: 4.9245\n",
      "Epoch [4/10], Step [2701/119], Loss: 4.7248\n",
      "Epoch [4/10], Step [2801/119], Loss: 4.5672\n",
      "Epoch [4/10], Step [2901/119], Loss: 3.8746\n",
      "Epoch [4/10], Step [3001/119], Loss: 3.2346\n",
      "Epoch [4/10], Step [3101/119], Loss: 3.3695\n",
      "Epoch [4/10], Step [3201/119], Loss: 2.7530\n",
      "Epoch [4/10], Step [3301/119], Loss: 2.1073\n",
      "Epoch [4/10], Step [3401/119], Loss: 2.0963\n",
      "Epoch [4/10], Step [3501/119], Loss: 1.9341\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.6465\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.4301\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.3144\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.2775\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.2013\n",
      "Epoch [4/10], Step [4101/119], Loss: 1.0679\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.9955\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.9587\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.9057\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.8466\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.7769\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.7485\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.7350\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.7126\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.6808\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.6660\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.6520\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.6437\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.6339\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.6206\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.6110\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.6142\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.6043\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.5955\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.5911\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.5866\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.5807\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.5784\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.5688\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.5729\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.5663\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.5618\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.5598\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.5547\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.5549\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.5491\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.5478\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.5478\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.5429\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.5458\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.5391\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.5391\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.5373\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.5288\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.5318\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.5277\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.5234\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.5223\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.5241\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.5190\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.5167\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.5125\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.5166\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.5095\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.5054\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.5046\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.4967\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.4977\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.4904\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.4967\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.4873\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.4797\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.4694\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.4628\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.4431\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.4356\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.4266\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.4279\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.3987\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.3595\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.3601\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.3318\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.2926\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.3005\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.2767\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.2616\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.2403\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.2168\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.2201\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.2035\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.1924\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.1406\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.1600\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.1553\n",
      "Epoch [5/10], Step [1/119], Loss: 4.7224\n",
      "Epoch [5/10], Step [101/119], Loss: 4.3941\n",
      "Epoch [5/10], Step [201/119], Loss: 3.9391\n",
      "Epoch [5/10], Step [301/119], Loss: 3.3421\n",
      "Epoch [5/10], Step [401/119], Loss: 2.8919\n",
      "Epoch [5/10], Step [501/119], Loss: 2.8454\n",
      "Epoch [5/10], Step [601/119], Loss: 2.1882\n",
      "Epoch [5/10], Step [701/119], Loss: 2.0489\n",
      "Epoch [5/10], Step [801/119], Loss: 1.3564\n",
      "Epoch [5/10], Step [901/119], Loss: 1.4172\n",
      "Epoch [5/10], Step [1001/119], Loss: 1.2159\n",
      "Epoch [5/10], Step [1101/119], Loss: 1.0741\n",
      "Epoch [5/10], Step [1201/119], Loss: 0.9447\n",
      "Epoch [5/10], Step [1301/119], Loss: 0.8405\n",
      "Epoch [5/10], Step [1401/119], Loss: 0.7810\n",
      "Epoch [5/10], Step [1501/119], Loss: 0.7309\n",
      "Epoch [5/10], Step [1601/119], Loss: 0.6748\n",
      "Epoch [5/10], Step [1701/119], Loss: 0.6242\n",
      "Epoch [5/10], Step [1801/119], Loss: 0.5977\n",
      "Epoch [5/10], Step [1901/119], Loss: 0.5774\n",
      "Epoch [5/10], Step [2001/119], Loss: 0.5499\n",
      "Epoch [5/10], Step [2101/119], Loss: 0.6979\n",
      "Epoch [5/10], Step [2201/119], Loss: 0.8374\n",
      "Epoch [5/10], Step [2301/119], Loss: 0.8745\n",
      "Epoch [5/10], Step [2401/119], Loss: 0.8947\n",
      "Epoch [5/10], Step [2501/119], Loss: 0.9115\n",
      "Epoch [5/10], Step [2601/119], Loss: 0.8963\n",
      "Epoch [5/10], Step [2701/119], Loss: 0.8969\n",
      "Epoch [5/10], Step [2801/119], Loss: 0.9610\n",
      "Epoch [5/10], Step [2901/119], Loss: 0.8839\n",
      "Epoch [5/10], Step [3001/119], Loss: 0.8201\n",
      "Epoch [5/10], Step [3101/119], Loss: 0.8667\n",
      "Epoch [5/10], Step [3201/119], Loss: 0.8017\n",
      "Epoch [5/10], Step [3301/119], Loss: 0.7376\n",
      "Epoch [5/10], Step [3401/119], Loss: 0.7473\n",
      "Epoch [5/10], Step [3501/119], Loss: 0.7155\n",
      "Epoch [5/10], Step [3601/119], Loss: 0.7040\n",
      "Epoch [5/10], Step [3701/119], Loss: 0.6826\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.6621\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.6523\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.6308\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.6234\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.6129\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.6054\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.6010\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.5950\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.5819\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.5850\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.5731\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.5685\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.5687\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.5665\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.5611\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.5605\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.5605\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.5592\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.5556\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.5535\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.5501\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.5526\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.5492\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.5485\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.5460\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.5442\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.5452\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.5396\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.5417\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.5384\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.5385\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.5364\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.5352\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.5340\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.5311\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.5308\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.5266\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.5266\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.5244\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.5237\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.5221\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.5206\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.5186\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.5174\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.5149\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.5092\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.5042\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.4947\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.4896\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.4760\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.4733\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.4554\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.4335\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.4239\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.3952\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.3851\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.3509\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.3419\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.3167\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.2852\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.2752\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.2636\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.2171\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.2183\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.2050\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.2083\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.1774\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.1661\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.1634\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.1365\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.1033\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.1135\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.1139\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.1026\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.0958\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.0775\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.0874\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.0824\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.0772\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.0577\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.0697\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0616\n",
      "Epoch [6/10], Step [1/119], Loss: 8.6019\n",
      "Epoch [6/10], Step [101/119], Loss: 8.0634\n",
      "Epoch [6/10], Step [201/119], Loss: 6.7137\n",
      "Epoch [6/10], Step [301/119], Loss: 5.4623\n",
      "Epoch [6/10], Step [401/119], Loss: 4.0839\n",
      "Epoch [6/10], Step [501/119], Loss: 3.3075\n",
      "Epoch [6/10], Step [601/119], Loss: 2.0802\n",
      "Epoch [6/10], Step [701/119], Loss: 1.1300\n",
      "Epoch [6/10], Step [801/119], Loss: 0.6911\n",
      "Epoch [6/10], Step [901/119], Loss: 0.4120\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.3131\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.2418\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.2329\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.1584\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.1503\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.1597\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.1387\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.1017\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.1061\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.0888\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.1061\n",
      "Epoch [6/10], Step [2101/119], Loss: 2.2213\n",
      "Epoch [6/10], Step [2201/119], Loss: 3.7427\n",
      "Epoch [6/10], Step [2301/119], Loss: 4.1967\n",
      "Epoch [6/10], Step [2401/119], Loss: 4.2535\n",
      "Epoch [6/10], Step [2501/119], Loss: 3.8485\n",
      "Epoch [6/10], Step [2601/119], Loss: 3.6090\n",
      "Epoch [6/10], Step [2701/119], Loss: 3.6162\n",
      "Epoch [6/10], Step [2801/119], Loss: 3.3556\n",
      "Epoch [6/10], Step [2901/119], Loss: 2.7425\n",
      "Epoch [6/10], Step [3001/119], Loss: 2.4233\n",
      "Epoch [6/10], Step [3101/119], Loss: 2.6180\n",
      "Epoch [6/10], Step [3201/119], Loss: 1.9958\n",
      "Epoch [6/10], Step [3301/119], Loss: 1.5442\n",
      "Epoch [6/10], Step [3401/119], Loss: 1.5513\n",
      "Epoch [6/10], Step [3501/119], Loss: 1.4555\n",
      "Epoch [6/10], Step [3601/119], Loss: 1.2250\n",
      "Epoch [6/10], Step [3701/119], Loss: 1.0496\n",
      "Epoch [6/10], Step [3801/119], Loss: 0.9664\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.9162\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.8928\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.8099\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.7367\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.7396\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.6899\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.6546\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.6003\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.5969\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.5880\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.5707\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.5517\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.5450\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.5370\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.5309\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.5286\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.5204\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.5170\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.5148\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.5110\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.5081\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.5061\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.5036\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.5015\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.4989\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.4969\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.4962\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.4951\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.4926\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.4918\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.4906\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.4902\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.4876\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.4854\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.4855\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.4838\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.4829\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.4822\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.4798\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.4787\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.4792\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.4789\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.4767\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.4759\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.4737\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.4738\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.4708\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.4719\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.4683\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.4684\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.4673\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.4664\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.4655\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.4633\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.4641\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.4605\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.4597\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.4585\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.4564\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.4567\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.4542\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.4528\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.4527\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.4506\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.4508\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.4494\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.4446\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.4471\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.4466\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.4439\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.4436\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.4404\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.4393\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.4378\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.4364\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.4396\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.4341\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.4338\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.4321\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.4317\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.4256\n",
      "Epoch [7/10], Step [1/119], Loss: 1.0740\n",
      "Epoch [7/10], Step [101/119], Loss: 1.0704\n",
      "Epoch [7/10], Step [201/119], Loss: 1.0682\n",
      "Epoch [7/10], Step [301/119], Loss: 1.0658\n",
      "Epoch [7/10], Step [401/119], Loss: 1.0607\n",
      "Epoch [7/10], Step [501/119], Loss: 1.0682\n",
      "Epoch [7/10], Step [601/119], Loss: 1.0521\n",
      "Epoch [7/10], Step [701/119], Loss: 1.0606\n",
      "Epoch [7/10], Step [801/119], Loss: 1.0506\n",
      "Epoch [7/10], Step [901/119], Loss: 1.0510\n",
      "Epoch [7/10], Step [1001/119], Loss: 1.0467\n",
      "Epoch [7/10], Step [1101/119], Loss: 1.0504\n",
      "Epoch [7/10], Step [1201/119], Loss: 1.0436\n",
      "Epoch [7/10], Step [1301/119], Loss: 1.0401\n",
      "Epoch [7/10], Step [1401/119], Loss: 1.0343\n",
      "Epoch [7/10], Step [1501/119], Loss: 1.0344\n",
      "Epoch [7/10], Step [1601/119], Loss: 1.0316\n",
      "Epoch [7/10], Step [1701/119], Loss: 1.0222\n",
      "Epoch [7/10], Step [1801/119], Loss: 1.0207\n",
      "Epoch [7/10], Step [1901/119], Loss: 1.0186\n",
      "Epoch [7/10], Step [2001/119], Loss: 1.0168\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.7313\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.4559\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.4581\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.4570\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.4579\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.4614\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.4609\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.4613\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.4601\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.4608\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.4603\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.4614\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.4624\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.4612\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.4605\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.4600\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.4592\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.4581\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.4593\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.4577\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.4566\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.4564\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.4552\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.4542\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.4525\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.4541\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.4529\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.4509\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.4503\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.4485\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.4485\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.4461\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.4440\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.4439\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.4441\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.4419\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.4405\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.4385\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.4378\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.4390\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.4373\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.4331\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.4338\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.4269\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.4212\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.4197\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.4050\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.3984\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.3847\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.3757\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.3527\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.3351\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.3304\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.3049\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.2891\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.2859\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.2554\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.2284\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.2051\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.1996\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.1840\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.1584\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.1661\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.1554\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.1238\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.1248\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.1115\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.1219\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.0964\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.0880\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.0776\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.0785\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.0607\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.0525\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.0657\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.0544\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.0485\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.0485\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.0462\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.0308\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.0390\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.0331\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.0376\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.0301\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0324\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.0312\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0272\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0182\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.0227\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0251\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.0235\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0272\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0184\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0192\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.0193\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.0199\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.0137\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0162\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0172\n",
      "Epoch [8/10], Step [1/119], Loss: 14.2957\n",
      "Epoch [8/10], Step [101/119], Loss: 11.7875\n",
      "Epoch [8/10], Step [201/119], Loss: 9.3388\n",
      "Epoch [8/10], Step [301/119], Loss: 6.6964\n",
      "Epoch [8/10], Step [401/119], Loss: 4.1175\n",
      "Epoch [8/10], Step [501/119], Loss: 1.8264\n",
      "Epoch [8/10], Step [601/119], Loss: 0.4685\n",
      "Epoch [8/10], Step [701/119], Loss: 0.2023\n",
      "Epoch [8/10], Step [801/119], Loss: 0.1732\n",
      "Epoch [8/10], Step [901/119], Loss: 0.0792\n",
      "Epoch [8/10], Step [1001/119], Loss: 0.0730\n",
      "Epoch [8/10], Step [1101/119], Loss: 0.0478\n",
      "Epoch [8/10], Step [1201/119], Loss: 0.0385\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.0226\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.0255\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.0242\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.0199\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.0129\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.0145\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.0082\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.0116\n",
      "Epoch [8/10], Step [2101/119], Loss: 5.8518\n",
      "Epoch [8/10], Step [2201/119], Loss: 10.2497\n",
      "Epoch [8/10], Step [2301/119], Loss: 10.3326\n",
      "Epoch [8/10], Step [2401/119], Loss: 10.7643\n",
      "Epoch [8/10], Step [2501/119], Loss: 9.5673\n",
      "Epoch [8/10], Step [2601/119], Loss: 9.2699\n",
      "Epoch [8/10], Step [2701/119], Loss: 8.6158\n",
      "Epoch [8/10], Step [2801/119], Loss: 7.7873\n",
      "Epoch [8/10], Step [2901/119], Loss: 6.6131\n",
      "Epoch [8/10], Step [3001/119], Loss: 5.3032\n",
      "Epoch [8/10], Step [3101/119], Loss: 5.2785\n",
      "Epoch [8/10], Step [3201/119], Loss: 4.0359\n",
      "Epoch [8/10], Step [3301/119], Loss: 2.9152\n",
      "Epoch [8/10], Step [3401/119], Loss: 2.7454\n",
      "Epoch [8/10], Step [3501/119], Loss: 2.3701\n",
      "Epoch [8/10], Step [3601/119], Loss: 1.7605\n",
      "Epoch [8/10], Step [3701/119], Loss: 1.4401\n",
      "Epoch [8/10], Step [3801/119], Loss: 1.1967\n",
      "Epoch [8/10], Step [3901/119], Loss: 1.0661\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.9470\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.7342\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.6474\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.5787\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.5244\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.4677\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.4274\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.3964\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.3639\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.3537\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.3490\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.3408\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.3377\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.3230\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.2953\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.3056\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.3045\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.2719\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.2809\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.2637\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.2772\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.2688\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.2690\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.2781\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.2605\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.2662\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.2605\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.2456\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.2557\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.2480\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.2531\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.2328\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.2382\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.2428\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.2358\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.2384\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.2410\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.2314\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.2230\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.2146\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.2246\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.2200\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.2089\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.2159\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.2157\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.1997\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.2091\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.2028\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.2173\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.2008\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.1948\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.1948\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.1792\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.1972\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.1774\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.1926\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.1804\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.1765\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.1769\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.1768\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.1588\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.1668\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.1681\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.1826\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.1747\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.1655\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.1682\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.1593\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.1460\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.1575\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.1564\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.1569\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.1548\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.1422\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.1581\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.1531\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.1565\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.1395\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.1520\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.1635\n",
      "Epoch [9/10], Step [1/119], Loss: 3.0194\n",
      "Epoch [9/10], Step [101/119], Loss: 2.8578\n",
      "Epoch [9/10], Step [201/119], Loss: 2.7273\n",
      "Epoch [9/10], Step [301/119], Loss: 2.6478\n",
      "Epoch [9/10], Step [401/119], Loss: 2.3793\n",
      "Epoch [9/10], Step [501/119], Loss: 2.5725\n",
      "Epoch [9/10], Step [601/119], Loss: 2.2704\n",
      "Epoch [9/10], Step [701/119], Loss: 2.3185\n",
      "Epoch [9/10], Step [801/119], Loss: 1.8396\n",
      "Epoch [9/10], Step [901/119], Loss: 1.9526\n",
      "Epoch [9/10], Step [1001/119], Loss: 1.8181\n",
      "Epoch [9/10], Step [1101/119], Loss: 1.8046\n",
      "Epoch [9/10], Step [1201/119], Loss: 1.6678\n",
      "Epoch [9/10], Step [1301/119], Loss: 1.5963\n",
      "Epoch [9/10], Step [1401/119], Loss: 1.4871\n",
      "Epoch [9/10], Step [1501/119], Loss: 1.4404\n",
      "Epoch [9/10], Step [1601/119], Loss: 1.3659\n",
      "Epoch [9/10], Step [1701/119], Loss: 1.3151\n",
      "Epoch [9/10], Step [1801/119], Loss: 1.2612\n",
      "Epoch [9/10], Step [1901/119], Loss: 1.2394\n",
      "Epoch [9/10], Step [2001/119], Loss: 1.1980\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.7721\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.3744\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.3815\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.3858\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.3883\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.3967\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.3992\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.3992\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.3998\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.4023\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.4053\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.4073\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.4068\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.4084\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.4079\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.4071\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.4087\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.4077\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.4081\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.4086\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.4086\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.4079\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.4063\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.4055\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.4039\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.4057\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.4029\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.4031\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.4053\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.4014\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.4028\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.4018\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.3991\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.3976\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.3973\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.3989\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.3958\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.3953\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.3932\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.3975\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.3940\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.3921\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.3912\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.3927\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.3918\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.3904\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.3902\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.3848\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.3880\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.3870\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.3839\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.3824\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.3819\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.3808\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.3804\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.3776\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.3767\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.3785\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.3780\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.3780\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.3740\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.3736\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.3710\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.3706\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.3659\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.3647\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.3662\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.3650\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.3652\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.3658\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.3605\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.3589\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.3635\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.3566\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.3564\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.3513\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.3475\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.3435\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.3383\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.3296\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.3242\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.3113\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.3123\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.2922\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.2618\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.2588\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.2413\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.2156\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.2147\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.2005\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.1821\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.1670\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.1466\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.1507\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.1354\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.1235\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0944\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.1040\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.1050\n",
      "Epoch [10/10], Step [1/119], Loss: 4.8684\n",
      "Epoch [10/10], Step [101/119], Loss: 4.5289\n",
      "Epoch [10/10], Step [201/119], Loss: 3.8866\n",
      "Epoch [10/10], Step [301/119], Loss: 3.3318\n",
      "Epoch [10/10], Step [401/119], Loss: 2.6795\n",
      "Epoch [10/10], Step [501/119], Loss: 2.3412\n",
      "Epoch [10/10], Step [601/119], Loss: 1.6432\n",
      "Epoch [10/10], Step [701/119], Loss: 1.3434\n",
      "Epoch [10/10], Step [801/119], Loss: 1.0683\n",
      "Epoch [10/10], Step [901/119], Loss: 0.8526\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.7584\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.6248\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.5980\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.4826\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.4432\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.4435\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.3792\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.3148\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.3102\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.2686\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.2743\n",
      "Epoch [10/10], Step [2101/119], Loss: 1.1358\n",
      "Epoch [10/10], Step [2201/119], Loss: 1.8330\n",
      "Epoch [10/10], Step [2301/119], Loss: 1.9197\n",
      "Epoch [10/10], Step [2401/119], Loss: 1.9764\n",
      "Epoch [10/10], Step [2501/119], Loss: 1.8326\n",
      "Epoch [10/10], Step [2601/119], Loss: 1.7820\n",
      "Epoch [10/10], Step [2701/119], Loss: 1.5848\n",
      "Epoch [10/10], Step [2801/119], Loss: 1.5493\n",
      "Epoch [10/10], Step [2901/119], Loss: 1.2692\n",
      "Epoch [10/10], Step [3001/119], Loss: 1.0345\n",
      "Epoch [10/10], Step [3101/119], Loss: 1.0623\n",
      "Epoch [10/10], Step [3201/119], Loss: 0.8825\n",
      "Epoch [10/10], Step [3301/119], Loss: 0.7169\n",
      "Epoch [10/10], Step [3401/119], Loss: 0.6656\n",
      "Epoch [10/10], Step [3501/119], Loss: 0.6116\n",
      "Epoch [10/10], Step [3601/119], Loss: 0.5922\n",
      "Epoch [10/10], Step [3701/119], Loss: 0.5286\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.5148\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.4981\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.4745\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.4621\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.4587\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.4491\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.4555\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.4421\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.4320\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.4385\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.4285\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.4226\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.4256\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.4212\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.4208\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.4186\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.4181\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.4177\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.4138\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.4115\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.4120\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.4130\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.4082\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.4079\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.4076\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.4088\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.4068\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.4031\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.4023\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.4001\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.3994\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.3999\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.3984\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.3992\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.3956\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.3961\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.3944\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.3944\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.3944\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.3917\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.3903\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.3893\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.3890\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.3875\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.3872\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.3870\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.3859\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.3857\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.3844\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.3833\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.3824\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.3809\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.3801\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.3807\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.3787\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.3784\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.3777\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.3767\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.3753\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.3751\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.3738\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.3731\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.3725\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.3710\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.3712\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.3723\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.3699\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.3729\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.3684\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.3672\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.3651\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.3654\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.3646\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.3642\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.3631\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.3625\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.3629\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.3612\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.3599\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.3578\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.3587\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.3576\n",
      "Epoch [1/10], Step [1/119], Loss: 0.8141\n",
      "Epoch [1/10], Step [101/119], Loss: 0.6096\n",
      "Epoch [1/10], Step [201/119], Loss: 0.4721\n",
      "Epoch [1/10], Step [301/119], Loss: 0.3868\n",
      "Epoch [1/10], Step [401/119], Loss: 0.3178\n",
      "Epoch [1/10], Step [501/119], Loss: 0.2007\n",
      "Epoch [1/10], Step [601/119], Loss: 0.1977\n",
      "Epoch [1/10], Step [701/119], Loss: 0.1339\n",
      "Epoch [1/10], Step [801/119], Loss: 0.1531\n",
      "Epoch [1/10], Step [901/119], Loss: 0.0872\n",
      "Epoch [1/10], Step [1001/119], Loss: 0.0742\n",
      "Epoch [1/10], Step [1101/119], Loss: 0.0494\n",
      "Epoch [1/10], Step [1201/119], Loss: 0.0471\n",
      "Epoch [1/10], Step [1301/119], Loss: 0.0276\n",
      "Epoch [1/10], Step [1401/119], Loss: 0.0266\n",
      "Epoch [1/10], Step [1501/119], Loss: 0.0201\n",
      "Epoch [1/10], Step [1601/119], Loss: 0.0141\n",
      "Epoch [1/10], Step [1701/119], Loss: 0.0103\n",
      "Epoch [1/10], Step [1801/119], Loss: 0.0069\n",
      "Epoch [1/10], Step [1901/119], Loss: 0.0049\n",
      "Epoch [1/10], Step [2001/119], Loss: 0.0053\n",
      "Epoch [1/10], Step [2101/119], Loss: 7.3155\n",
      "Epoch [1/10], Step [2201/119], Loss: 12.4661\n",
      "Epoch [1/10], Step [2301/119], Loss: 11.9079\n",
      "Epoch [1/10], Step [2401/119], Loss: 11.0031\n",
      "Epoch [1/10], Step [2501/119], Loss: 9.3227\n",
      "Epoch [1/10], Step [2601/119], Loss: 8.1325\n",
      "Epoch [1/10], Step [2701/119], Loss: 6.9917\n",
      "Epoch [1/10], Step [2801/119], Loss: 5.8309\n",
      "Epoch [1/10], Step [2901/119], Loss: 4.3772\n",
      "Epoch [1/10], Step [3001/119], Loss: 2.9940\n",
      "Epoch [1/10], Step [3101/119], Loss: 2.5519\n",
      "Epoch [1/10], Step [3201/119], Loss: 1.7768\n",
      "Epoch [1/10], Step [3301/119], Loss: 1.1594\n",
      "Epoch [1/10], Step [3401/119], Loss: 0.9551\n",
      "Epoch [1/10], Step [3501/119], Loss: 0.7978\n",
      "Epoch [1/10], Step [3601/119], Loss: 0.7276\n",
      "Epoch [1/10], Step [3701/119], Loss: 0.6943\n",
      "Epoch [1/10], Step [3801/119], Loss: 0.6775\n",
      "Epoch [1/10], Step [3901/119], Loss: 0.6706\n",
      "Epoch [1/10], Step [4001/119], Loss: 0.6649\n",
      "Epoch [1/10], Step [4101/119], Loss: 0.6590\n",
      "Epoch [1/10], Step [4201/119], Loss: 0.6568\n",
      "Epoch [1/10], Step [4301/119], Loss: 0.6525\n",
      "Epoch [1/10], Step [4401/119], Loss: 0.6553\n",
      "Epoch [1/10], Step [4501/119], Loss: 0.6438\n",
      "Epoch [1/10], Step [4601/119], Loss: 0.6431\n",
      "Epoch [1/10], Step [4701/119], Loss: 0.6365\n",
      "Epoch [1/10], Step [4801/119], Loss: 0.6359\n",
      "Epoch [1/10], Step [4901/119], Loss: 0.6345\n",
      "Epoch [1/10], Step [5001/119], Loss: 0.6290\n",
      "Epoch [1/10], Step [5101/119], Loss: 0.6285\n",
      "Epoch [1/10], Step [5201/119], Loss: 0.6249\n",
      "Epoch [1/10], Step [5301/119], Loss: 0.6210\n",
      "Epoch [1/10], Step [5401/119], Loss: 0.6210\n",
      "Epoch [1/10], Step [5501/119], Loss: 0.6150\n",
      "Epoch [1/10], Step [5601/119], Loss: 0.6150\n",
      "Epoch [1/10], Step [5701/119], Loss: 0.6064\n",
      "Epoch [1/10], Step [5801/119], Loss: 0.6068\n",
      "Epoch [1/10], Step [5901/119], Loss: 0.6010\n",
      "Epoch [1/10], Step [6001/119], Loss: 0.6022\n",
      "Epoch [1/10], Step [6101/119], Loss: 0.5978\n",
      "Epoch [1/10], Step [6201/119], Loss: 0.5963\n",
      "Epoch [1/10], Step [6301/119], Loss: 0.5887\n",
      "Epoch [1/10], Step [6401/119], Loss: 0.5821\n",
      "Epoch [1/10], Step [6501/119], Loss: 0.5773\n",
      "Epoch [1/10], Step [6601/119], Loss: 0.5624\n",
      "Epoch [1/10], Step [6701/119], Loss: 0.5425\n",
      "Epoch [1/10], Step [6801/119], Loss: 0.5246\n",
      "Epoch [1/10], Step [6901/119], Loss: 0.5054\n",
      "Epoch [1/10], Step [7001/119], Loss: 0.4784\n",
      "Epoch [1/10], Step [7101/119], Loss: 0.4300\n",
      "Epoch [1/10], Step [7201/119], Loss: 0.4074\n",
      "Epoch [1/10], Step [7301/119], Loss: 0.3899\n",
      "Epoch [1/10], Step [7401/119], Loss: 0.3481\n",
      "Epoch [1/10], Step [7501/119], Loss: 0.3199\n",
      "Epoch [1/10], Step [7601/119], Loss: 0.3109\n",
      "Epoch [1/10], Step [7701/119], Loss: 0.2584\n",
      "Epoch [1/10], Step [7801/119], Loss: 0.2223\n",
      "Epoch [1/10], Step [7901/119], Loss: 0.1977\n",
      "Epoch [1/10], Step [8001/119], Loss: 0.1862\n",
      "Epoch [1/10], Step [8101/119], Loss: 0.1632\n",
      "Epoch [1/10], Step [8201/119], Loss: 0.1267\n",
      "Epoch [1/10], Step [8301/119], Loss: 0.1443\n",
      "Epoch [1/10], Step [8401/119], Loss: 0.1302\n",
      "Epoch [1/10], Step [8501/119], Loss: 0.0950\n",
      "Epoch [1/10], Step [8601/119], Loss: 0.1019\n",
      "Epoch [1/10], Step [8701/119], Loss: 0.0811\n",
      "Epoch [1/10], Step [8801/119], Loss: 0.0963\n",
      "Epoch [1/10], Step [8901/119], Loss: 0.0622\n",
      "Epoch [1/10], Step [9001/119], Loss: 0.0499\n",
      "Epoch [1/10], Step [9101/119], Loss: 0.0620\n",
      "Epoch [1/10], Step [9201/119], Loss: 0.0420\n",
      "Epoch [1/10], Step [9301/119], Loss: 0.0469\n",
      "Epoch [1/10], Step [9401/119], Loss: 0.0526\n",
      "Epoch [1/10], Step [9501/119], Loss: 0.0327\n",
      "Epoch [1/10], Step [9601/119], Loss: 0.0358\n",
      "Epoch [1/10], Step [9701/119], Loss: 0.0295\n",
      "Epoch [1/10], Step [9801/119], Loss: 0.0379\n",
      "Epoch [1/10], Step [9901/119], Loss: 0.0242\n",
      "Epoch [1/10], Step [10001/119], Loss: 0.0309\n",
      "Epoch [1/10], Step [10101/119], Loss: 0.0271\n",
      "Epoch [1/10], Step [10201/119], Loss: 0.0207\n",
      "Epoch [1/10], Step [10301/119], Loss: 0.0243\n",
      "Epoch [1/10], Step [10401/119], Loss: 0.0215\n",
      "Epoch [1/10], Step [10501/119], Loss: 0.0199\n",
      "Epoch [1/10], Step [10601/119], Loss: 0.0177\n",
      "Epoch [1/10], Step [10701/119], Loss: 0.0131\n",
      "Epoch [1/10], Step [10801/119], Loss: 0.0127\n",
      "Epoch [1/10], Step [10901/119], Loss: 0.0155\n",
      "Epoch [1/10], Step [11001/119], Loss: 0.0117\n",
      "Epoch [1/10], Step [11101/119], Loss: 0.0149\n",
      "Epoch [1/10], Step [11201/119], Loss: 0.0104\n",
      "Epoch [1/10], Step [11301/119], Loss: 0.0094\n",
      "Epoch [1/10], Step [11401/119], Loss: 0.0099\n",
      "Epoch [1/10], Step [11501/119], Loss: 0.0095\n",
      "Epoch [1/10], Step [11601/119], Loss: 0.0079\n",
      "Epoch [1/10], Step [11701/119], Loss: 0.0074\n",
      "Epoch [1/10], Step [11801/119], Loss: 0.0060\n",
      "Epoch [1/10], Step [11901/119], Loss: 0.0050\n",
      "Epoch [2/10], Step [1/119], Loss: 19.2200\n",
      "Epoch [2/10], Step [101/119], Loss: 17.1508\n",
      "Epoch [2/10], Step [201/119], Loss: 14.6333\n",
      "Epoch [2/10], Step [301/119], Loss: 13.0040\n",
      "Epoch [2/10], Step [401/119], Loss: 10.6631\n",
      "Epoch [2/10], Step [501/119], Loss: 10.4112\n",
      "Epoch [2/10], Step [601/119], Loss: 8.2252\n",
      "Epoch [2/10], Step [701/119], Loss: 7.6343\n",
      "Epoch [2/10], Step [801/119], Loss: 4.1814\n",
      "Epoch [2/10], Step [901/119], Loss: 4.6452\n",
      "Epoch [2/10], Step [1001/119], Loss: 3.5193\n",
      "Epoch [2/10], Step [1101/119], Loss: 3.1656\n",
      "Epoch [2/10], Step [1201/119], Loss: 2.1529\n",
      "Epoch [2/10], Step [1301/119], Loss: 1.6707\n",
      "Epoch [2/10], Step [1401/119], Loss: 1.1774\n",
      "Epoch [2/10], Step [1501/119], Loss: 0.8899\n",
      "Epoch [2/10], Step [1601/119], Loss: 0.6918\n",
      "Epoch [2/10], Step [1701/119], Loss: 0.5730\n",
      "Epoch [2/10], Step [1801/119], Loss: 0.5002\n",
      "Epoch [2/10], Step [1901/119], Loss: 0.4552\n",
      "Epoch [2/10], Step [2001/119], Loss: 0.4112\n",
      "Epoch [2/10], Step [2101/119], Loss: 0.7978\n",
      "Epoch [2/10], Step [2201/119], Loss: 1.1644\n",
      "Epoch [2/10], Step [2301/119], Loss: 1.2085\n",
      "Epoch [2/10], Step [2401/119], Loss: 1.3453\n",
      "Epoch [2/10], Step [2501/119], Loss: 1.3152\n",
      "Epoch [2/10], Step [2601/119], Loss: 1.2777\n",
      "Epoch [2/10], Step [2701/119], Loss: 1.2946\n",
      "Epoch [2/10], Step [2801/119], Loss: 1.2844\n",
      "Epoch [2/10], Step [2901/119], Loss: 1.1788\n",
      "Epoch [2/10], Step [3001/119], Loss: 1.0942\n",
      "Epoch [2/10], Step [3101/119], Loss: 1.1291\n",
      "Epoch [2/10], Step [3201/119], Loss: 1.0295\n",
      "Epoch [2/10], Step [3301/119], Loss: 0.9013\n",
      "Epoch [2/10], Step [3401/119], Loss: 0.8814\n",
      "Epoch [2/10], Step [3501/119], Loss: 0.8591\n",
      "Epoch [2/10], Step [3601/119], Loss: 0.7998\n",
      "Epoch [2/10], Step [3701/119], Loss: 0.7616\n",
      "Epoch [2/10], Step [3801/119], Loss: 0.7583\n",
      "Epoch [2/10], Step [3901/119], Loss: 0.7103\n",
      "Epoch [2/10], Step [4001/119], Loss: 0.6858\n",
      "Epoch [2/10], Step [4101/119], Loss: 0.6662\n",
      "Epoch [2/10], Step [4201/119], Loss: 0.6454\n",
      "Epoch [2/10], Step [4301/119], Loss: 0.6373\n",
      "Epoch [2/10], Step [4401/119], Loss: 0.6364\n",
      "Epoch [2/10], Step [4501/119], Loss: 0.6106\n",
      "Epoch [2/10], Step [4601/119], Loss: 0.5993\n",
      "Epoch [2/10], Step [4701/119], Loss: 0.5944\n",
      "Epoch [2/10], Step [4801/119], Loss: 0.5860\n",
      "Epoch [2/10], Step [4901/119], Loss: 0.5808\n",
      "Epoch [2/10], Step [5001/119], Loss: 0.5782\n",
      "Epoch [2/10], Step [5101/119], Loss: 0.5728\n",
      "Epoch [2/10], Step [5201/119], Loss: 0.5719\n",
      "Epoch [2/10], Step [5301/119], Loss: 0.5667\n",
      "Epoch [2/10], Step [5401/119], Loss: 0.5624\n",
      "Epoch [2/10], Step [5501/119], Loss: 0.5613\n",
      "Epoch [2/10], Step [5601/119], Loss: 0.5589\n",
      "Epoch [2/10], Step [5701/119], Loss: 0.5523\n",
      "Epoch [2/10], Step [5801/119], Loss: 0.5529\n",
      "Epoch [2/10], Step [5901/119], Loss: 0.5491\n",
      "Epoch [2/10], Step [6001/119], Loss: 0.5510\n",
      "Epoch [2/10], Step [6101/119], Loss: 0.5471\n",
      "Epoch [2/10], Step [6201/119], Loss: 0.5424\n",
      "Epoch [2/10], Step [6301/119], Loss: 0.5397\n",
      "Epoch [2/10], Step [6401/119], Loss: 0.5354\n",
      "Epoch [2/10], Step [6501/119], Loss: 0.5357\n",
      "Epoch [2/10], Step [6601/119], Loss: 0.5348\n",
      "Epoch [2/10], Step [6701/119], Loss: 0.5282\n",
      "Epoch [2/10], Step [6801/119], Loss: 0.5157\n",
      "Epoch [2/10], Step [6901/119], Loss: 0.5109\n",
      "Epoch [2/10], Step [7001/119], Loss: 0.4959\n",
      "Epoch [2/10], Step [7101/119], Loss: 0.4770\n",
      "Epoch [2/10], Step [7201/119], Loss: 0.4611\n",
      "Epoch [2/10], Step [7301/119], Loss: 0.4508\n",
      "Epoch [2/10], Step [7401/119], Loss: 0.4272\n",
      "Epoch [2/10], Step [7501/119], Loss: 0.4069\n",
      "Epoch [2/10], Step [7601/119], Loss: 0.3930\n",
      "Epoch [2/10], Step [7701/119], Loss: 0.3564\n",
      "Epoch [2/10], Step [7801/119], Loss: 0.3218\n",
      "Epoch [2/10], Step [7901/119], Loss: 0.2943\n",
      "Epoch [2/10], Step [8001/119], Loss: 0.2815\n",
      "Epoch [2/10], Step [8101/119], Loss: 0.2487\n",
      "Epoch [2/10], Step [8201/119], Loss: 0.2210\n",
      "Epoch [2/10], Step [8301/119], Loss: 0.2288\n",
      "Epoch [2/10], Step [8401/119], Loss: 0.2052\n",
      "Epoch [2/10], Step [8501/119], Loss: 0.1585\n",
      "Epoch [2/10], Step [8601/119], Loss: 0.1633\n",
      "Epoch [2/10], Step [8701/119], Loss: 0.1400\n",
      "Epoch [2/10], Step [8801/119], Loss: 0.1551\n",
      "Epoch [2/10], Step [8901/119], Loss: 0.1120\n",
      "Epoch [2/10], Step [9001/119], Loss: 0.0874\n",
      "Epoch [2/10], Step [9101/119], Loss: 0.1120\n",
      "Epoch [2/10], Step [9201/119], Loss: 0.0672\n",
      "Epoch [2/10], Step [9301/119], Loss: 0.0761\n",
      "Epoch [2/10], Step [9401/119], Loss: 0.0858\n",
      "Epoch [2/10], Step [9501/119], Loss: 0.0596\n",
      "Epoch [2/10], Step [9601/119], Loss: 0.0583\n",
      "Epoch [2/10], Step [9701/119], Loss: 0.0537\n",
      "Epoch [2/10], Step [9801/119], Loss: 0.0651\n",
      "Epoch [2/10], Step [9901/119], Loss: 0.0397\n",
      "Epoch [2/10], Step [10001/119], Loss: 0.0504\n",
      "Epoch [2/10], Step [10101/119], Loss: 0.0461\n",
      "Epoch [2/10], Step [10201/119], Loss: 0.0384\n",
      "Epoch [2/10], Step [10301/119], Loss: 0.0399\n",
      "Epoch [2/10], Step [10401/119], Loss: 0.0367\n",
      "Epoch [2/10], Step [10501/119], Loss: 0.0296\n",
      "Epoch [2/10], Step [10601/119], Loss: 0.0273\n",
      "Epoch [2/10], Step [10701/119], Loss: 0.0248\n",
      "Epoch [2/10], Step [10801/119], Loss: 0.0252\n",
      "Epoch [2/10], Step [10901/119], Loss: 0.0221\n",
      "Epoch [2/10], Step [11001/119], Loss: 0.0174\n",
      "Epoch [2/10], Step [11101/119], Loss: 0.0240\n",
      "Epoch [2/10], Step [11201/119], Loss: 0.0200\n",
      "Epoch [2/10], Step [11301/119], Loss: 0.0140\n",
      "Epoch [2/10], Step [11401/119], Loss: 0.0173\n",
      "Epoch [2/10], Step [11501/119], Loss: 0.0163\n",
      "Epoch [2/10], Step [11601/119], Loss: 0.0139\n",
      "Epoch [2/10], Step [11701/119], Loss: 0.0126\n",
      "Epoch [2/10], Step [11801/119], Loss: 0.0113\n",
      "Epoch [2/10], Step [11901/119], Loss: 0.0115\n",
      "Epoch [3/10], Step [1/119], Loss: 16.0383\n",
      "Epoch [3/10], Step [101/119], Loss: 14.1362\n",
      "Epoch [3/10], Step [201/119], Loss: 12.4508\n",
      "Epoch [3/10], Step [301/119], Loss: 10.5299\n",
      "Epoch [3/10], Step [401/119], Loss: 8.7027\n",
      "Epoch [3/10], Step [501/119], Loss: 8.3216\n",
      "Epoch [3/10], Step [601/119], Loss: 6.4797\n",
      "Epoch [3/10], Step [701/119], Loss: 6.0588\n",
      "Epoch [3/10], Step [801/119], Loss: 3.0718\n",
      "Epoch [3/10], Step [901/119], Loss: 3.1873\n",
      "Epoch [3/10], Step [1001/119], Loss: 2.3087\n",
      "Epoch [3/10], Step [1101/119], Loss: 1.6617\n",
      "Epoch [3/10], Step [1201/119], Loss: 1.0074\n",
      "Epoch [3/10], Step [1301/119], Loss: 0.6308\n",
      "Epoch [3/10], Step [1401/119], Loss: 0.4758\n",
      "Epoch [3/10], Step [1501/119], Loss: 0.3744\n",
      "Epoch [3/10], Step [1601/119], Loss: 0.3176\n",
      "Epoch [3/10], Step [1701/119], Loss: 0.2310\n",
      "Epoch [3/10], Step [1801/119], Loss: 0.2135\n",
      "Epoch [3/10], Step [1901/119], Loss: 0.1897\n",
      "Epoch [3/10], Step [2001/119], Loss: 0.1896\n",
      "Epoch [3/10], Step [2101/119], Loss: 1.2872\n",
      "Epoch [3/10], Step [2201/119], Loss: 2.3190\n",
      "Epoch [3/10], Step [2301/119], Loss: 2.4582\n",
      "Epoch [3/10], Step [2401/119], Loss: 2.5915\n",
      "Epoch [3/10], Step [2501/119], Loss: 2.4406\n",
      "Epoch [3/10], Step [2601/119], Loss: 2.4752\n",
      "Epoch [3/10], Step [2701/119], Loss: 2.4450\n",
      "Epoch [3/10], Step [2801/119], Loss: 2.3814\n",
      "Epoch [3/10], Step [2901/119], Loss: 2.1130\n",
      "Epoch [3/10], Step [3001/119], Loss: 1.8926\n",
      "Epoch [3/10], Step [3101/119], Loss: 1.9855\n",
      "Epoch [3/10], Step [3201/119], Loss: 1.7485\n",
      "Epoch [3/10], Step [3301/119], Loss: 1.3837\n",
      "Epoch [3/10], Step [3401/119], Loss: 1.4244\n",
      "Epoch [3/10], Step [3501/119], Loss: 1.3672\n",
      "Epoch [3/10], Step [3601/119], Loss: 1.1977\n",
      "Epoch [3/10], Step [3701/119], Loss: 1.0930\n",
      "Epoch [3/10], Step [3801/119], Loss: 1.0472\n",
      "Epoch [3/10], Step [3901/119], Loss: 1.0114\n",
      "Epoch [3/10], Step [4001/119], Loss: 0.9833\n",
      "Epoch [3/10], Step [4101/119], Loss: 0.8880\n",
      "Epoch [3/10], Step [4201/119], Loss: 0.8142\n",
      "Epoch [3/10], Step [4301/119], Loss: 0.8018\n",
      "Epoch [3/10], Step [4401/119], Loss: 0.7917\n",
      "Epoch [3/10], Step [4501/119], Loss: 0.7461\n",
      "Epoch [3/10], Step [4601/119], Loss: 0.6832\n",
      "Epoch [3/10], Step [4701/119], Loss: 0.6623\n",
      "Epoch [3/10], Step [4801/119], Loss: 0.6544\n",
      "Epoch [3/10], Step [4901/119], Loss: 0.6294\n",
      "Epoch [3/10], Step [5001/119], Loss: 0.6068\n",
      "Epoch [3/10], Step [5101/119], Loss: 0.5854\n",
      "Epoch [3/10], Step [5201/119], Loss: 0.5702\n",
      "Epoch [3/10], Step [5301/119], Loss: 0.5496\n",
      "Epoch [3/10], Step [5401/119], Loss: 0.5258\n",
      "Epoch [3/10], Step [5501/119], Loss: 0.5142\n",
      "Epoch [3/10], Step [5601/119], Loss: 0.4982\n",
      "Epoch [3/10], Step [5701/119], Loss: 0.4475\n",
      "Epoch [3/10], Step [5801/119], Loss: 0.4461\n",
      "Epoch [3/10], Step [5901/119], Loss: 0.4065\n",
      "Epoch [3/10], Step [6001/119], Loss: 0.4059\n",
      "Epoch [3/10], Step [6101/119], Loss: 0.3800\n",
      "Epoch [3/10], Step [6201/119], Loss: 0.3541\n",
      "Epoch [3/10], Step [6301/119], Loss: 0.3533\n",
      "Epoch [3/10], Step [6401/119], Loss: 0.3142\n",
      "Epoch [3/10], Step [6501/119], Loss: 0.2986\n",
      "Epoch [3/10], Step [6601/119], Loss: 0.2887\n",
      "Epoch [3/10], Step [6701/119], Loss: 0.2553\n",
      "Epoch [3/10], Step [6801/119], Loss: 0.2503\n",
      "Epoch [3/10], Step [6901/119], Loss: 0.2338\n",
      "Epoch [3/10], Step [7001/119], Loss: 0.2262\n",
      "Epoch [3/10], Step [7101/119], Loss: 0.1905\n",
      "Epoch [3/10], Step [7201/119], Loss: 0.1902\n",
      "Epoch [3/10], Step [7301/119], Loss: 0.1892\n",
      "Epoch [3/10], Step [7401/119], Loss: 0.1733\n",
      "Epoch [3/10], Step [7501/119], Loss: 0.1742\n",
      "Epoch [3/10], Step [7601/119], Loss: 0.1699\n",
      "Epoch [3/10], Step [7701/119], Loss: 0.1431\n",
      "Epoch [3/10], Step [7801/119], Loss: 0.1280\n",
      "Epoch [3/10], Step [7901/119], Loss: 0.1159\n",
      "Epoch [3/10], Step [8001/119], Loss: 0.1181\n",
      "Epoch [3/10], Step [8101/119], Loss: 0.1009\n",
      "Epoch [3/10], Step [8201/119], Loss: 0.0845\n",
      "Epoch [3/10], Step [8301/119], Loss: 0.0995\n",
      "Epoch [3/10], Step [8401/119], Loss: 0.0930\n",
      "Epoch [3/10], Step [8501/119], Loss: 0.0688\n",
      "Epoch [3/10], Step [8601/119], Loss: 0.0770\n",
      "Epoch [3/10], Step [8701/119], Loss: 0.0639\n",
      "Epoch [3/10], Step [8801/119], Loss: 0.0765\n",
      "Epoch [3/10], Step [8901/119], Loss: 0.0546\n",
      "Epoch [3/10], Step [9001/119], Loss: 0.0427\n",
      "Epoch [3/10], Step [9101/119], Loss: 0.0556\n",
      "Epoch [3/10], Step [9201/119], Loss: 0.0340\n",
      "Epoch [3/10], Step [9301/119], Loss: 0.0392\n",
      "Epoch [3/10], Step [9401/119], Loss: 0.0497\n",
      "Epoch [3/10], Step [9501/119], Loss: 0.0321\n",
      "Epoch [3/10], Step [9601/119], Loss: 0.0357\n",
      "Epoch [3/10], Step [9701/119], Loss: 0.0300\n",
      "Epoch [3/10], Step [9801/119], Loss: 0.0392\n",
      "Epoch [3/10], Step [9901/119], Loss: 0.0239\n",
      "Epoch [3/10], Step [10001/119], Loss: 0.0283\n",
      "Epoch [3/10], Step [10101/119], Loss: 0.0288\n",
      "Epoch [3/10], Step [10201/119], Loss: 0.0206\n",
      "Epoch [3/10], Step [10301/119], Loss: 0.0219\n",
      "Epoch [3/10], Step [10401/119], Loss: 0.0235\n",
      "Epoch [3/10], Step [10501/119], Loss: 0.0196\n",
      "Epoch [3/10], Step [10601/119], Loss: 0.0195\n",
      "Epoch [3/10], Step [10701/119], Loss: 0.0150\n",
      "Epoch [3/10], Step [10801/119], Loss: 0.0151\n",
      "Epoch [3/10], Step [10901/119], Loss: 0.0149\n",
      "Epoch [3/10], Step [11001/119], Loss: 0.0111\n",
      "Epoch [3/10], Step [11101/119], Loss: 0.0143\n",
      "Epoch [3/10], Step [11201/119], Loss: 0.0117\n",
      "Epoch [3/10], Step [11301/119], Loss: 0.0082\n",
      "Epoch [3/10], Step [11401/119], Loss: 0.0107\n",
      "Epoch [3/10], Step [11501/119], Loss: 0.0083\n",
      "Epoch [3/10], Step [11601/119], Loss: 0.0082\n",
      "Epoch [3/10], Step [11701/119], Loss: 0.0085\n",
      "Epoch [3/10], Step [11801/119], Loss: 0.0075\n",
      "Epoch [3/10], Step [11901/119], Loss: 0.0051\n",
      "Epoch [4/10], Step [1/119], Loss: 19.0648\n",
      "Epoch [4/10], Step [101/119], Loss: 16.3159\n",
      "Epoch [4/10], Step [201/119], Loss: 13.2698\n",
      "Epoch [4/10], Step [301/119], Loss: 10.6945\n",
      "Epoch [4/10], Step [401/119], Loss: 7.6263\n",
      "Epoch [4/10], Step [501/119], Loss: 6.0593\n",
      "Epoch [4/10], Step [601/119], Loss: 3.4792\n",
      "Epoch [4/10], Step [701/119], Loss: 1.7441\n",
      "Epoch [4/10], Step [801/119], Loss: 0.5446\n",
      "Epoch [4/10], Step [901/119], Loss: 0.2249\n",
      "Epoch [4/10], Step [1001/119], Loss: 0.1591\n",
      "Epoch [4/10], Step [1101/119], Loss: 0.1028\n",
      "Epoch [4/10], Step [1201/119], Loss: 0.0891\n",
      "Epoch [4/10], Step [1301/119], Loss: 0.0540\n",
      "Epoch [4/10], Step [1401/119], Loss: 0.0541\n",
      "Epoch [4/10], Step [1501/119], Loss: 0.0539\n",
      "Epoch [4/10], Step [1601/119], Loss: 0.0387\n",
      "Epoch [4/10], Step [1701/119], Loss: 0.0252\n",
      "Epoch [4/10], Step [1801/119], Loss: 0.0266\n",
      "Epoch [4/10], Step [1901/119], Loss: 0.0164\n",
      "Epoch [4/10], Step [2001/119], Loss: 0.0244\n",
      "Epoch [4/10], Step [2101/119], Loss: 4.2646\n",
      "Epoch [4/10], Step [2201/119], Loss: 7.5654\n",
      "Epoch [4/10], Step [2301/119], Loss: 7.7505\n",
      "Epoch [4/10], Step [2401/119], Loss: 7.7415\n",
      "Epoch [4/10], Step [2501/119], Loss: 7.3605\n",
      "Epoch [4/10], Step [2601/119], Loss: 6.8267\n",
      "Epoch [4/10], Step [2701/119], Loss: 6.4485\n",
      "Epoch [4/10], Step [2801/119], Loss: 6.0808\n",
      "Epoch [4/10], Step [2901/119], Loss: 5.4550\n",
      "Epoch [4/10], Step [3001/119], Loss: 4.4538\n",
      "Epoch [4/10], Step [3101/119], Loss: 4.4445\n",
      "Epoch [4/10], Step [3201/119], Loss: 3.6557\n",
      "Epoch [4/10], Step [3301/119], Loss: 2.5690\n",
      "Epoch [4/10], Step [3401/119], Loss: 2.5880\n",
      "Epoch [4/10], Step [3501/119], Loss: 2.3369\n",
      "Epoch [4/10], Step [3601/119], Loss: 1.8506\n",
      "Epoch [4/10], Step [3701/119], Loss: 1.5905\n",
      "Epoch [4/10], Step [3801/119], Loss: 1.3941\n",
      "Epoch [4/10], Step [3901/119], Loss: 1.2672\n",
      "Epoch [4/10], Step [4001/119], Loss: 1.1978\n",
      "Epoch [4/10], Step [4101/119], Loss: 1.0305\n",
      "Epoch [4/10], Step [4201/119], Loss: 0.9063\n",
      "Epoch [4/10], Step [4301/119], Loss: 0.8896\n",
      "Epoch [4/10], Step [4401/119], Loss: 0.8512\n",
      "Epoch [4/10], Step [4501/119], Loss: 0.7368\n",
      "Epoch [4/10], Step [4601/119], Loss: 0.6637\n",
      "Epoch [4/10], Step [4701/119], Loss: 0.6541\n",
      "Epoch [4/10], Step [4801/119], Loss: 0.6295\n",
      "Epoch [4/10], Step [4901/119], Loss: 0.6079\n",
      "Epoch [4/10], Step [5001/119], Loss: 0.5712\n",
      "Epoch [4/10], Step [5101/119], Loss: 0.5609\n",
      "Epoch [4/10], Step [5201/119], Loss: 0.5489\n",
      "Epoch [4/10], Step [5301/119], Loss: 0.5381\n",
      "Epoch [4/10], Step [5401/119], Loss: 0.5361\n",
      "Epoch [4/10], Step [5501/119], Loss: 0.5220\n",
      "Epoch [4/10], Step [5601/119], Loss: 0.5155\n",
      "Epoch [4/10], Step [5701/119], Loss: 0.5052\n",
      "Epoch [4/10], Step [5801/119], Loss: 0.5014\n",
      "Epoch [4/10], Step [5901/119], Loss: 0.5009\n",
      "Epoch [4/10], Step [6001/119], Loss: 0.4965\n",
      "Epoch [4/10], Step [6101/119], Loss: 0.4915\n",
      "Epoch [4/10], Step [6201/119], Loss: 0.4890\n",
      "Epoch [4/10], Step [6301/119], Loss: 0.4806\n",
      "Epoch [4/10], Step [6401/119], Loss: 0.4737\n",
      "Epoch [4/10], Step [6501/119], Loss: 0.4756\n",
      "Epoch [4/10], Step [6601/119], Loss: 0.4747\n",
      "Epoch [4/10], Step [6701/119], Loss: 0.4668\n",
      "Epoch [4/10], Step [6801/119], Loss: 0.4693\n",
      "Epoch [4/10], Step [6901/119], Loss: 0.4622\n",
      "Epoch [4/10], Step [7001/119], Loss: 0.4619\n",
      "Epoch [4/10], Step [7101/119], Loss: 0.4526\n",
      "Epoch [4/10], Step [7201/119], Loss: 0.4539\n",
      "Epoch [4/10], Step [7301/119], Loss: 0.4590\n",
      "Epoch [4/10], Step [7401/119], Loss: 0.4533\n",
      "Epoch [4/10], Step [7501/119], Loss: 0.4525\n",
      "Epoch [4/10], Step [7601/119], Loss: 0.4519\n",
      "Epoch [4/10], Step [7701/119], Loss: 0.4461\n",
      "Epoch [4/10], Step [7801/119], Loss: 0.4404\n",
      "Epoch [4/10], Step [7901/119], Loss: 0.4378\n",
      "Epoch [4/10], Step [8001/119], Loss: 0.4430\n",
      "Epoch [4/10], Step [8101/119], Loss: 0.4401\n",
      "Epoch [4/10], Step [8201/119], Loss: 0.4345\n",
      "Epoch [4/10], Step [8301/119], Loss: 0.4342\n",
      "Epoch [4/10], Step [8401/119], Loss: 0.4326\n",
      "Epoch [4/10], Step [8501/119], Loss: 0.4282\n",
      "Epoch [4/10], Step [8601/119], Loss: 0.4299\n",
      "Epoch [4/10], Step [8701/119], Loss: 0.4262\n",
      "Epoch [4/10], Step [8801/119], Loss: 0.4298\n",
      "Epoch [4/10], Step [8901/119], Loss: 0.4218\n",
      "Epoch [4/10], Step [9001/119], Loss: 0.4154\n",
      "Epoch [4/10], Step [9101/119], Loss: 0.4182\n",
      "Epoch [4/10], Step [9201/119], Loss: 0.4103\n",
      "Epoch [4/10], Step [9301/119], Loss: 0.4070\n",
      "Epoch [4/10], Step [9401/119], Loss: 0.4144\n",
      "Epoch [4/10], Step [9501/119], Loss: 0.4054\n",
      "Epoch [4/10], Step [9601/119], Loss: 0.4070\n",
      "Epoch [4/10], Step [9701/119], Loss: 0.4048\n",
      "Epoch [4/10], Step [9801/119], Loss: 0.4062\n",
      "Epoch [4/10], Step [9901/119], Loss: 0.3941\n",
      "Epoch [4/10], Step [10001/119], Loss: 0.3996\n",
      "Epoch [4/10], Step [10101/119], Loss: 0.3926\n",
      "Epoch [4/10], Step [10201/119], Loss: 0.3925\n",
      "Epoch [4/10], Step [10301/119], Loss: 0.3859\n",
      "Epoch [4/10], Step [10401/119], Loss: 0.3839\n",
      "Epoch [4/10], Step [10501/119], Loss: 0.3764\n",
      "Epoch [4/10], Step [10601/119], Loss: 0.3795\n",
      "Epoch [4/10], Step [10701/119], Loss: 0.3810\n",
      "Epoch [4/10], Step [10801/119], Loss: 0.3710\n",
      "Epoch [4/10], Step [10901/119], Loss: 0.3751\n",
      "Epoch [4/10], Step [11001/119], Loss: 0.3689\n",
      "Epoch [4/10], Step [11101/119], Loss: 0.3616\n",
      "Epoch [4/10], Step [11201/119], Loss: 0.3632\n",
      "Epoch [4/10], Step [11301/119], Loss: 0.3487\n",
      "Epoch [4/10], Step [11401/119], Loss: 0.3500\n",
      "Epoch [4/10], Step [11501/119], Loss: 0.3305\n",
      "Epoch [4/10], Step [11601/119], Loss: 0.3091\n",
      "Epoch [4/10], Step [11701/119], Loss: 0.2966\n",
      "Epoch [4/10], Step [11801/119], Loss: 0.2784\n",
      "Epoch [4/10], Step [11901/119], Loss: 0.2769\n",
      "Epoch [5/10], Step [1/119], Loss: 2.0909\n",
      "Epoch [5/10], Step [101/119], Loss: 2.0355\n",
      "Epoch [5/10], Step [201/119], Loss: 1.7885\n",
      "Epoch [5/10], Step [301/119], Loss: 1.6456\n",
      "Epoch [5/10], Step [401/119], Loss: 1.5053\n",
      "Epoch [5/10], Step [501/119], Loss: 1.4809\n",
      "Epoch [5/10], Step [601/119], Loss: 1.3223\n",
      "Epoch [5/10], Step [701/119], Loss: 1.3159\n",
      "Epoch [5/10], Step [801/119], Loss: 1.1812\n",
      "Epoch [5/10], Step [901/119], Loss: 1.2237\n",
      "Epoch [5/10], Step [1001/119], Loss: 1.2071\n",
      "Epoch [5/10], Step [1101/119], Loss: 1.2048\n",
      "Epoch [5/10], Step [1201/119], Loss: 1.1605\n",
      "Epoch [5/10], Step [1301/119], Loss: 1.1525\n",
      "Epoch [5/10], Step [1401/119], Loss: 1.1334\n",
      "Epoch [5/10], Step [1501/119], Loss: 1.1102\n",
      "Epoch [5/10], Step [1601/119], Loss: 1.0960\n",
      "Epoch [5/10], Step [1701/119], Loss: 1.0919\n",
      "Epoch [5/10], Step [1801/119], Loss: 1.0694\n",
      "Epoch [5/10], Step [1901/119], Loss: 1.0654\n",
      "Epoch [5/10], Step [2001/119], Loss: 1.0477\n",
      "Epoch [5/10], Step [2101/119], Loss: 0.7387\n",
      "Epoch [5/10], Step [2201/119], Loss: 0.4501\n",
      "Epoch [5/10], Step [2301/119], Loss: 0.4540\n",
      "Epoch [5/10], Step [2401/119], Loss: 0.4554\n",
      "Epoch [5/10], Step [2501/119], Loss: 0.4567\n",
      "Epoch [5/10], Step [2601/119], Loss: 0.4600\n",
      "Epoch [5/10], Step [2701/119], Loss: 0.4620\n",
      "Epoch [5/10], Step [2801/119], Loss: 0.4590\n",
      "Epoch [5/10], Step [2901/119], Loss: 0.4597\n",
      "Epoch [5/10], Step [3001/119], Loss: 0.4643\n",
      "Epoch [5/10], Step [3101/119], Loss: 0.4628\n",
      "Epoch [5/10], Step [3201/119], Loss: 0.4661\n",
      "Epoch [5/10], Step [3301/119], Loss: 0.4668\n",
      "Epoch [5/10], Step [3401/119], Loss: 0.4667\n",
      "Epoch [5/10], Step [3501/119], Loss: 0.4676\n",
      "Epoch [5/10], Step [3601/119], Loss: 0.4650\n",
      "Epoch [5/10], Step [3701/119], Loss: 0.4646\n",
      "Epoch [5/10], Step [3801/119], Loss: 0.4630\n",
      "Epoch [5/10], Step [3901/119], Loss: 0.4631\n",
      "Epoch [5/10], Step [4001/119], Loss: 0.4651\n",
      "Epoch [5/10], Step [4101/119], Loss: 0.4610\n",
      "Epoch [5/10], Step [4201/119], Loss: 0.4629\n",
      "Epoch [5/10], Step [4301/119], Loss: 0.4611\n",
      "Epoch [5/10], Step [4401/119], Loss: 0.4581\n",
      "Epoch [5/10], Step [4501/119], Loss: 0.4556\n",
      "Epoch [5/10], Step [4601/119], Loss: 0.4575\n",
      "Epoch [5/10], Step [4701/119], Loss: 0.4577\n",
      "Epoch [5/10], Step [4801/119], Loss: 0.4552\n",
      "Epoch [5/10], Step [4901/119], Loss: 0.4561\n",
      "Epoch [5/10], Step [5001/119], Loss: 0.4536\n",
      "Epoch [5/10], Step [5101/119], Loss: 0.4546\n",
      "Epoch [5/10], Step [5201/119], Loss: 0.4509\n",
      "Epoch [5/10], Step [5301/119], Loss: 0.4488\n",
      "Epoch [5/10], Step [5401/119], Loss: 0.4470\n",
      "Epoch [5/10], Step [5501/119], Loss: 0.4484\n",
      "Epoch [5/10], Step [5601/119], Loss: 0.4480\n",
      "Epoch [5/10], Step [5701/119], Loss: 0.4422\n",
      "Epoch [5/10], Step [5801/119], Loss: 0.4416\n",
      "Epoch [5/10], Step [5901/119], Loss: 0.4352\n",
      "Epoch [5/10], Step [6001/119], Loss: 0.4396\n",
      "Epoch [5/10], Step [6101/119], Loss: 0.4364\n",
      "Epoch [5/10], Step [6201/119], Loss: 0.4338\n",
      "Epoch [5/10], Step [6301/119], Loss: 0.4300\n",
      "Epoch [5/10], Step [6401/119], Loss: 0.4246\n",
      "Epoch [5/10], Step [6501/119], Loss: 0.4208\n",
      "Epoch [5/10], Step [6601/119], Loss: 0.4130\n",
      "Epoch [5/10], Step [6701/119], Loss: 0.3953\n",
      "Epoch [5/10], Step [6801/119], Loss: 0.3846\n",
      "Epoch [5/10], Step [6901/119], Loss: 0.3740\n",
      "Epoch [5/10], Step [7001/119], Loss: 0.3664\n",
      "Epoch [5/10], Step [7101/119], Loss: 0.3312\n",
      "Epoch [5/10], Step [7201/119], Loss: 0.3263\n",
      "Epoch [5/10], Step [7301/119], Loss: 0.3209\n",
      "Epoch [5/10], Step [7401/119], Loss: 0.2925\n",
      "Epoch [5/10], Step [7501/119], Loss: 0.2837\n",
      "Epoch [5/10], Step [7601/119], Loss: 0.2718\n",
      "Epoch [5/10], Step [7701/119], Loss: 0.2484\n",
      "Epoch [5/10], Step [7801/119], Loss: 0.2206\n",
      "Epoch [5/10], Step [7901/119], Loss: 0.2050\n",
      "Epoch [5/10], Step [8001/119], Loss: 0.1984\n",
      "Epoch [5/10], Step [8101/119], Loss: 0.1861\n",
      "Epoch [5/10], Step [8201/119], Loss: 0.1546\n",
      "Epoch [5/10], Step [8301/119], Loss: 0.1659\n",
      "Epoch [5/10], Step [8401/119], Loss: 0.1548\n",
      "Epoch [5/10], Step [8501/119], Loss: 0.1210\n",
      "Epoch [5/10], Step [8601/119], Loss: 0.1271\n",
      "Epoch [5/10], Step [8701/119], Loss: 0.1157\n",
      "Epoch [5/10], Step [8801/119], Loss: 0.1201\n",
      "Epoch [5/10], Step [8901/119], Loss: 0.0899\n",
      "Epoch [5/10], Step [9001/119], Loss: 0.0758\n",
      "Epoch [5/10], Step [9101/119], Loss: 0.0900\n",
      "Epoch [5/10], Step [9201/119], Loss: 0.0562\n",
      "Epoch [5/10], Step [9301/119], Loss: 0.0637\n",
      "Epoch [5/10], Step [9401/119], Loss: 0.0749\n",
      "Epoch [5/10], Step [9501/119], Loss: 0.0531\n",
      "Epoch [5/10], Step [9601/119], Loss: 0.0517\n",
      "Epoch [5/10], Step [9701/119], Loss: 0.0469\n",
      "Epoch [5/10], Step [9801/119], Loss: 0.0564\n",
      "Epoch [5/10], Step [9901/119], Loss: 0.0357\n",
      "Epoch [5/10], Step [10001/119], Loss: 0.0441\n",
      "Epoch [5/10], Step [10101/119], Loss: 0.0412\n",
      "Epoch [5/10], Step [10201/119], Loss: 0.0359\n",
      "Epoch [5/10], Step [10301/119], Loss: 0.0365\n",
      "Epoch [5/10], Step [10401/119], Loss: 0.0334\n",
      "Epoch [5/10], Step [10501/119], Loss: 0.0255\n",
      "Epoch [5/10], Step [10601/119], Loss: 0.0270\n",
      "Epoch [5/10], Step [10701/119], Loss: 0.0218\n",
      "Epoch [5/10], Step [10801/119], Loss: 0.0215\n",
      "Epoch [5/10], Step [10901/119], Loss: 0.0195\n",
      "Epoch [5/10], Step [11001/119], Loss: 0.0171\n",
      "Epoch [5/10], Step [11101/119], Loss: 0.0212\n",
      "Epoch [5/10], Step [11201/119], Loss: 0.0158\n",
      "Epoch [5/10], Step [11301/119], Loss: 0.0134\n",
      "Epoch [5/10], Step [11401/119], Loss: 0.0150\n",
      "Epoch [5/10], Step [11501/119], Loss: 0.0119\n",
      "Epoch [5/10], Step [11601/119], Loss: 0.0096\n",
      "Epoch [5/10], Step [11701/119], Loss: 0.0121\n",
      "Epoch [5/10], Step [11801/119], Loss: 0.0088\n",
      "Epoch [5/10], Step [11901/119], Loss: 0.0086\n",
      "Epoch [6/10], Step [1/119], Loss: 14.4470\n",
      "Epoch [6/10], Step [101/119], Loss: 13.2835\n",
      "Epoch [6/10], Step [201/119], Loss: 10.3056\n",
      "Epoch [6/10], Step [301/119], Loss: 7.7499\n",
      "Epoch [6/10], Step [401/119], Loss: 4.6601\n",
      "Epoch [6/10], Step [501/119], Loss: 2.7041\n",
      "Epoch [6/10], Step [601/119], Loss: 0.9023\n",
      "Epoch [6/10], Step [701/119], Loss: 0.2873\n",
      "Epoch [6/10], Step [801/119], Loss: 0.2393\n",
      "Epoch [6/10], Step [901/119], Loss: 0.1152\n",
      "Epoch [6/10], Step [1001/119], Loss: 0.0925\n",
      "Epoch [6/10], Step [1101/119], Loss: 0.0666\n",
      "Epoch [6/10], Step [1201/119], Loss: 0.0558\n",
      "Epoch [6/10], Step [1301/119], Loss: 0.0327\n",
      "Epoch [6/10], Step [1401/119], Loss: 0.0323\n",
      "Epoch [6/10], Step [1501/119], Loss: 0.0346\n",
      "Epoch [6/10], Step [1601/119], Loss: 0.0298\n",
      "Epoch [6/10], Step [1701/119], Loss: 0.0213\n",
      "Epoch [6/10], Step [1801/119], Loss: 0.0186\n",
      "Epoch [6/10], Step [1901/119], Loss: 0.0133\n",
      "Epoch [6/10], Step [2001/119], Loss: 0.0185\n",
      "Epoch [6/10], Step [2101/119], Loss: 4.5338\n",
      "Epoch [6/10], Step [2201/119], Loss: 7.8585\n",
      "Epoch [6/10], Step [2301/119], Loss: 8.0982\n",
      "Epoch [6/10], Step [2401/119], Loss: 8.1020\n",
      "Epoch [6/10], Step [2501/119], Loss: 7.2862\n",
      "Epoch [6/10], Step [2601/119], Loss: 6.4743\n",
      "Epoch [6/10], Step [2701/119], Loss: 5.9547\n",
      "Epoch [6/10], Step [2801/119], Loss: 5.2877\n",
      "Epoch [6/10], Step [2901/119], Loss: 4.6040\n",
      "Epoch [6/10], Step [3001/119], Loss: 3.5226\n",
      "Epoch [6/10], Step [3101/119], Loss: 3.5496\n",
      "Epoch [6/10], Step [3201/119], Loss: 2.8464\n",
      "Epoch [6/10], Step [3301/119], Loss: 2.0115\n",
      "Epoch [6/10], Step [3401/119], Loss: 1.7960\n",
      "Epoch [6/10], Step [3501/119], Loss: 1.6418\n",
      "Epoch [6/10], Step [3601/119], Loss: 1.4198\n",
      "Epoch [6/10], Step [3701/119], Loss: 1.1317\n",
      "Epoch [6/10], Step [3801/119], Loss: 1.0020\n",
      "Epoch [6/10], Step [3901/119], Loss: 0.9080\n",
      "Epoch [6/10], Step [4001/119], Loss: 0.8167\n",
      "Epoch [6/10], Step [4101/119], Loss: 0.7113\n",
      "Epoch [6/10], Step [4201/119], Loss: 0.6542\n",
      "Epoch [6/10], Step [4301/119], Loss: 0.6122\n",
      "Epoch [6/10], Step [4401/119], Loss: 0.6023\n",
      "Epoch [6/10], Step [4501/119], Loss: 0.5617\n",
      "Epoch [6/10], Step [4601/119], Loss: 0.5219\n",
      "Epoch [6/10], Step [4701/119], Loss: 0.4992\n",
      "Epoch [6/10], Step [4801/119], Loss: 0.4906\n",
      "Epoch [6/10], Step [4901/119], Loss: 0.4715\n",
      "Epoch [6/10], Step [5001/119], Loss: 0.4725\n",
      "Epoch [6/10], Step [5101/119], Loss: 0.4656\n",
      "Epoch [6/10], Step [5201/119], Loss: 0.4587\n",
      "Epoch [6/10], Step [5301/119], Loss: 0.4511\n",
      "Epoch [6/10], Step [5401/119], Loss: 0.4517\n",
      "Epoch [6/10], Step [5501/119], Loss: 0.4488\n",
      "Epoch [6/10], Step [5601/119], Loss: 0.4419\n",
      "Epoch [6/10], Step [5701/119], Loss: 0.4383\n",
      "Epoch [6/10], Step [5801/119], Loss: 0.4357\n",
      "Epoch [6/10], Step [5901/119], Loss: 0.4352\n",
      "Epoch [6/10], Step [6001/119], Loss: 0.4347\n",
      "Epoch [6/10], Step [6101/119], Loss: 0.4308\n",
      "Epoch [6/10], Step [6201/119], Loss: 0.4294\n",
      "Epoch [6/10], Step [6301/119], Loss: 0.4267\n",
      "Epoch [6/10], Step [6401/119], Loss: 0.4245\n",
      "Epoch [6/10], Step [6501/119], Loss: 0.4241\n",
      "Epoch [6/10], Step [6601/119], Loss: 0.4244\n",
      "Epoch [6/10], Step [6701/119], Loss: 0.4238\n",
      "Epoch [6/10], Step [6801/119], Loss: 0.4160\n",
      "Epoch [6/10], Step [6901/119], Loss: 0.4172\n",
      "Epoch [6/10], Step [7001/119], Loss: 0.4170\n",
      "Epoch [6/10], Step [7101/119], Loss: 0.4090\n",
      "Epoch [6/10], Step [7201/119], Loss: 0.4106\n",
      "Epoch [6/10], Step [7301/119], Loss: 0.4134\n",
      "Epoch [6/10], Step [7401/119], Loss: 0.4079\n",
      "Epoch [6/10], Step [7501/119], Loss: 0.4099\n",
      "Epoch [6/10], Step [7601/119], Loss: 0.4088\n",
      "Epoch [6/10], Step [7701/119], Loss: 0.4042\n",
      "Epoch [6/10], Step [7801/119], Loss: 0.4037\n",
      "Epoch [6/10], Step [7901/119], Loss: 0.4022\n",
      "Epoch [6/10], Step [8001/119], Loss: 0.4027\n",
      "Epoch [6/10], Step [8101/119], Loss: 0.3990\n",
      "Epoch [6/10], Step [8201/119], Loss: 0.3968\n",
      "Epoch [6/10], Step [8301/119], Loss: 0.3945\n",
      "Epoch [6/10], Step [8401/119], Loss: 0.3968\n",
      "Epoch [6/10], Step [8501/119], Loss: 0.3879\n",
      "Epoch [6/10], Step [8601/119], Loss: 0.3907\n",
      "Epoch [6/10], Step [8701/119], Loss: 0.3905\n",
      "Epoch [6/10], Step [8801/119], Loss: 0.3893\n",
      "Epoch [6/10], Step [8901/119], Loss: 0.3853\n",
      "Epoch [6/10], Step [9001/119], Loss: 0.3832\n",
      "Epoch [6/10], Step [9101/119], Loss: 0.3821\n",
      "Epoch [6/10], Step [9201/119], Loss: 0.3819\n",
      "Epoch [6/10], Step [9301/119], Loss: 0.3771\n",
      "Epoch [6/10], Step [9401/119], Loss: 0.3790\n",
      "Epoch [6/10], Step [9501/119], Loss: 0.3724\n",
      "Epoch [6/10], Step [9601/119], Loss: 0.3718\n",
      "Epoch [6/10], Step [9701/119], Loss: 0.3740\n",
      "Epoch [6/10], Step [9801/119], Loss: 0.3726\n",
      "Epoch [6/10], Step [9901/119], Loss: 0.3673\n",
      "Epoch [6/10], Step [10001/119], Loss: 0.3670\n",
      "Epoch [6/10], Step [10101/119], Loss: 0.3614\n",
      "Epoch [6/10], Step [10201/119], Loss: 0.3606\n",
      "Epoch [6/10], Step [10301/119], Loss: 0.3611\n",
      "Epoch [6/10], Step [10401/119], Loss: 0.3578\n",
      "Epoch [6/10], Step [10501/119], Loss: 0.3535\n",
      "Epoch [6/10], Step [10601/119], Loss: 0.3563\n",
      "Epoch [6/10], Step [10701/119], Loss: 0.3501\n",
      "Epoch [6/10], Step [10801/119], Loss: 0.3516\n",
      "Epoch [6/10], Step [10901/119], Loss: 0.3541\n",
      "Epoch [6/10], Step [11001/119], Loss: 0.3418\n",
      "Epoch [6/10], Step [11101/119], Loss: 0.3428\n",
      "Epoch [6/10], Step [11201/119], Loss: 0.3473\n",
      "Epoch [6/10], Step [11301/119], Loss: 0.3329\n",
      "Epoch [6/10], Step [11401/119], Loss: 0.3399\n",
      "Epoch [6/10], Step [11501/119], Loss: 0.3339\n",
      "Epoch [6/10], Step [11601/119], Loss: 0.3265\n",
      "Epoch [6/10], Step [11701/119], Loss: 0.3282\n",
      "Epoch [6/10], Step [11801/119], Loss: 0.3305\n",
      "Epoch [6/10], Step [11901/119], Loss: 0.3390\n",
      "Epoch [7/10], Step [1/119], Loss: 1.3876\n",
      "Epoch [7/10], Step [101/119], Loss: 1.3542\n",
      "Epoch [7/10], Step [201/119], Loss: 1.3355\n",
      "Epoch [7/10], Step [301/119], Loss: 1.3213\n",
      "Epoch [7/10], Step [401/119], Loss: 1.3073\n",
      "Epoch [7/10], Step [501/119], Loss: 1.3434\n",
      "Epoch [7/10], Step [601/119], Loss: 1.2752\n",
      "Epoch [7/10], Step [701/119], Loss: 1.3184\n",
      "Epoch [7/10], Step [801/119], Loss: 1.2516\n",
      "Epoch [7/10], Step [901/119], Loss: 1.2679\n",
      "Epoch [7/10], Step [1001/119], Loss: 1.2413\n",
      "Epoch [7/10], Step [1101/119], Loss: 1.2449\n",
      "Epoch [7/10], Step [1201/119], Loss: 1.2346\n",
      "Epoch [7/10], Step [1301/119], Loss: 1.2039\n",
      "Epoch [7/10], Step [1401/119], Loss: 1.1846\n",
      "Epoch [7/10], Step [1501/119], Loss: 1.1870\n",
      "Epoch [7/10], Step [1601/119], Loss: 1.1738\n",
      "Epoch [7/10], Step [1701/119], Loss: 1.1547\n",
      "Epoch [7/10], Step [1801/119], Loss: 1.1418\n",
      "Epoch [7/10], Step [1901/119], Loss: 1.1376\n",
      "Epoch [7/10], Step [2001/119], Loss: 1.1296\n",
      "Epoch [7/10], Step [2101/119], Loss: 0.7580\n",
      "Epoch [7/10], Step [2201/119], Loss: 0.3971\n",
      "Epoch [7/10], Step [2301/119], Loss: 0.4007\n",
      "Epoch [7/10], Step [2401/119], Loss: 0.4031\n",
      "Epoch [7/10], Step [2501/119], Loss: 0.4033\n",
      "Epoch [7/10], Step [2601/119], Loss: 0.4052\n",
      "Epoch [7/10], Step [2701/119], Loss: 0.4074\n",
      "Epoch [7/10], Step [2801/119], Loss: 0.4049\n",
      "Epoch [7/10], Step [2901/119], Loss: 0.4056\n",
      "Epoch [7/10], Step [3001/119], Loss: 0.4093\n",
      "Epoch [7/10], Step [3101/119], Loss: 0.4082\n",
      "Epoch [7/10], Step [3201/119], Loss: 0.4081\n",
      "Epoch [7/10], Step [3301/119], Loss: 0.4085\n",
      "Epoch [7/10], Step [3401/119], Loss: 0.4104\n",
      "Epoch [7/10], Step [3501/119], Loss: 0.4078\n",
      "Epoch [7/10], Step [3601/119], Loss: 0.4065\n",
      "Epoch [7/10], Step [3701/119], Loss: 0.4068\n",
      "Epoch [7/10], Step [3801/119], Loss: 0.4059\n",
      "Epoch [7/10], Step [3901/119], Loss: 0.4070\n",
      "Epoch [7/10], Step [4001/119], Loss: 0.4077\n",
      "Epoch [7/10], Step [4101/119], Loss: 0.4052\n",
      "Epoch [7/10], Step [4201/119], Loss: 0.4066\n",
      "Epoch [7/10], Step [4301/119], Loss: 0.4050\n",
      "Epoch [7/10], Step [4401/119], Loss: 0.4045\n",
      "Epoch [7/10], Step [4501/119], Loss: 0.4016\n",
      "Epoch [7/10], Step [4601/119], Loss: 0.4022\n",
      "Epoch [7/10], Step [4701/119], Loss: 0.3991\n",
      "Epoch [7/10], Step [4801/119], Loss: 0.3961\n",
      "Epoch [7/10], Step [4901/119], Loss: 0.3951\n",
      "Epoch [7/10], Step [5001/119], Loss: 0.3883\n",
      "Epoch [7/10], Step [5101/119], Loss: 0.3769\n",
      "Epoch [7/10], Step [5201/119], Loss: 0.3707\n",
      "Epoch [7/10], Step [5301/119], Loss: 0.3535\n",
      "Epoch [7/10], Step [5401/119], Loss: 0.3290\n",
      "Epoch [7/10], Step [5501/119], Loss: 0.3243\n",
      "Epoch [7/10], Step [5601/119], Loss: 0.3077\n",
      "Epoch [7/10], Step [5701/119], Loss: 0.2630\n",
      "Epoch [7/10], Step [5801/119], Loss: 0.2612\n",
      "Epoch [7/10], Step [5901/119], Loss: 0.2271\n",
      "Epoch [7/10], Step [6001/119], Loss: 0.2258\n",
      "Epoch [7/10], Step [6101/119], Loss: 0.2021\n",
      "Epoch [7/10], Step [6201/119], Loss: 0.1931\n",
      "Epoch [7/10], Step [6301/119], Loss: 0.1874\n",
      "Epoch [7/10], Step [6401/119], Loss: 0.1670\n",
      "Epoch [7/10], Step [6501/119], Loss: 0.1513\n",
      "Epoch [7/10], Step [6601/119], Loss: 0.1465\n",
      "Epoch [7/10], Step [6701/119], Loss: 0.1205\n",
      "Epoch [7/10], Step [6801/119], Loss: 0.1211\n",
      "Epoch [7/10], Step [6901/119], Loss: 0.1108\n",
      "Epoch [7/10], Step [7001/119], Loss: 0.1038\n",
      "Epoch [7/10], Step [7101/119], Loss: 0.0900\n",
      "Epoch [7/10], Step [7201/119], Loss: 0.0860\n",
      "Epoch [7/10], Step [7301/119], Loss: 0.0876\n",
      "Epoch [7/10], Step [7401/119], Loss: 0.0776\n",
      "Epoch [7/10], Step [7501/119], Loss: 0.0715\n",
      "Epoch [7/10], Step [7601/119], Loss: 0.0766\n",
      "Epoch [7/10], Step [7701/119], Loss: 0.0617\n",
      "Epoch [7/10], Step [7801/119], Loss: 0.0548\n",
      "Epoch [7/10], Step [7901/119], Loss: 0.0498\n",
      "Epoch [7/10], Step [8001/119], Loss: 0.0501\n",
      "Epoch [7/10], Step [8101/119], Loss: 0.0443\n",
      "Epoch [7/10], Step [8201/119], Loss: 0.0371\n",
      "Epoch [7/10], Step [8301/119], Loss: 0.0481\n",
      "Epoch [7/10], Step [8401/119], Loss: 0.0415\n",
      "Epoch [7/10], Step [8501/119], Loss: 0.0297\n",
      "Epoch [7/10], Step [8601/119], Loss: 0.0335\n",
      "Epoch [7/10], Step [8701/119], Loss: 0.0274\n",
      "Epoch [7/10], Step [8801/119], Loss: 0.0349\n",
      "Epoch [7/10], Step [8901/119], Loss: 0.0263\n",
      "Epoch [7/10], Step [9001/119], Loss: 0.0213\n",
      "Epoch [7/10], Step [9101/119], Loss: 0.0254\n",
      "Epoch [7/10], Step [9201/119], Loss: 0.0174\n",
      "Epoch [7/10], Step [9301/119], Loss: 0.0198\n",
      "Epoch [7/10], Step [9401/119], Loss: 0.0259\n",
      "Epoch [7/10], Step [9501/119], Loss: 0.0155\n",
      "Epoch [7/10], Step [9601/119], Loss: 0.0191\n",
      "Epoch [7/10], Step [9701/119], Loss: 0.0178\n",
      "Epoch [7/10], Step [9801/119], Loss: 0.0228\n",
      "Epoch [7/10], Step [9901/119], Loss: 0.0132\n",
      "Epoch [7/10], Step [10001/119], Loss: 0.0178\n",
      "Epoch [7/10], Step [10101/119], Loss: 0.0194\n",
      "Epoch [7/10], Step [10201/119], Loss: 0.0149\n",
      "Epoch [7/10], Step [10301/119], Loss: 0.0167\n",
      "Epoch [7/10], Step [10401/119], Loss: 0.0177\n",
      "Epoch [7/10], Step [10501/119], Loss: 0.0134\n",
      "Epoch [7/10], Step [10601/119], Loss: 0.0153\n",
      "Epoch [7/10], Step [10701/119], Loss: 0.0118\n",
      "Epoch [7/10], Step [10801/119], Loss: 0.0122\n",
      "Epoch [7/10], Step [10901/119], Loss: 0.0136\n",
      "Epoch [7/10], Step [11001/119], Loss: 0.0110\n",
      "Epoch [7/10], Step [11101/119], Loss: 0.0149\n",
      "Epoch [7/10], Step [11201/119], Loss: 0.0101\n",
      "Epoch [7/10], Step [11301/119], Loss: 0.0076\n",
      "Epoch [7/10], Step [11401/119], Loss: 0.0109\n",
      "Epoch [7/10], Step [11501/119], Loss: 0.0090\n",
      "Epoch [7/10], Step [11601/119], Loss: 0.0088\n",
      "Epoch [7/10], Step [11701/119], Loss: 0.0093\n",
      "Epoch [7/10], Step [11801/119], Loss: 0.0082\n",
      "Epoch [7/10], Step [11901/119], Loss: 0.0072\n",
      "Epoch [8/10], Step [1/119], Loss: 16.3343\n",
      "Epoch [8/10], Step [101/119], Loss: 13.9095\n",
      "Epoch [8/10], Step [201/119], Loss: 11.2532\n",
      "Epoch [8/10], Step [301/119], Loss: 8.0921\n",
      "Epoch [8/10], Step [401/119], Loss: 4.8316\n",
      "Epoch [8/10], Step [501/119], Loss: 2.5666\n",
      "Epoch [8/10], Step [601/119], Loss: 0.6311\n",
      "Epoch [8/10], Step [701/119], Loss: 0.2226\n",
      "Epoch [8/10], Step [801/119], Loss: 0.2010\n",
      "Epoch [8/10], Step [901/119], Loss: 0.0875\n",
      "Epoch [8/10], Step [1001/119], Loss: 0.0758\n",
      "Epoch [8/10], Step [1101/119], Loss: 0.0470\n",
      "Epoch [8/10], Step [1201/119], Loss: 0.0348\n",
      "Epoch [8/10], Step [1301/119], Loss: 0.0228\n",
      "Epoch [8/10], Step [1401/119], Loss: 0.0227\n",
      "Epoch [8/10], Step [1501/119], Loss: 0.0241\n",
      "Epoch [8/10], Step [1601/119], Loss: 0.0172\n",
      "Epoch [8/10], Step [1701/119], Loss: 0.0113\n",
      "Epoch [8/10], Step [1801/119], Loss: 0.0129\n",
      "Epoch [8/10], Step [1901/119], Loss: 0.0073\n",
      "Epoch [8/10], Step [2001/119], Loss: 0.0116\n",
      "Epoch [8/10], Step [2101/119], Loss: 5.9222\n",
      "Epoch [8/10], Step [2201/119], Loss: 10.5431\n",
      "Epoch [8/10], Step [2301/119], Loss: 10.9251\n",
      "Epoch [8/10], Step [2401/119], Loss: 10.4939\n",
      "Epoch [8/10], Step [2501/119], Loss: 9.8789\n",
      "Epoch [8/10], Step [2601/119], Loss: 9.6398\n",
      "Epoch [8/10], Step [2701/119], Loss: 8.6022\n",
      "Epoch [8/10], Step [2801/119], Loss: 8.2923\n",
      "Epoch [8/10], Step [2901/119], Loss: 6.7621\n",
      "Epoch [8/10], Step [3001/119], Loss: 5.2599\n",
      "Epoch [8/10], Step [3101/119], Loss: 5.4658\n",
      "Epoch [8/10], Step [3201/119], Loss: 4.2557\n",
      "Epoch [8/10], Step [3301/119], Loss: 2.8599\n",
      "Epoch [8/10], Step [3401/119], Loss: 2.8145\n",
      "Epoch [8/10], Step [3501/119], Loss: 2.4621\n",
      "Epoch [8/10], Step [3601/119], Loss: 1.8757\n",
      "Epoch [8/10], Step [3701/119], Loss: 1.4573\n",
      "Epoch [8/10], Step [3801/119], Loss: 1.2185\n",
      "Epoch [8/10], Step [3901/119], Loss: 1.1378\n",
      "Epoch [8/10], Step [4001/119], Loss: 0.9662\n",
      "Epoch [8/10], Step [4101/119], Loss: 0.7823\n",
      "Epoch [8/10], Step [4201/119], Loss: 0.6708\n",
      "Epoch [8/10], Step [4301/119], Loss: 0.6004\n",
      "Epoch [8/10], Step [4401/119], Loss: 0.5840\n",
      "Epoch [8/10], Step [4501/119], Loss: 0.4858\n",
      "Epoch [8/10], Step [4601/119], Loss: 0.4341\n",
      "Epoch [8/10], Step [4701/119], Loss: 0.4178\n",
      "Epoch [8/10], Step [4801/119], Loss: 0.3955\n",
      "Epoch [8/10], Step [4901/119], Loss: 0.3831\n",
      "Epoch [8/10], Step [5001/119], Loss: 0.3742\n",
      "Epoch [8/10], Step [5101/119], Loss: 0.3622\n",
      "Epoch [8/10], Step [5201/119], Loss: 0.3587\n",
      "Epoch [8/10], Step [5301/119], Loss: 0.3498\n",
      "Epoch [8/10], Step [5401/119], Loss: 0.3396\n",
      "Epoch [8/10], Step [5501/119], Loss: 0.3405\n",
      "Epoch [8/10], Step [5601/119], Loss: 0.3384\n",
      "Epoch [8/10], Step [5701/119], Loss: 0.3293\n",
      "Epoch [8/10], Step [5801/119], Loss: 0.3201\n",
      "Epoch [8/10], Step [5901/119], Loss: 0.3171\n",
      "Epoch [8/10], Step [6001/119], Loss: 0.3274\n",
      "Epoch [8/10], Step [6101/119], Loss: 0.3202\n",
      "Epoch [8/10], Step [6201/119], Loss: 0.3201\n",
      "Epoch [8/10], Step [6301/119], Loss: 0.3155\n",
      "Epoch [8/10], Step [6401/119], Loss: 0.3152\n",
      "Epoch [8/10], Step [6501/119], Loss: 0.3181\n",
      "Epoch [8/10], Step [6601/119], Loss: 0.3126\n",
      "Epoch [8/10], Step [6701/119], Loss: 0.3086\n",
      "Epoch [8/10], Step [6801/119], Loss: 0.3048\n",
      "Epoch [8/10], Step [6901/119], Loss: 0.3030\n",
      "Epoch [8/10], Step [7001/119], Loss: 0.3095\n",
      "Epoch [8/10], Step [7101/119], Loss: 0.2926\n",
      "Epoch [8/10], Step [7201/119], Loss: 0.2979\n",
      "Epoch [8/10], Step [7301/119], Loss: 0.2990\n",
      "Epoch [8/10], Step [7401/119], Loss: 0.2942\n",
      "Epoch [8/10], Step [7501/119], Loss: 0.2991\n",
      "Epoch [8/10], Step [7601/119], Loss: 0.2951\n",
      "Epoch [8/10], Step [7701/119], Loss: 0.2851\n",
      "Epoch [8/10], Step [7801/119], Loss: 0.2857\n",
      "Epoch [8/10], Step [7901/119], Loss: 0.2844\n",
      "Epoch [8/10], Step [8001/119], Loss: 0.2912\n",
      "Epoch [8/10], Step [8101/119], Loss: 0.2825\n",
      "Epoch [8/10], Step [8201/119], Loss: 0.2723\n",
      "Epoch [8/10], Step [8301/119], Loss: 0.2761\n",
      "Epoch [8/10], Step [8401/119], Loss: 0.2768\n",
      "Epoch [8/10], Step [8501/119], Loss: 0.2670\n",
      "Epoch [8/10], Step [8601/119], Loss: 0.2681\n",
      "Epoch [8/10], Step [8701/119], Loss: 0.2607\n",
      "Epoch [8/10], Step [8801/119], Loss: 0.2632\n",
      "Epoch [8/10], Step [8901/119], Loss: 0.2581\n",
      "Epoch [8/10], Step [9001/119], Loss: 0.2544\n",
      "Epoch [8/10], Step [9101/119], Loss: 0.2624\n",
      "Epoch [8/10], Step [9201/119], Loss: 0.2570\n",
      "Epoch [8/10], Step [9301/119], Loss: 0.2431\n",
      "Epoch [8/10], Step [9401/119], Loss: 0.2533\n",
      "Epoch [8/10], Step [9501/119], Loss: 0.2401\n",
      "Epoch [8/10], Step [9601/119], Loss: 0.2374\n",
      "Epoch [8/10], Step [9701/119], Loss: 0.2455\n",
      "Epoch [8/10], Step [9801/119], Loss: 0.2465\n",
      "Epoch [8/10], Step [9901/119], Loss: 0.2405\n",
      "Epoch [8/10], Step [10001/119], Loss: 0.2407\n",
      "Epoch [8/10], Step [10101/119], Loss: 0.2289\n",
      "Epoch [8/10], Step [10201/119], Loss: 0.2322\n",
      "Epoch [8/10], Step [10301/119], Loss: 0.2323\n",
      "Epoch [8/10], Step [10401/119], Loss: 0.2324\n",
      "Epoch [8/10], Step [10501/119], Loss: 0.2227\n",
      "Epoch [8/10], Step [10601/119], Loss: 0.2252\n",
      "Epoch [8/10], Step [10701/119], Loss: 0.2216\n",
      "Epoch [8/10], Step [10801/119], Loss: 0.2207\n",
      "Epoch [8/10], Step [10901/119], Loss: 0.2188\n",
      "Epoch [8/10], Step [11001/119], Loss: 0.2147\n",
      "Epoch [8/10], Step [11101/119], Loss: 0.2083\n",
      "Epoch [8/10], Step [11201/119], Loss: 0.2128\n",
      "Epoch [8/10], Step [11301/119], Loss: 0.1999\n",
      "Epoch [8/10], Step [11401/119], Loss: 0.2038\n",
      "Epoch [8/10], Step [11501/119], Loss: 0.1990\n",
      "Epoch [8/10], Step [11601/119], Loss: 0.1891\n",
      "Epoch [8/10], Step [11701/119], Loss: 0.1906\n",
      "Epoch [8/10], Step [11801/119], Loss: 0.1967\n",
      "Epoch [8/10], Step [11901/119], Loss: 0.2107\n",
      "Epoch [9/10], Step [1/119], Loss: 2.0663\n",
      "Epoch [9/10], Step [101/119], Loss: 2.0691\n",
      "Epoch [9/10], Step [201/119], Loss: 1.9651\n",
      "Epoch [9/10], Step [301/119], Loss: 1.8793\n",
      "Epoch [9/10], Step [401/119], Loss: 1.8025\n",
      "Epoch [9/10], Step [501/119], Loss: 1.9284\n",
      "Epoch [9/10], Step [601/119], Loss: 1.7159\n",
      "Epoch [9/10], Step [701/119], Loss: 1.8001\n",
      "Epoch [9/10], Step [801/119], Loss: 1.6194\n",
      "Epoch [9/10], Step [901/119], Loss: 1.6407\n",
      "Epoch [9/10], Step [1001/119], Loss: 1.5378\n",
      "Epoch [9/10], Step [1101/119], Loss: 1.5055\n",
      "Epoch [9/10], Step [1201/119], Loss: 1.4929\n",
      "Epoch [9/10], Step [1301/119], Loss: 1.3936\n",
      "Epoch [9/10], Step [1401/119], Loss: 1.3787\n",
      "Epoch [9/10], Step [1501/119], Loss: 1.3711\n",
      "Epoch [9/10], Step [1601/119], Loss: 1.3375\n",
      "Epoch [9/10], Step [1701/119], Loss: 1.3041\n",
      "Epoch [9/10], Step [1801/119], Loss: 1.2746\n",
      "Epoch [9/10], Step [1901/119], Loss: 1.2628\n",
      "Epoch [9/10], Step [2001/119], Loss: 1.2497\n",
      "Epoch [9/10], Step [2101/119], Loss: 0.7815\n",
      "Epoch [9/10], Step [2201/119], Loss: 0.3364\n",
      "Epoch [9/10], Step [2301/119], Loss: 0.3454\n",
      "Epoch [9/10], Step [2401/119], Loss: 0.3431\n",
      "Epoch [9/10], Step [2501/119], Loss: 0.3454\n",
      "Epoch [9/10], Step [2601/119], Loss: 0.3535\n",
      "Epoch [9/10], Step [2701/119], Loss: 0.3556\n",
      "Epoch [9/10], Step [2801/119], Loss: 0.3568\n",
      "Epoch [9/10], Step [2901/119], Loss: 0.3561\n",
      "Epoch [9/10], Step [3001/119], Loss: 0.3563\n",
      "Epoch [9/10], Step [3101/119], Loss: 0.3583\n",
      "Epoch [9/10], Step [3201/119], Loss: 0.3568\n",
      "Epoch [9/10], Step [3301/119], Loss: 0.3589\n",
      "Epoch [9/10], Step [3401/119], Loss: 0.3616\n",
      "Epoch [9/10], Step [3501/119], Loss: 0.3587\n",
      "Epoch [9/10], Step [3601/119], Loss: 0.3558\n",
      "Epoch [9/10], Step [3701/119], Loss: 0.3569\n",
      "Epoch [9/10], Step [3801/119], Loss: 0.3582\n",
      "Epoch [9/10], Step [3901/119], Loss: 0.3580\n",
      "Epoch [9/10], Step [4001/119], Loss: 0.3584\n",
      "Epoch [9/10], Step [4101/119], Loss: 0.3544\n",
      "Epoch [9/10], Step [4201/119], Loss: 0.3546\n",
      "Epoch [9/10], Step [4301/119], Loss: 0.3553\n",
      "Epoch [9/10], Step [4401/119], Loss: 0.3480\n",
      "Epoch [9/10], Step [4501/119], Loss: 0.3377\n",
      "Epoch [9/10], Step [4601/119], Loss: 0.3386\n",
      "Epoch [9/10], Step [4701/119], Loss: 0.3235\n",
      "Epoch [9/10], Step [4801/119], Loss: 0.3021\n",
      "Epoch [9/10], Step [4901/119], Loss: 0.3005\n",
      "Epoch [9/10], Step [5001/119], Loss: 0.2867\n",
      "Epoch [9/10], Step [5101/119], Loss: 0.2764\n",
      "Epoch [9/10], Step [5201/119], Loss: 0.2639\n",
      "Epoch [9/10], Step [5301/119], Loss: 0.2489\n",
      "Epoch [9/10], Step [5401/119], Loss: 0.2120\n",
      "Epoch [9/10], Step [5501/119], Loss: 0.2139\n",
      "Epoch [9/10], Step [5601/119], Loss: 0.1952\n",
      "Epoch [9/10], Step [5701/119], Loss: 0.1584\n",
      "Epoch [9/10], Step [5801/119], Loss: 0.1630\n",
      "Epoch [9/10], Step [5901/119], Loss: 0.1360\n",
      "Epoch [9/10], Step [6001/119], Loss: 0.1339\n",
      "Epoch [9/10], Step [6101/119], Loss: 0.1120\n",
      "Epoch [9/10], Step [6201/119], Loss: 0.1104\n",
      "Epoch [9/10], Step [6301/119], Loss: 0.1070\n",
      "Epoch [9/10], Step [6401/119], Loss: 0.0992\n",
      "Epoch [9/10], Step [6501/119], Loss: 0.0810\n",
      "Epoch [9/10], Step [6601/119], Loss: 0.0830\n",
      "Epoch [9/10], Step [6701/119], Loss: 0.0604\n",
      "Epoch [9/10], Step [6801/119], Loss: 0.0654\n",
      "Epoch [9/10], Step [6901/119], Loss: 0.0585\n",
      "Epoch [9/10], Step [7001/119], Loss: 0.0570\n",
      "Epoch [9/10], Step [7101/119], Loss: 0.0478\n",
      "Epoch [9/10], Step [7201/119], Loss: 0.0480\n",
      "Epoch [9/10], Step [7301/119], Loss: 0.0457\n",
      "Epoch [9/10], Step [7401/119], Loss: 0.0429\n",
      "Epoch [9/10], Step [7501/119], Loss: 0.0424\n",
      "Epoch [9/10], Step [7601/119], Loss: 0.0395\n",
      "Epoch [9/10], Step [7701/119], Loss: 0.0317\n",
      "Epoch [9/10], Step [7801/119], Loss: 0.0303\n",
      "Epoch [9/10], Step [7901/119], Loss: 0.0245\n",
      "Epoch [9/10], Step [8001/119], Loss: 0.0243\n",
      "Epoch [9/10], Step [8101/119], Loss: 0.0265\n",
      "Epoch [9/10], Step [8201/119], Loss: 0.0176\n",
      "Epoch [9/10], Step [8301/119], Loss: 0.0229\n",
      "Epoch [9/10], Step [8401/119], Loss: 0.0209\n",
      "Epoch [9/10], Step [8501/119], Loss: 0.0160\n",
      "Epoch [9/10], Step [8601/119], Loss: 0.0185\n",
      "Epoch [9/10], Step [8701/119], Loss: 0.0115\n",
      "Epoch [9/10], Step [8801/119], Loss: 0.0177\n",
      "Epoch [9/10], Step [8901/119], Loss: 0.0119\n",
      "Epoch [9/10], Step [9001/119], Loss: 0.0085\n",
      "Epoch [9/10], Step [9101/119], Loss: 0.0126\n",
      "Epoch [9/10], Step [9201/119], Loss: 0.0074\n",
      "Epoch [9/10], Step [9301/119], Loss: 0.0110\n",
      "Epoch [9/10], Step [9401/119], Loss: 0.0129\n",
      "Epoch [9/10], Step [9501/119], Loss: 0.0067\n",
      "Epoch [9/10], Step [9601/119], Loss: 0.0093\n",
      "Epoch [9/10], Step [9701/119], Loss: 0.0077\n",
      "Epoch [9/10], Step [9801/119], Loss: 0.0105\n",
      "Epoch [9/10], Step [9901/119], Loss: 0.0059\n",
      "Epoch [9/10], Step [10001/119], Loss: 0.0088\n",
      "Epoch [9/10], Step [10101/119], Loss: 0.0090\n",
      "Epoch [9/10], Step [10201/119], Loss: 0.0071\n",
      "Epoch [9/10], Step [10301/119], Loss: 0.0080\n",
      "Epoch [9/10], Step [10401/119], Loss: 0.0081\n",
      "Epoch [9/10], Step [10501/119], Loss: 0.0067\n",
      "Epoch [9/10], Step [10601/119], Loss: 0.0063\n",
      "Epoch [9/10], Step [10701/119], Loss: 0.0056\n",
      "Epoch [9/10], Step [10801/119], Loss: 0.0050\n",
      "Epoch [9/10], Step [10901/119], Loss: 0.0056\n",
      "Epoch [9/10], Step [11001/119], Loss: 0.0045\n",
      "Epoch [9/10], Step [11101/119], Loss: 0.0074\n",
      "Epoch [9/10], Step [11201/119], Loss: 0.0049\n",
      "Epoch [9/10], Step [11301/119], Loss: 0.0035\n",
      "Epoch [9/10], Step [11401/119], Loss: 0.0054\n",
      "Epoch [9/10], Step [11501/119], Loss: 0.0043\n",
      "Epoch [9/10], Step [11601/119], Loss: 0.0039\n",
      "Epoch [9/10], Step [11701/119], Loss: 0.0043\n",
      "Epoch [9/10], Step [11801/119], Loss: 0.0037\n",
      "Epoch [9/10], Step [11901/119], Loss: 0.0036\n",
      "Epoch [10/10], Step [1/119], Loss: 20.7221\n",
      "Epoch [10/10], Step [101/119], Loss: 16.5052\n",
      "Epoch [10/10], Step [201/119], Loss: 11.4100\n",
      "Epoch [10/10], Step [301/119], Loss: 6.2089\n",
      "Epoch [10/10], Step [401/119], Loss: 1.9775\n",
      "Epoch [10/10], Step [501/119], Loss: 0.2523\n",
      "Epoch [10/10], Step [601/119], Loss: 0.1245\n",
      "Epoch [10/10], Step [701/119], Loss: 0.0499\n",
      "Epoch [10/10], Step [801/119], Loss: 0.0583\n",
      "Epoch [10/10], Step [901/119], Loss: 0.0159\n",
      "Epoch [10/10], Step [1001/119], Loss: 0.0218\n",
      "Epoch [10/10], Step [1101/119], Loss: 0.0083\n",
      "Epoch [10/10], Step [1201/119], Loss: 0.0051\n",
      "Epoch [10/10], Step [1301/119], Loss: 0.0029\n",
      "Epoch [10/10], Step [1401/119], Loss: 0.0039\n",
      "Epoch [10/10], Step [1501/119], Loss: 0.0029\n",
      "Epoch [10/10], Step [1601/119], Loss: 0.0021\n",
      "Epoch [10/10], Step [1701/119], Loss: 0.0017\n",
      "Epoch [10/10], Step [1801/119], Loss: 0.0019\n",
      "Epoch [10/10], Step [1901/119], Loss: 0.0007\n",
      "Epoch [10/10], Step [2001/119], Loss: 0.0012\n",
      "Epoch [10/10], Step [2101/119], Loss: 10.0573\n",
      "Epoch [10/10], Step [2201/119], Loss: 17.2034\n",
      "Epoch [10/10], Step [2301/119], Loss: 17.2029\n",
      "Epoch [10/10], Step [2401/119], Loss: 17.1484\n",
      "Epoch [10/10], Step [2501/119], Loss: 15.0793\n",
      "Epoch [10/10], Step [2601/119], Loss: 14.2652\n",
      "Epoch [10/10], Step [2701/119], Loss: 13.0922\n",
      "Epoch [10/10], Step [2801/119], Loss: 11.5261\n",
      "Epoch [10/10], Step [2901/119], Loss: 9.2136\n",
      "Epoch [10/10], Step [3001/119], Loss: 6.9041\n",
      "Epoch [10/10], Step [3101/119], Loss: 6.8913\n",
      "Epoch [10/10], Step [3201/119], Loss: 4.9729\n",
      "Epoch [10/10], Step [3301/119], Loss: 3.2690\n",
      "Epoch [10/10], Step [3401/119], Loss: 2.8146\n",
      "Epoch [10/10], Step [3501/119], Loss: 2.3985\n",
      "Epoch [10/10], Step [3601/119], Loss: 1.6991\n",
      "Epoch [10/10], Step [3701/119], Loss: 1.2792\n",
      "Epoch [10/10], Step [3801/119], Loss: 0.9905\n",
      "Epoch [10/10], Step [3901/119], Loss: 0.8696\n",
      "Epoch [10/10], Step [4001/119], Loss: 0.7016\n",
      "Epoch [10/10], Step [4101/119], Loss: 0.5557\n",
      "Epoch [10/10], Step [4201/119], Loss: 0.4681\n",
      "Epoch [10/10], Step [4301/119], Loss: 0.4331\n",
      "Epoch [10/10], Step [4401/119], Loss: 0.4229\n",
      "Epoch [10/10], Step [4501/119], Loss: 0.3459\n",
      "Epoch [10/10], Step [4601/119], Loss: 0.3340\n",
      "Epoch [10/10], Step [4701/119], Loss: 0.3152\n",
      "Epoch [10/10], Step [4801/119], Loss: 0.3047\n",
      "Epoch [10/10], Step [4901/119], Loss: 0.2882\n",
      "Epoch [10/10], Step [5001/119], Loss: 0.2784\n",
      "Epoch [10/10], Step [5101/119], Loss: 0.2786\n",
      "Epoch [10/10], Step [5201/119], Loss: 0.2716\n",
      "Epoch [10/10], Step [5301/119], Loss: 0.2686\n",
      "Epoch [10/10], Step [5401/119], Loss: 0.2480\n",
      "Epoch [10/10], Step [5501/119], Loss: 0.2604\n",
      "Epoch [10/10], Step [5601/119], Loss: 0.2597\n",
      "Epoch [10/10], Step [5701/119], Loss: 0.2359\n",
      "Epoch [10/10], Step [5801/119], Loss: 0.2377\n",
      "Epoch [10/10], Step [5901/119], Loss: 0.2317\n",
      "Epoch [10/10], Step [6001/119], Loss: 0.2419\n",
      "Epoch [10/10], Step [6101/119], Loss: 0.2412\n",
      "Epoch [10/10], Step [6201/119], Loss: 0.2299\n",
      "Epoch [10/10], Step [6301/119], Loss: 0.2337\n",
      "Epoch [10/10], Step [6401/119], Loss: 0.2321\n",
      "Epoch [10/10], Step [6501/119], Loss: 0.2335\n",
      "Epoch [10/10], Step [6601/119], Loss: 0.2317\n",
      "Epoch [10/10], Step [6701/119], Loss: 0.2179\n",
      "Epoch [10/10], Step [6801/119], Loss: 0.2280\n",
      "Epoch [10/10], Step [6901/119], Loss: 0.2217\n",
      "Epoch [10/10], Step [7001/119], Loss: 0.2250\n",
      "Epoch [10/10], Step [7101/119], Loss: 0.2100\n",
      "Epoch [10/10], Step [7201/119], Loss: 0.2139\n",
      "Epoch [10/10], Step [7301/119], Loss: 0.2182\n",
      "Epoch [10/10], Step [7401/119], Loss: 0.2135\n",
      "Epoch [10/10], Step [7501/119], Loss: 0.2207\n",
      "Epoch [10/10], Step [7601/119], Loss: 0.2111\n",
      "Epoch [10/10], Step [7701/119], Loss: 0.2069\n",
      "Epoch [10/10], Step [7801/119], Loss: 0.2015\n",
      "Epoch [10/10], Step [7901/119], Loss: 0.1961\n",
      "Epoch [10/10], Step [8001/119], Loss: 0.2050\n",
      "Epoch [10/10], Step [8101/119], Loss: 0.2037\n",
      "Epoch [10/10], Step [8201/119], Loss: 0.1988\n",
      "Epoch [10/10], Step [8301/119], Loss: 0.2027\n",
      "Epoch [10/10], Step [8401/119], Loss: 0.2043\n",
      "Epoch [10/10], Step [8501/119], Loss: 0.1908\n",
      "Epoch [10/10], Step [8601/119], Loss: 0.1925\n",
      "Epoch [10/10], Step [8701/119], Loss: 0.1885\n",
      "Epoch [10/10], Step [8801/119], Loss: 0.1903\n",
      "Epoch [10/10], Step [8901/119], Loss: 0.1848\n",
      "Epoch [10/10], Step [9001/119], Loss: 0.1762\n",
      "Epoch [10/10], Step [9101/119], Loss: 0.1895\n",
      "Epoch [10/10], Step [9201/119], Loss: 0.1726\n",
      "Epoch [10/10], Step [9301/119], Loss: 0.1664\n",
      "Epoch [10/10], Step [9401/119], Loss: 0.1863\n",
      "Epoch [10/10], Step [9501/119], Loss: 0.1710\n",
      "Epoch [10/10], Step [9601/119], Loss: 0.1709\n",
      "Epoch [10/10], Step [9701/119], Loss: 0.1768\n",
      "Epoch [10/10], Step [9801/119], Loss: 0.1776\n",
      "Epoch [10/10], Step [9901/119], Loss: 0.1676\n",
      "Epoch [10/10], Step [10001/119], Loss: 0.1724\n",
      "Epoch [10/10], Step [10101/119], Loss: 0.1639\n",
      "Epoch [10/10], Step [10201/119], Loss: 0.1570\n",
      "Epoch [10/10], Step [10301/119], Loss: 0.1546\n",
      "Epoch [10/10], Step [10401/119], Loss: 0.1678\n",
      "Epoch [10/10], Step [10501/119], Loss: 0.1545\n",
      "Epoch [10/10], Step [10601/119], Loss: 0.1598\n",
      "Epoch [10/10], Step [10701/119], Loss: 0.1549\n",
      "Epoch [10/10], Step [10801/119], Loss: 0.1585\n",
      "Epoch [10/10], Step [10901/119], Loss: 0.1670\n",
      "Epoch [10/10], Step [11001/119], Loss: 0.1486\n",
      "Epoch [10/10], Step [11101/119], Loss: 0.1494\n",
      "Epoch [10/10], Step [11201/119], Loss: 0.1520\n",
      "Epoch [10/10], Step [11301/119], Loss: 0.1395\n",
      "Epoch [10/10], Step [11401/119], Loss: 0.1408\n",
      "Epoch [10/10], Step [11501/119], Loss: 0.1314\n",
      "Epoch [10/10], Step [11601/119], Loss: 0.1231\n",
      "Epoch [10/10], Step [11701/119], Loss: 0.1234\n",
      "Epoch [10/10], Step [11801/119], Loss: 0.1223\n",
      "Epoch [10/10], Step [11901/119], Loss: 0.1190\n"
     ]
    }
   ],
   "source": [
    "save_path = \"model_4th_fold_domain2.pth\"\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    \n",
    "    # Create an instance of the classifier and define loss and optimizer\n",
    "    model = TextClassifier(input_size, hidden_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train_tensor[i:i+batch_size]\n",
    "            y_batch = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train)//batch_size}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = (predicted == y_val_tensor).sum().item() / len(y_val_tensor)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Save the model after training on the 4th fold\n",
    "    if fold == 3:  # 0-indexed, so 3 means 4th fold\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "# Continue with plotting the accuracies or any other tasks you want to perform after training on all folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict domian2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "loaded_model = TextClassifier(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Load the saved weights\n",
    "loaded_model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    test_tensor = torch.tensor(X_test, dtype=torch.float32)  # Assuming you've got your test data in X_test\n",
    "    outputs = loaded_model(test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # Now `predicted` contains the predicted labels for the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'0': 0, '1': 1, '2': 1112, '3': 2223, '4': 3334, '5': 4445, '6': 4556, '7': 4667, '8': 4778, '9': 4889, '10': 2, '11': 113, '12': 224, '13': 335, '14': 446, '15': 557, '16': 668, '17': 779, '18': 890, '19': 1001, '20': 1113, '21': 1224, '22': 1335, '23': 1446, '24': 1557, '25': 1668, '26': 1779, '27': 1890, '28': 2001, '29': 2112, '30': 2224, '31': 2335, '32': 2446, '33': 2557, '34': 2668, '35': 2779, '36': 2890, '37': 3001, '38': 3112, '39': 3223, '40': 3335, '41': 3446, '42': 3557, '43': 3668, '44': 3779, '45': 3890, '46': 4001, '47': 4112, '48': 4223, '49': 4334, '50': 4446, '51': 4457, '52': 4468, '53': 4479, '54': 4490, '55': 4501, '56': 4512, '57': 4523, '58': 4534, '59': 4545, '60': 4557, '61': 4568, '62': 4579, '63': 4590, '64': 4601, '65': 4612, '66': 4623, '67': 4634, '68': 4645, '69': 4656, '70': 4668, '71': 4679, '72': 4690, '73': 4701, '74': 4712, '75': 4723, '76': 4734, '77': 4745, '78': 4756, '79': 4767, '80': 4779, '81': 4790, '82': 4801, '83': 4812, '84': 4823, '85': 4834, '86': 4845, '87': 4856, '88': 4867, '89': 4878, '90': 4890, '91': 4901, '92': 4912, '93': 4923, '94': 4934, '95': 4945, '96': 4956, '97': 4967, '98': 4978, '99': 4989, '100': 3, '101': 14, '102': 25, '103': 36, '104': 47, '105': 58, '106': 69, '107': 80, '108': 91, '109': 102, '110': 114, '111': 125, '112': 136, '113': 147, '114': 158, '115': 169, '116': 180, '117': 191, '118': 202, '119': 213, '120': 225, '121': 236, '122': 247, '123': 258, '124': 269, '125': 280, '126': 291, '127': 302, '128': 313, '129': 324, '130': 336, '131': 347, '132': 358, '133': 369, '134': 380, '135': 391, '136': 402, '137': 413, '138': 424, '139': 435, '140': 447, '141': 458, '142': 469, '143': 480, '144': 491, '145': 502, '146': 513, '147': 524, '148': 535, '149': 546, '150': 558, '151': 569, '152': 580, '153': 591, '154': 602, '155': 613, '156': 624, '157': 635, '158': 646, '159': 657, '160': 669, '161': 680, '162': 691, '163': 702, '164': 713, '165': 724, '166': 735, '167': 746, '168': 757, '169': 768, '170': 780, '171': 791, '172': 802, '173': 813, '174': 824, '175': 835, '176': 846, '177': 857, '178': 868, '179': 879, '180': 891, '181': 902, '182': 913, '183': 924, '184': 935, '185': 946, '186': 957, '187': 968, '188': 979, '189': 990, '190': 1002, '191': 1013, '192': 1024, '193': 1035, '194': 1046, '195': 1057, '196': 1068, '197': 1079, '198': 1090, '199': 1101, '200': 1114, '201': 1125, '202': 1136, '203': 1147, '204': 1158, '205': 1169, '206': 1180, '207': 1191, '208': 1202, '209': 1213, '210': 1225, '211': 1236, '212': 1247, '213': 1258, '214': 1269, '215': 1280, '216': 1291, '217': 1302, '218': 1313, '219': 1324, '220': 1336, '221': 1347, '222': 1358, '223': 1369, '224': 1380, '225': 1391, '226': 1402, '227': 1413, '228': 1424, '229': 1435, '230': 1447, '231': 1458, '232': 1469, '233': 1480, '234': 1491, '235': 1502, '236': 1513, '237': 1524, '238': 1535, '239': 1546, '240': 1558, '241': 1569, '242': 1580, '243': 1591, '244': 1602, '245': 1613, '246': 1624, '247': 1635, '248': 1646, '249': 1657, '250': 1669, '251': 1680, '252': 1691, '253': 1702, '254': 1713, '255': 1724, '256': 1735, '257': 1746, '258': 1757, '259': 1768, '260': 1780, '261': 1791, '262': 1802, '263': 1813, '264': 1824, '265': 1835, '266': 1846, '267': 1857, '268': 1868, '269': 1879, '270': 1891, '271': 1902, '272': 1913, '273': 1924, '274': 1935, '275': 1946, '276': 1957, '277': 1968, '278': 1979, '279': 1990, '280': 2002, '281': 2013, '282': 2024, '283': 2035, '284': 2046, '285': 2057, '286': 2068, '287': 2079, '288': 2090, '289': 2101, '290': 2113, '291': 2124, '292': 2135, '293': 2146, '294': 2157, '295': 2168, '296': 2179, '297': 2190, '298': 2201, '299': 2212, '300': 2225, '301': 2236, '302': 2247, '303': 2258, '304': 2269, '305': 2280, '306': 2291, '307': 2302, '308': 2313, '309': 2324, '310': 2336, '311': 2347, '312': 2358, '313': 2369, '314': 2380, '315': 2391, '316': 2402, '317': 2413, '318': 2424, '319': 2435, '320': 2447, '321': 2458, '322': 2469, '323': 2480, '324': 2491, '325': 2502, '326': 2513, '327': 2524, '328': 2535, '329': 2546, '330': 2558, '331': 2569, '332': 2580, '333': 2591, '334': 2602, '335': 2613, '336': 2624, '337': 2635, '338': 2646, '339': 2657, '340': 2669, '341': 2680, '342': 2691, '343': 2702, '344': 2713, '345': 2724, '346': 2735, '347': 2746, '348': 2757, '349': 2768, '350': 2780, '351': 2791, '352': 2802, '353': 2813, '354': 2824, '355': 2835, '356': 2846, '357': 2857, '358': 2868, '359': 2879, '360': 2891, '361': 2902, '362': 2913, '363': 2924, '364': 2935, '365': 2946, '366': 2957, '367': 2968, '368': 2979, '369': 2990, '370': 3002, '371': 3013, '372': 3024, '373': 3035, '374': 3046, '375': 3057, '376': 3068, '377': 3079, '378': 3090, '379': 3101, '380': 3113, '381': 3124, '382': 3135, '383': 3146, '384': 3157, '385': 3168, '386': 3179, '387': 3190, '388': 3201, '389': 3212, '390': 3224, '391': 3235, '392': 3246, '393': 3257, '394': 3268, '395': 3279, '396': 3290, '397': 3301, '398': 3312, '399': 3323, '400': 3336, '401': 3347, '402': 3358, '403': 3369, '404': 3380, '405': 3391, '406': 3402, '407': 3413, '408': 3424, '409': 3435, '410': 3447, '411': 3458, '412': 3469, '413': 3480, '414': 3491, '415': 3502, '416': 3513, '417': 3524, '418': 3535, '419': 3546, '420': 3558, '421': 3569, '422': 3580, '423': 3591, '424': 3602, '425': 3613, '426': 3624, '427': 3635, '428': 3646, '429': 3657, '430': 3669, '431': 3680, '432': 3691, '433': 3702, '434': 3713, '435': 3724, '436': 3735, '437': 3746, '438': 3757, '439': 3768, '440': 3780, '441': 3791, '442': 3802, '443': 3813, '444': 3824, '445': 3835, '446': 3846, '447': 3857, '448': 3868, '449': 3879, '450': 3891, '451': 3902, '452': 3913, '453': 3924, '454': 3935, '455': 3946, '456': 3957, '457': 3968, '458': 3979, '459': 3990, '460': 4002, '461': 4013, '462': 4024, '463': 4035, '464': 4046, '465': 4057, '466': 4068, '467': 4079, '468': 4090, '469': 4101, '470': 4113, '471': 4124, '472': 4135, '473': 4146, '474': 4157, '475': 4168, '476': 4179, '477': 4190, '478': 4201, '479': 4212, '480': 4224, '481': 4235, '482': 4246, '483': 4257, '484': 4268, '485': 4279, '486': 4290, '487': 4301, '488': 4312, '489': 4323, '490': 4335, '491': 4346, '492': 4357, '493': 4368, '494': 4379, '495': 4390, '496': 4401, '497': 4412, '498': 4423, '499': 4434, '500': 4447, '501': 4448, '502': 4449, '503': 4450, '504': 4451, '505': 4452, '506': 4453, '507': 4454, '508': 4455, '509': 4456, '510': 4458, '511': 4459, '512': 4460, '513': 4461, '514': 4462, '515': 4463, '516': 4464, '517': 4465, '518': 4466, '519': 4467, '520': 4469, '521': 4470, '522': 4471, '523': 4472, '524': 4473, '525': 4474, '526': 4475, '527': 4476, '528': 4477, '529': 4478, '530': 4480, '531': 4481, '532': 4482, '533': 4483, '534': 4484, '535': 4485, '536': 4486, '537': 4487, '538': 4488, '539': 4489, '540': 4491, '541': 4492, '542': 4493, '543': 4494, '544': 4495, '545': 4496, '546': 4497, '547': 4498, '548': 4499, '549': 4500, '550': 4502, '551': 4503, '552': 4504, '553': 4505, '554': 4506, '555': 4507, '556': 4508, '557': 4509, '558': 4510, '559': 4511, '560': 4513, '561': 4514, '562': 4515, '563': 4516, '564': 4517, '565': 4518, '566': 4519, '567': 4520, '568': 4521, '569': 4522, '570': 4524, '571': 4525, '572': 4526, '573': 4527, '574': 4528, '575': 4529, '576': 4530, '577': 4531, '578': 4532, '579': 4533, '580': 4535, '581': 4536, '582': 4537, '583': 4538, '584': 4539, '585': 4540, '586': 4541, '587': 4542, '588': 4543, '589': 4544, '590': 4546, '591': 4547, '592': 4548, '593': 4549, '594': 4550, '595': 4551, '596': 4552, '597': 4553, '598': 4554, '599': 4555, '600': 4558, '601': 4559, '602': 4560, '603': 4561, '604': 4562, '605': 4563, '606': 4564, '607': 4565, '608': 4566, '609': 4567, '610': 4569, '611': 4570, '612': 4571, '613': 4572, '614': 4573, '615': 4574, '616': 4575, '617': 4576, '618': 4577, '619': 4578, '620': 4580, '621': 4581, '622': 4582, '623': 4583, '624': 4584, '625': 4585, '626': 4586, '627': 4587, '628': 4588, '629': 4589, '630': 4591, '631': 4592, '632': 4593, '633': 4594, '634': 4595, '635': 4596, '636': 4597, '637': 4598, '638': 4599, '639': 4600, '640': 4602, '641': 4603, '642': 4604, '643': 4605, '644': 4606, '645': 4607, '646': 4608, '647': 4609, '648': 4610, '649': 4611, '650': 4613, '651': 4614, '652': 4615, '653': 4616, '654': 4617, '655': 4618, '656': 4619, '657': 4620, '658': 4621, '659': 4622, '660': 4624, '661': 4625, '662': 4626, '663': 4627, '664': 4628, '665': 4629, '666': 4630, '667': 4631, '668': 4632, '669': 4633, '670': 4635, '671': 4636, '672': 4637, '673': 4638, '674': 4639, '675': 4640, '676': 4641, '677': 4642, '678': 4643, '679': 4644, '680': 4646, '681': 4647, '682': 4648, '683': 4649, '684': 4650, '685': 4651, '686': 4652, '687': 4653, '688': 4654, '689': 4655, '690': 4657, '691': 4658, '692': 4659, '693': 4660, '694': 4661, '695': 4662, '696': 4663, '697': 4664, '698': 4665, '699': 4666, '700': 4669, '701': 4670, '702': 4671, '703': 4672, '704': 4673, '705': 4674, '706': 4675, '707': 4676, '708': 4677, '709': 4678, '710': 4680, '711': 4681, '712': 4682, '713': 4683, '714': 4684, '715': 4685, '716': 4686, '717': 4687, '718': 4688, '719': 4689, '720': 4691, '721': 4692, '722': 4693, '723': 4694, '724': 4695, '725': 4696, '726': 4697, '727': 4698, '728': 4699, '729': 4700, '730': 4702, '731': 4703, '732': 4704, '733': 4705, '734': 4706, '735': 4707, '736': 4708, '737': 4709, '738': 4710, '739': 4711, '740': 4713, '741': 4714, '742': 4715, '743': 4716, '744': 4717, '745': 4718, '746': 4719, '747': 4720, '748': 4721, '749': 4722, '750': 4724, '751': 4725, '752': 4726, '753': 4727, '754': 4728, '755': 4729, '756': 4730, '757': 4731, '758': 4732, '759': 4733, '760': 4735, '761': 4736, '762': 4737, '763': 4738, '764': 4739, '765': 4740, '766': 4741, '767': 4742, '768': 4743, '769': 4744, '770': 4746, '771': 4747, '772': 4748, '773': 4749, '774': 4750, '775': 4751, '776': 4752, '777': 4753, '778': 4754, '779': 4755, '780': 4757, '781': 4758, '782': 4759, '783': 4760, '784': 4761, '785': 4762, '786': 4763, '787': 4764, '788': 4765, '789': 4766, '790': 4768, '791': 4769, '792': 4770, '793': 4771, '794': 4772, '795': 4773, '796': 4774, '797': 4775, '798': 4776, '799': 4777, '800': 4780, '801': 4781, '802': 4782, '803': 4783, '804': 4784, '805': 4785, '806': 4786, '807': 4787, '808': 4788, '809': 4789, '810': 4791, '811': 4792, '812': 4793, '813': 4794, '814': 4795, '815': 4796, '816': 4797, '817': 4798, '818': 4799, '819': 4800, '820': 4802, '821': 4803, '822': 4804, '823': 4805, '824': 4806, '825': 4807, '826': 4808, '827': 4809, '828': 4810, '829': 4811, '830': 4813, '831': 4814, '832': 4815, '833': 4816, '834': 4817, '835': 4818, '836': 4819, '837': 4820, '838': 4821, '839': 4822, '840': 4824, '841': 4825, '842': 4826, '843': 4827, '844': 4828, '845': 4829, '846': 4830, '847': 4831, '848': 4832, '849': 4833, '850': 4835, '851': 4836, '852': 4837, '853': 4838, '854': 4839, '855': 4840, '856': 4841, '857': 4842, '858': 4843, '859': 4844, '860': 4846, '861': 4847, '862': 4848, '863': 4849, '864': 4850, '865': 4851, '866': 4852, '867': 4853, '868': 4854, '869': 4855, '870': 4857, '871': 4858, '872': 4859, '873': 4860, '874': 4861, '875': 4862, '876': 4863, '877': 4864, '878': 4865, '879': 4866, '880': 4868, '881': 4869, '882': 4870, '883': 4871, '884': 4872, '885': 4873, '886': 4874, '887': 4875, '888': 4876, '889': 4877, '890': 4879, '891': 4880, '892': 4881, '893': 4882, '894': 4883, '895': 4884, '896': 4885, '897': 4886, '898': 4887, '899': 4888, '900': 4891, '901': 4892, '902': 4893, '903': 4894, '904': 4895, '905': 4896, '906': 4897, '907': 4898, '908': 4899, '909': 4900, '910': 4902, '911': 4903, '912': 4904, '913': 4905, '914': 4906, '915': 4907, '916': 4908, '917': 4909, '918': 4910, '919': 4911, '920': 4913, '921': 4914, '922': 4915, '923': 4916, '924': 4917, '925': 4918, '926': 4919, '927': 4920, '928': 4921, '929': 4922, '930': 4924, '931': 4925, '932': 4926, '933': 4927, '934': 4928, '935': 4929, '936': 4930, '937': 4931, '938': 4932, '939': 4933, '940': 4935, '941': 4936, '942': 4937, '943': 4938, '944': 4939, '945': 4940, '946': 4941, '947': 4942, '948': 4943, '949': 4944, '950': 4946, '951': 4947, '952': 4948, '953': 4949, '954': 4950, '955': 4951, '956': 4952, '957': 4953, '958': 4954, '959': 4955, '960': 4957, '961': 4958, '962': 4959, '963': 4960, '964': 4961, '965': 4962, '966': 4963, '967': 4964, '968': 4965, '969': 4966, '970': 4968, '971': 4969, '972': 4970, '973': 4971, '974': 4972, '975': 4973, '976': 4974, '977': 4975, '978': 4976, '979': 4977, '980': 4979, '981': 4980, '982': 4981, '983': 4982, '984': 4983, '985': 4984, '986': 4985, '987': 4986, '988': 4987, '989': 4988, '990': 4990, '991': 4991, '992': 4992, '993': 4993, '994': 4994, '995': 4995, '996': 4996, '997': 4997, '998': 4998, '999': 4999, '1000': 4, '1001': 5, '1002': 6, '1003': 7, '1004': 8, '1005': 9, '1006': 10, '1007': 11, '1008': 12, '1009': 13, '1010': 15, '1011': 16, '1012': 17, '1013': 18, '1014': 19, '1015': 20, '1016': 21, '1017': 22, '1018': 23, '1019': 24, '1020': 26, '1021': 27, '1022': 28, '1023': 29, '1024': 30, '1025': 31, '1026': 32, '1027': 33, '1028': 34, '1029': 35, '1030': 37, '1031': 38, '1032': 39, '1033': 40, '1034': 41, '1035': 42, '1036': 43, '1037': 44, '1038': 45, '1039': 46, '1040': 48, '1041': 49, '1042': 50, '1043': 51, '1044': 52, '1045': 53, '1046': 54, '1047': 55, '1048': 56, '1049': 57, '1050': 59, '1051': 60, '1052': 61, '1053': 62, '1054': 63, '1055': 64, '1056': 65, '1057': 66, '1058': 67, '1059': 68, '1060': 70, '1061': 71, '1062': 72, '1063': 73, '1064': 74, '1065': 75, '1066': 76, '1067': 77, '1068': 78, '1069': 79, '1070': 81, '1071': 82, '1072': 83, '1073': 84, '1074': 85, '1075': 86, '1076': 87, '1077': 88, '1078': 89, '1079': 90, '1080': 92, '1081': 93, '1082': 94, '1083': 95, '1084': 96, '1085': 97, '1086': 98, '1087': 99, '1088': 100, '1089': 101, '1090': 103, '1091': 104, '1092': 105, '1093': 106, '1094': 107, '1095': 108, '1096': 109, '1097': 110, '1098': 111, '1099': 112, '1100': 115, '1101': 116, '1102': 117, '1103': 118, '1104': 119, '1105': 120, '1106': 121, '1107': 122, '1108': 123, '1109': 124, '1110': 126, '1111': 127, '1112': 128, '1113': 129, '1114': 130, '1115': 131, '1116': 132, '1117': 133, '1118': 134, '1119': 135, '1120': 137, '1121': 138, '1122': 139, '1123': 140, '1124': 141, '1125': 142, '1126': 143, '1127': 144, '1128': 145, '1129': 146, '1130': 148, '1131': 149, '1132': 150, '1133': 151, '1134': 152, '1135': 153, '1136': 154, '1137': 155, '1138': 156, '1139': 157, '1140': 159, '1141': 160, '1142': 161, '1143': 162, '1144': 163, '1145': 164, '1146': 165, '1147': 166, '1148': 167, '1149': 168, '1150': 170, '1151': 171, '1152': 172, '1153': 173, '1154': 174, '1155': 175, '1156': 176, '1157': 177, '1158': 178, '1159': 179, '1160': 181, '1161': 182, '1162': 183, '1163': 184, '1164': 185, '1165': 186, '1166': 187, '1167': 188, '1168': 189, '1169': 190, '1170': 192, '1171': 193, '1172': 194, '1173': 195, '1174': 196, '1175': 197, '1176': 198, '1177': 199, '1178': 200, '1179': 201, '1180': 203, '1181': 204, '1182': 205, '1183': 206, '1184': 207, '1185': 208, '1186': 209, '1187': 210, '1188': 211, '1189': 212, '1190': 214, '1191': 215, '1192': 216, '1193': 217, '1194': 218, '1195': 219, '1196': 220, '1197': 221, '1198': 222, '1199': 223, '1200': 226, '1201': 227, '1202': 228, '1203': 229, '1204': 230, '1205': 231, '1206': 232, '1207': 233, '1208': 234, '1209': 235, '1210': 237, '1211': 238, '1212': 239, '1213': 240, '1214': 241, '1215': 242, '1216': 243, '1217': 244, '1218': 245, '1219': 246, '1220': 248, '1221': 249, '1222': 250, '1223': 251, '1224': 252, '1225': 253, '1226': 254, '1227': 255, '1228': 256, '1229': 257, '1230': 259, '1231': 260, '1232': 261, '1233': 262, '1234': 263, '1235': 264, '1236': 265, '1237': 266, '1238': 267, '1239': 268, '1240': 270, '1241': 271, '1242': 272, '1243': 273, '1244': 274, '1245': 275, '1246': 276, '1247': 277, '1248': 278, '1249': 279, '1250': 281, '1251': 282, '1252': 283, '1253': 284, '1254': 285, '1255': 286, '1256': 287, '1257': 288, '1258': 289, '1259': 290, '1260': 292, '1261': 293, '1262': 294, '1263': 295, '1264': 296, '1265': 297, '1266': 298, '1267': 299, '1268': 300, '1269': 301, '1270': 303, '1271': 304, '1272': 305, '1273': 306, '1274': 307, '1275': 308, '1276': 309, '1277': 310, '1278': 311, '1279': 312, '1280': 314, '1281': 315, '1282': 316, '1283': 317, '1284': 318, '1285': 319, '1286': 320, '1287': 321, '1288': 322, '1289': 323, '1290': 325, '1291': 326, '1292': 327, '1293': 328, '1294': 329, '1295': 330, '1296': 331, '1297': 332, '1298': 333, '1299': 334, '1300': 337, '1301': 338, '1302': 339, '1303': 340, '1304': 341, '1305': 342, '1306': 343, '1307': 344, '1308': 345, '1309': 346, '1310': 348, '1311': 349, '1312': 350, '1313': 351, '1314': 352, '1315': 353, '1316': 354, '1317': 355, '1318': 356, '1319': 357, '1320': 359, '1321': 360, '1322': 361, '1323': 362, '1324': 363, '1325': 364, '1326': 365, '1327': 366, '1328': 367, '1329': 368, '1330': 370, '1331': 371, '1332': 372, '1333': 373, '1334': 374, '1335': 375, '1336': 376, '1337': 377, '1338': 378, '1339': 379, '1340': 381, '1341': 382, '1342': 383, '1343': 384, '1344': 385, '1345': 386, '1346': 387, '1347': 388, '1348': 389, '1349': 390, '1350': 392, '1351': 393, '1352': 394, '1353': 395, '1354': 396, '1355': 397, '1356': 398, '1357': 399, '1358': 400, '1359': 401, '1360': 403, '1361': 404, '1362': 405, '1363': 406, '1364': 407, '1365': 408, '1366': 409, '1367': 410, '1368': 411, '1369': 412, '1370': 414, '1371': 415, '1372': 416, '1373': 417, '1374': 418, '1375': 419, '1376': 420, '1377': 421, '1378': 422, '1379': 423, '1380': 425, '1381': 426, '1382': 427, '1383': 428, '1384': 429, '1385': 430, '1386': 431, '1387': 432, '1388': 433, '1389': 434, '1390': 436, '1391': 437, '1392': 438, '1393': 439, '1394': 440, '1395': 441, '1396': 442, '1397': 443, '1398': 444, '1399': 445, '1400': 448, '1401': 449, '1402': 450, '1403': 451, '1404': 452, '1405': 453, '1406': 454, '1407': 455, '1408': 456, '1409': 457, '1410': 459, '1411': 460, '1412': 461, '1413': 462, '1414': 463, '1415': 464, '1416': 465, '1417': 466, '1418': 467, '1419': 468, '1420': 470, '1421': 471, '1422': 472, '1423': 473, '1424': 474, '1425': 475, '1426': 476, '1427': 477, '1428': 478, '1429': 479, '1430': 481, '1431': 482, '1432': 483, '1433': 484, '1434': 485, '1435': 486, '1436': 487, '1437': 488, '1438': 489, '1439': 490, '1440': 492, '1441': 493, '1442': 494, '1443': 495, '1444': 496, '1445': 497, '1446': 498, '1447': 499, '1448': 500, '1449': 501, '1450': 503, '1451': 504, '1452': 505, '1453': 506, '1454': 507, '1455': 508, '1456': 509, '1457': 510, '1458': 511, '1459': 512, '1460': 514, '1461': 515, '1462': 516, '1463': 517, '1464': 518, '1465': 519, '1466': 520, '1467': 521, '1468': 522, '1469': 523, '1470': 525, '1471': 526, '1472': 527, '1473': 528, '1474': 529, '1475': 530, '1476': 531, '1477': 532, '1478': 533, '1479': 534, '1480': 536, '1481': 537, '1482': 538, '1483': 539, '1484': 540, '1485': 541, '1486': 542, '1487': 543, '1488': 544, '1489': 545, '1490': 547, '1491': 548, '1492': 549, '1493': 550, '1494': 551, '1495': 552, '1496': 553, '1497': 554, '1498': 555, '1499': 556, '1500': 559, '1501': 560, '1502': 561, '1503': 562, '1504': 563, '1505': 564, '1506': 565, '1507': 566, '1508': 567, '1509': 568, '1510': 570, '1511': 571, '1512': 572, '1513': 573, '1514': 574, '1515': 575, '1516': 576, '1517': 577, '1518': 578, '1519': 579, '1520': 581, '1521': 582, '1522': 583, '1523': 584, '1524': 585, '1525': 586, '1526': 587, '1527': 588, '1528': 589, '1529': 590, '1530': 592, '1531': 593, '1532': 594, '1533': 595, '1534': 596, '1535': 597, '1536': 598, '1537': 599, '1538': 600, '1539': 601, '1540': 603, '1541': 604, '1542': 605, '1543': 606, '1544': 607, '1545': 608, '1546': 609, '1547': 610, '1548': 611, '1549': 612, '1550': 614, '1551': 615, '1552': 616, '1553': 617, '1554': 618, '1555': 619, '1556': 620, '1557': 621, '1558': 622, '1559': 623, '1560': 625, '1561': 626, '1562': 627, '1563': 628, '1564': 629, '1565': 630, '1566': 631, '1567': 632, '1568': 633, '1569': 634, '1570': 636, '1571': 637, '1572': 638, '1573': 639, '1574': 640, '1575': 641, '1576': 642, '1577': 643, '1578': 644, '1579': 645, '1580': 647, '1581': 648, '1582': 649, '1583': 650, '1584': 651, '1585': 652, '1586': 653, '1587': 654, '1588': 655, '1589': 656, '1590': 658, '1591': 659, '1592': 660, '1593': 661, '1594': 662, '1595': 663, '1596': 664, '1597': 665, '1598': 666, '1599': 667, '1600': 670, '1601': 671, '1602': 672, '1603': 673, '1604': 674, '1605': 675, '1606': 676, '1607': 677, '1608': 678, '1609': 679, '1610': 681, '1611': 682, '1612': 683, '1613': 684, '1614': 685, '1615': 686, '1616': 687, '1617': 688, '1618': 689, '1619': 690, '1620': 692, '1621': 693, '1622': 694, '1623': 695, '1624': 696, '1625': 697, '1626': 698, '1627': 699, '1628': 700, '1629': 701, '1630': 703, '1631': 704, '1632': 705, '1633': 706, '1634': 707, '1635': 708, '1636': 709, '1637': 710, '1638': 711, '1639': 712, '1640': 714, '1641': 715, '1642': 716, '1643': 717, '1644': 718, '1645': 719, '1646': 720, '1647': 721, '1648': 722, '1649': 723, '1650': 725, '1651': 726, '1652': 727, '1653': 728, '1654': 729, '1655': 730, '1656': 731, '1657': 732, '1658': 733, '1659': 734, '1660': 736, '1661': 737, '1662': 738, '1663': 739, '1664': 740, '1665': 741, '1666': 742, '1667': 743, '1668': 744, '1669': 745, '1670': 747, '1671': 748, '1672': 749, '1673': 750, '1674': 751, '1675': 752, '1676': 753, '1677': 754, '1678': 755, '1679': 756, '1680': 758, '1681': 759, '1682': 760, '1683': 761, '1684': 762, '1685': 763, '1686': 764, '1687': 765, '1688': 766, '1689': 767, '1690': 769, '1691': 770, '1692': 771, '1693': 772, '1694': 773, '1695': 774, '1696': 775, '1697': 776, '1698': 777, '1699': 778, '1700': 781, '1701': 782, '1702': 783, '1703': 784, '1704': 785, '1705': 786, '1706': 787, '1707': 788, '1708': 789, '1709': 790, '1710': 792, '1711': 793, '1712': 794, '1713': 795, '1714': 796, '1715': 797, '1716': 798, '1717': 799, '1718': 800, '1719': 801, '1720': 803, '1721': 804, '1722': 805, '1723': 806, '1724': 807, '1725': 808, '1726': 809, '1727': 810, '1728': 811, '1729': 812, '1730': 814, '1731': 815, '1732': 816, '1733': 817, '1734': 818, '1735': 819, '1736': 820, '1737': 821, '1738': 822, '1739': 823, '1740': 825, '1741': 826, '1742': 827, '1743': 828, '1744': 829, '1745': 830, '1746': 831, '1747': 832, '1748': 833, '1749': 834, '1750': 836, '1751': 837, '1752': 838, '1753': 839, '1754': 840, '1755': 841, '1756': 842, '1757': 843, '1758': 844, '1759': 845, '1760': 847, '1761': 848, '1762': 849, '1763': 850, '1764': 851, '1765': 852, '1766': 853, '1767': 854, '1768': 855, '1769': 856, '1770': 858, '1771': 859, '1772': 860, '1773': 861, '1774': 862, '1775': 863, '1776': 864, '1777': 865, '1778': 866, '1779': 867, '1780': 869, '1781': 870, '1782': 871, '1783': 872, '1784': 873, '1785': 874, '1786': 875, '1787': 876, '1788': 877, '1789': 878, '1790': 880, '1791': 881, '1792': 882, '1793': 883, '1794': 884, '1795': 885, '1796': 886, '1797': 887, '1798': 888, '1799': 889, '1800': 892, '1801': 893, '1802': 894, '1803': 895, '1804': 896, '1805': 897, '1806': 898, '1807': 899, '1808': 900, '1809': 901, '1810': 903, '1811': 904, '1812': 905, '1813': 906, '1814': 907, '1815': 908, '1816': 909, '1817': 910, '1818': 911, '1819': 912, '1820': 914, '1821': 915, '1822': 916, '1823': 917, '1824': 918, '1825': 919, '1826': 920, '1827': 921, '1828': 922, '1829': 923, '1830': 925, '1831': 926, '1832': 927, '1833': 928, '1834': 929, '1835': 930, '1836': 931, '1837': 932, '1838': 933, '1839': 934, '1840': 936, '1841': 937, '1842': 938, '1843': 939, '1844': 940, '1845': 941, '1846': 942, '1847': 943, '1848': 944, '1849': 945, '1850': 947, '1851': 948, '1852': 949, '1853': 950, '1854': 951, '1855': 952, '1856': 953, '1857': 954, '1858': 955, '1859': 956, '1860': 958, '1861': 959, '1862': 960, '1863': 961, '1864': 962, '1865': 963, '1866': 964, '1867': 965, '1868': 966, '1869': 967, '1870': 969, '1871': 970, '1872': 971, '1873': 972, '1874': 973, '1875': 974, '1876': 975, '1877': 976, '1878': 977, '1879': 978, '1880': 980, '1881': 981, '1882': 982, '1883': 983, '1884': 984, '1885': 985, '1886': 986, '1887': 987, '1888': 988, '1889': 989, '1890': 991, '1891': 992, '1892': 993, '1893': 994, '1894': 995, '1895': 996, '1896': 997, '1897': 998, '1898': 999, '1899': 1000, '1900': 1003, '1901': 1004, '1902': 1005, '1903': 1006, '1904': 1007, '1905': 1008, '1906': 1009, '1907': 1010, '1908': 1011, '1909': 1012, '1910': 1014, '1911': 1015, '1912': 1016, '1913': 1017, '1914': 1018, '1915': 1019, '1916': 1020, '1917': 1021, '1918': 1022, '1919': 1023, '1920': 1025, '1921': 1026, '1922': 1027, '1923': 1028, '1924': 1029, '1925': 1030, '1926': 1031, '1927': 1032, '1928': 1033, '1929': 1034, '1930': 1036, '1931': 1037, '1932': 1038, '1933': 1039, '1934': 1040, '1935': 1041, '1936': 1042, '1937': 1043, '1938': 1044, '1939': 1045, '1940': 1047, '1941': 1048, '1942': 1049, '1943': 1050, '1944': 1051, '1945': 1052, '1946': 1053, '1947': 1054, '1948': 1055, '1949': 1056, '1950': 1058, '1951': 1059, '1952': 1060, '1953': 1061, '1954': 1062, '1955': 1063, '1956': 1064, '1957': 1065, '1958': 1066, '1959': 1067, '1960': 1069, '1961': 1070, '1962': 1071, '1963': 1072, '1964': 1073, '1965': 1074, '1966': 1075, '1967': 1076, '1968': 1077, '1969': 1078, '1970': 1080, '1971': 1081, '1972': 1082, '1973': 1083, '1974': 1084, '1975': 1085, '1976': 1086, '1977': 1087, '1978': 1088, '1979': 1089, '1980': 1091, '1981': 1092, '1982': 1093, '1983': 1094, '1984': 1095, '1985': 1096, '1986': 1097, '1987': 1098, '1988': 1099, '1989': 1100, '1990': 1102, '1991': 1103, '1992': 1104, '1993': 1105, '1994': 1106, '1995': 1107, '1996': 1108, '1997': 1109, '1998': 1110, '1999': 1111, '2000': 1115, '2001': 1116, '2002': 1117, '2003': 1118, '2004': 1119, '2005': 1120, '2006': 1121, '2007': 1122, '2008': 1123, '2009': 1124, '2010': 1126, '2011': 1127, '2012': 1128, '2013': 1129, '2014': 1130, '2015': 1131, '2016': 1132, '2017': 1133, '2018': 1134, '2019': 1135, '2020': 1137, '2021': 1138, '2022': 1139, '2023': 1140, '2024': 1141, '2025': 1142, '2026': 1143, '2027': 1144, '2028': 1145, '2029': 1146, '2030': 1148, '2031': 1149, '2032': 1150, '2033': 1151, '2034': 1152, '2035': 1153, '2036': 1154, '2037': 1155, '2038': 1156, '2039': 1157, '2040': 1159, '2041': 1160, '2042': 1161, '2043': 1162, '2044': 1163, '2045': 1164, '2046': 1165, '2047': 1166, '2048': 1167, '2049': 1168, '2050': 1170, '2051': 1171, '2052': 1172, '2053': 1173, '2054': 1174, '2055': 1175, '2056': 1176, '2057': 1177, '2058': 1178, '2059': 1179, '2060': 1181, '2061': 1182, '2062': 1183, '2063': 1184, '2064': 1185, '2065': 1186, '2066': 1187, '2067': 1188, '2068': 1189, '2069': 1190, '2070': 1192, '2071': 1193, '2072': 1194, '2073': 1195, '2074': 1196, '2075': 1197, '2076': 1198, '2077': 1199, '2078': 1200, '2079': 1201, '2080': 1203, '2081': 1204, '2082': 1205, '2083': 1206, '2084': 1207, '2085': 1208, '2086': 1209, '2087': 1210, '2088': 1211, '2089': 1212, '2090': 1214, '2091': 1215, '2092': 1216, '2093': 1217, '2094': 1218, '2095': 1219, '2096': 1220, '2097': 1221, '2098': 1222, '2099': 1223, '2100': 1226, '2101': 1227, '2102': 1228, '2103': 1229, '2104': 1230, '2105': 1231, '2106': 1232, '2107': 1233, '2108': 1234, '2109': 1235, '2110': 1237, '2111': 1238, '2112': 1239, '2113': 1240, '2114': 1241, '2115': 1242, '2116': 1243, '2117': 1244, '2118': 1245, '2119': 1246, '2120': 1248, '2121': 1249, '2122': 1250, '2123': 1251, '2124': 1252, '2125': 1253, '2126': 1254, '2127': 1255, '2128': 1256, '2129': 1257, '2130': 1259, '2131': 1260, '2132': 1261, '2133': 1262, '2134': 1263, '2135': 1264, '2136': 1265, '2137': 1266, '2138': 1267, '2139': 1268, '2140': 1270, '2141': 1271, '2142': 1272, '2143': 1273, '2144': 1274, '2145': 1275, '2146': 1276, '2147': 1277, '2148': 1278, '2149': 1279, '2150': 1281, '2151': 1282, '2152': 1283, '2153': 1284, '2154': 1285, '2155': 1286, '2156': 1287, '2157': 1288, '2158': 1289, '2159': 1290, '2160': 1292, '2161': 1293, '2162': 1294, '2163': 1295, '2164': 1296, '2165': 1297, '2166': 1298, '2167': 1299, '2168': 1300, '2169': 1301, '2170': 1303, '2171': 1304, '2172': 1305, '2173': 1306, '2174': 1307, '2175': 1308, '2176': 1309, '2177': 1310, '2178': 1311, '2179': 1312, '2180': 1314, '2181': 1315, '2182': 1316, '2183': 1317, '2184': 1318, '2185': 1319, '2186': 1320, '2187': 1321, '2188': 1322, '2189': 1323, '2190': 1325, '2191': 1326, '2192': 1327, '2193': 1328, '2194': 1329, '2195': 1330, '2196': 1331, '2197': 1332, '2198': 1333, '2199': 1334, '2200': 1337, '2201': 1338, '2202': 1339, '2203': 1340, '2204': 1341, '2205': 1342, '2206': 1343, '2207': 1344, '2208': 1345, '2209': 1346, '2210': 1348, '2211': 1349, '2212': 1350, '2213': 1351, '2214': 1352, '2215': 1353, '2216': 1354, '2217': 1355, '2218': 1356, '2219': 1357, '2220': 1359, '2221': 1360, '2222': 1361, '2223': 1362, '2224': 1363, '2225': 1364, '2226': 1365, '2227': 1366, '2228': 1367, '2229': 1368, '2230': 1370, '2231': 1371, '2232': 1372, '2233': 1373, '2234': 1374, '2235': 1375, '2236': 1376, '2237': 1377, '2238': 1378, '2239': 1379, '2240': 1381, '2241': 1382, '2242': 1383, '2243': 1384, '2244': 1385, '2245': 1386, '2246': 1387, '2247': 1388, '2248': 1389, '2249': 1390, '2250': 1392, '2251': 1393, '2252': 1394, '2253': 1395, '2254': 1396, '2255': 1397, '2256': 1398, '2257': 1399, '2258': 1400, '2259': 1401, '2260': 1403, '2261': 1404, '2262': 1405, '2263': 1406, '2264': 1407, '2265': 1408, '2266': 1409, '2267': 1410, '2268': 1411, '2269': 1412, '2270': 1414, '2271': 1415, '2272': 1416, '2273': 1417, '2274': 1418, '2275': 1419, '2276': 1420, '2277': 1421, '2278': 1422, '2279': 1423, '2280': 1425, '2281': 1426, '2282': 1427, '2283': 1428, '2284': 1429, '2285': 1430, '2286': 1431, '2287': 1432, '2288': 1433, '2289': 1434, '2290': 1436, '2291': 1437, '2292': 1438, '2293': 1439, '2294': 1440, '2295': 1441, '2296': 1442, '2297': 1443, '2298': 1444, '2299': 1445, '2300': 1448, '2301': 1449, '2302': 1450, '2303': 1451, '2304': 1452, '2305': 1453, '2306': 1454, '2307': 1455, '2308': 1456, '2309': 1457, '2310': 1459, '2311': 1460, '2312': 1461, '2313': 1462, '2314': 1463, '2315': 1464, '2316': 1465, '2317': 1466, '2318': 1467, '2319': 1468, '2320': 1470, '2321': 1471, '2322': 1472, '2323': 1473, '2324': 1474, '2325': 1475, '2326': 1476, '2327': 1477, '2328': 1478, '2329': 1479, '2330': 1481, '2331': 1482, '2332': 1483, '2333': 1484, '2334': 1485, '2335': 1486, '2336': 1487, '2337': 1488, '2338': 1489, '2339': 1490, '2340': 1492, '2341': 1493, '2342': 1494, '2343': 1495, '2344': 1496, '2345': 1497, '2346': 1498, '2347': 1499, '2348': 1500, '2349': 1501, '2350': 1503, '2351': 1504, '2352': 1505, '2353': 1506, '2354': 1507, '2355': 1508, '2356': 1509, '2357': 1510, '2358': 1511, '2359': 1512, '2360': 1514, '2361': 1515, '2362': 1516, '2363': 1517, '2364': 1518, '2365': 1519, '2366': 1520, '2367': 1521, '2368': 1522, '2369': 1523, '2370': 1525, '2371': 1526, '2372': 1527, '2373': 1528, '2374': 1529, '2375': 1530, '2376': 1531, '2377': 1532, '2378': 1533, '2379': 1534, '2380': 1536, '2381': 1537, '2382': 1538, '2383': 1539, '2384': 1540, '2385': 1541, '2386': 1542, '2387': 1543, '2388': 1544, '2389': 1545, '2390': 1547, '2391': 1548, '2392': 1549, '2393': 1550, '2394': 1551, '2395': 1552, '2396': 1553, '2397': 1554, '2398': 1555, '2399': 1556, '2400': 1559, '2401': 1560, '2402': 1561, '2403': 1562, '2404': 1563, '2405': 1564, '2406': 1565, '2407': 1566, '2408': 1567, '2409': 1568, '2410': 1570, '2411': 1571, '2412': 1572, '2413': 1573, '2414': 1574, '2415': 1575, '2416': 1576, '2417': 1577, '2418': 1578, '2419': 1579, '2420': 1581, '2421': 1582, '2422': 1583, '2423': 1584, '2424': 1585, '2425': 1586, '2426': 1587, '2427': 1588, '2428': 1589, '2429': 1590, '2430': 1592, '2431': 1593, '2432': 1594, '2433': 1595, '2434': 1596, '2435': 1597, '2436': 1598, '2437': 1599, '2438': 1600, '2439': 1601, '2440': 1603, '2441': 1604, '2442': 1605, '2443': 1606, '2444': 1607, '2445': 1608, '2446': 1609, '2447': 1610, '2448': 1611, '2449': 1612, '2450': 1614, '2451': 1615, '2452': 1616, '2453': 1617, '2454': 1618, '2455': 1619, '2456': 1620, '2457': 1621, '2458': 1622, '2459': 1623, '2460': 1625, '2461': 1626, '2462': 1627, '2463': 1628, '2464': 1629, '2465': 1630, '2466': 1631, '2467': 1632, '2468': 1633, '2469': 1634, '2470': 1636, '2471': 1637, '2472': 1638, '2473': 1639, '2474': 1640, '2475': 1641, '2476': 1642, '2477': 1643, '2478': 1644, '2479': 1645, '2480': 1647, '2481': 1648, '2482': 1649, '2483': 1650, '2484': 1651, '2485': 1652, '2486': 1653, '2487': 1654, '2488': 1655, '2489': 1656, '2490': 1658, '2491': 1659, '2492': 1660, '2493': 1661, '2494': 1662, '2495': 1663, '2496': 1664, '2497': 1665, '2498': 1666, '2499': 1667, '2500': 1670, '2501': 1671, '2502': 1672, '2503': 1673, '2504': 1674, '2505': 1675, '2506': 1676, '2507': 1677, '2508': 1678, '2509': 1679, '2510': 1681, '2511': 1682, '2512': 1683, '2513': 1684, '2514': 1685, '2515': 1686, '2516': 1687, '2517': 1688, '2518': 1689, '2519': 1690, '2520': 1692, '2521': 1693, '2522': 1694, '2523': 1695, '2524': 1696, '2525': 1697, '2526': 1698, '2527': 1699, '2528': 1700, '2529': 1701, '2530': 1703, '2531': 1704, '2532': 1705, '2533': 1706, '2534': 1707, '2535': 1708, '2536': 1709, '2537': 1710, '2538': 1711, '2539': 1712, '2540': 1714, '2541': 1715, '2542': 1716, '2543': 1717, '2544': 1718, '2545': 1719, '2546': 1720, '2547': 1721, '2548': 1722, '2549': 1723, '2550': 1725, '2551': 1726, '2552': 1727, '2553': 1728, '2554': 1729, '2555': 1730, '2556': 1731, '2557': 1732, '2558': 1733, '2559': 1734, '2560': 1736, '2561': 1737, '2562': 1738, '2563': 1739, '2564': 1740, '2565': 1741, '2566': 1742, '2567': 1743, '2568': 1744, '2569': 1745, '2570': 1747, '2571': 1748, '2572': 1749, '2573': 1750, '2574': 1751, '2575': 1752, '2576': 1753, '2577': 1754, '2578': 1755, '2579': 1756, '2580': 1758, '2581': 1759, '2582': 1760, '2583': 1761, '2584': 1762, '2585': 1763, '2586': 1764, '2587': 1765, '2588': 1766, '2589': 1767, '2590': 1769, '2591': 1770, '2592': 1771, '2593': 1772, '2594': 1773, '2595': 1774, '2596': 1775, '2597': 1776, '2598': 1777, '2599': 1778, '2600': 1781, '2601': 1782, '2602': 1783, '2603': 1784, '2604': 1785, '2605': 1786, '2606': 1787, '2607': 1788, '2608': 1789, '2609': 1790, '2610': 1792, '2611': 1793, '2612': 1794, '2613': 1795, '2614': 1796, '2615': 1797, '2616': 1798, '2617': 1799, '2618': 1800, '2619': 1801, '2620': 1803, '2621': 1804, '2622': 1805, '2623': 1806, '2624': 1807, '2625': 1808, '2626': 1809, '2627': 1810, '2628': 1811, '2629': 1812, '2630': 1814, '2631': 1815, '2632': 1816, '2633': 1817, '2634': 1818, '2635': 1819, '2636': 1820, '2637': 1821, '2638': 1822, '2639': 1823, '2640': 1825, '2641': 1826, '2642': 1827, '2643': 1828, '2644': 1829, '2645': 1830, '2646': 1831, '2647': 1832, '2648': 1833, '2649': 1834, '2650': 1836, '2651': 1837, '2652': 1838, '2653': 1839, '2654': 1840, '2655': 1841, '2656': 1842, '2657': 1843, '2658': 1844, '2659': 1845, '2660': 1847, '2661': 1848, '2662': 1849, '2663': 1850, '2664': 1851, '2665': 1852, '2666': 1853, '2667': 1854, '2668': 1855, '2669': 1856, '2670': 1858, '2671': 1859, '2672': 1860, '2673': 1861, '2674': 1862, '2675': 1863, '2676': 1864, '2677': 1865, '2678': 1866, '2679': 1867, '2680': 1869, '2681': 1870, '2682': 1871, '2683': 1872, '2684': 1873, '2685': 1874, '2686': 1875, '2687': 1876, '2688': 1877, '2689': 1878, '2690': 1880, '2691': 1881, '2692': 1882, '2693': 1883, '2694': 1884, '2695': 1885, '2696': 1886, '2697': 1887, '2698': 1888, '2699': 1889, '2700': 1892, '2701': 1893, '2702': 1894, '2703': 1895, '2704': 1896, '2705': 1897, '2706': 1898, '2707': 1899, '2708': 1900, '2709': 1901, '2710': 1903, '2711': 1904, '2712': 1905, '2713': 1906, '2714': 1907, '2715': 1908, '2716': 1909, '2717': 1910, '2718': 1911, '2719': 1912, '2720': 1914, '2721': 1915, '2722': 1916, '2723': 1917, '2724': 1918, '2725': 1919, '2726': 1920, '2727': 1921, '2728': 1922, '2729': 1923, '2730': 1925, '2731': 1926, '2732': 1927, '2733': 1928, '2734': 1929, '2735': 1930, '2736': 1931, '2737': 1932, '2738': 1933, '2739': 1934, '2740': 1936, '2741': 1937, '2742': 1938, '2743': 1939, '2744': 1940, '2745': 1941, '2746': 1942, '2747': 1943, '2748': 1944, '2749': 1945, '2750': 1947, '2751': 1948, '2752': 1949, '2753': 1950, '2754': 1951, '2755': 1952, '2756': 1953, '2757': 1954, '2758': 1955, '2759': 1956, '2760': 1958, '2761': 1959, '2762': 1960, '2763': 1961, '2764': 1962, '2765': 1963, '2766': 1964, '2767': 1965, '2768': 1966, '2769': 1967, '2770': 1969, '2771': 1970, '2772': 1971, '2773': 1972, '2774': 1973, '2775': 1974, '2776': 1975, '2777': 1976, '2778': 1977, '2779': 1978, '2780': 1980, '2781': 1981, '2782': 1982, '2783': 1983, '2784': 1984, '2785': 1985, '2786': 1986, '2787': 1987, '2788': 1988, '2789': 1989, '2790': 1991, '2791': 1992, '2792': 1993, '2793': 1994, '2794': 1995, '2795': 1996, '2796': 1997, '2797': 1998, '2798': 1999, '2799': 2000, '2800': 2003, '2801': 2004, '2802': 2005, '2803': 2006, '2804': 2007, '2805': 2008, '2806': 2009, '2807': 2010, '2808': 2011, '2809': 2012, '2810': 2014, '2811': 2015, '2812': 2016, '2813': 2017, '2814': 2018, '2815': 2019, '2816': 2020, '2817': 2021, '2818': 2022, '2819': 2023, '2820': 2025, '2821': 2026, '2822': 2027, '2823': 2028, '2824': 2029, '2825': 2030, '2826': 2031, '2827': 2032, '2828': 2033, '2829': 2034, '2830': 2036, '2831': 2037, '2832': 2038, '2833': 2039, '2834': 2040, '2835': 2041, '2836': 2042, '2837': 2043, '2838': 2044, '2839': 2045, '2840': 2047, '2841': 2048, '2842': 2049, '2843': 2050, '2844': 2051, '2845': 2052, '2846': 2053, '2847': 2054, '2848': 2055, '2849': 2056, '2850': 2058, '2851': 2059, '2852': 2060, '2853': 2061, '2854': 2062, '2855': 2063, '2856': 2064, '2857': 2065, '2858': 2066, '2859': 2067, '2860': 2069, '2861': 2070, '2862': 2071, '2863': 2072, '2864': 2073, '2865': 2074, '2866': 2075, '2867': 2076, '2868': 2077, '2869': 2078, '2870': 2080, '2871': 2081, '2872': 2082, '2873': 2083, '2874': 2084, '2875': 2085, '2876': 2086, '2877': 2087, '2878': 2088, '2879': 2089, '2880': 2091, '2881': 2092, '2882': 2093, '2883': 2094, '2884': 2095, '2885': 2096, '2886': 2097, '2887': 2098, '2888': 2099, '2889': 2100, '2890': 2102, '2891': 2103, '2892': 2104, '2893': 2105, '2894': 2106, '2895': 2107, '2896': 2108, '2897': 2109, '2898': 2110, '2899': 2111, '2900': 2114, '2901': 2115, '2902': 2116, '2903': 2117, '2904': 2118, '2905': 2119, '2906': 2120, '2907': 2121, '2908': 2122, '2909': 2123, '2910': 2125, '2911': 2126, '2912': 2127, '2913': 2128, '2914': 2129, '2915': 2130, '2916': 2131, '2917': 2132, '2918': 2133, '2919': 2134, '2920': 2136, '2921': 2137, '2922': 2138, '2923': 2139, '2924': 2140, '2925': 2141, '2926': 2142, '2927': 2143, '2928': 2144, '2929': 2145, '2930': 2147, '2931': 2148, '2932': 2149, '2933': 2150, '2934': 2151, '2935': 2152, '2936': 2153, '2937': 2154, '2938': 2155, '2939': 2156, '2940': 2158, '2941': 2159, '2942': 2160, '2943': 2161, '2944': 2162, '2945': 2163, '2946': 2164, '2947': 2165, '2948': 2166, '2949': 2167, '2950': 2169, '2951': 2170, '2952': 2171, '2953': 2172, '2954': 2173, '2955': 2174, '2956': 2175, '2957': 2176, '2958': 2177, '2959': 2178, '2960': 2180, '2961': 2181, '2962': 2182, '2963': 2183, '2964': 2184, '2965': 2185, '2966': 2186, '2967': 2187, '2968': 2188, '2969': 2189, '2970': 2191, '2971': 2192, '2972': 2193, '2973': 2194, '2974': 2195, '2975': 2196, '2976': 2197, '2977': 2198, '2978': 2199, '2979': 2200, '2980': 2202, '2981': 2203, '2982': 2204, '2983': 2205, '2984': 2206, '2985': 2207, '2986': 2208, '2987': 2209, '2988': 2210, '2989': 2211, '2990': 2213, '2991': 2214, '2992': 2215, '2993': 2216, '2994': 2217, '2995': 2218, '2996': 2219, '2997': 2220, '2998': 2221, '2999': 2222, '3000': 2226, '3001': 2227, '3002': 2228, '3003': 2229, '3004': 2230, '3005': 2231, '3006': 2232, '3007': 2233, '3008': 2234, '3009': 2235, '3010': 2237, '3011': 2238, '3012': 2239, '3013': 2240, '3014': 2241, '3015': 2242, '3016': 2243, '3017': 2244, '3018': 2245, '3019': 2246, '3020': 2248, '3021': 2249, '3022': 2250, '3023': 2251, '3024': 2252, '3025': 2253, '3026': 2254, '3027': 2255, '3028': 2256, '3029': 2257, '3030': 2259, '3031': 2260, '3032': 2261, '3033': 2262, '3034': 2263, '3035': 2264, '3036': 2265, '3037': 2266, '3038': 2267, '3039': 2268, '3040': 2270, '3041': 2271, '3042': 2272, '3043': 2273, '3044': 2274, '3045': 2275, '3046': 2276, '3047': 2277, '3048': 2278, '3049': 2279, '3050': 2281, '3051': 2282, '3052': 2283, '3053': 2284, '3054': 2285, '3055': 2286, '3056': 2287, '3057': 2288, '3058': 2289, '3059': 2290, '3060': 2292, '3061': 2293, '3062': 2294, '3063': 2295, '3064': 2296, '3065': 2297, '3066': 2298, '3067': 2299, '3068': 2300, '3069': 2301, '3070': 2303, '3071': 2304, '3072': 2305, '3073': 2306, '3074': 2307, '3075': 2308, '3076': 2309, '3077': 2310, '3078': 2311, '3079': 2312, '3080': 2314, '3081': 2315, '3082': 2316, '3083': 2317, '3084': 2318, '3085': 2319, '3086': 2320, '3087': 2321, '3088': 2322, '3089': 2323, '3090': 2325, '3091': 2326, '3092': 2327, '3093': 2328, '3094': 2329, '3095': 2330, '3096': 2331, '3097': 2332, '3098': 2333, '3099': 2334, '3100': 2337, '3101': 2338, '3102': 2339, '3103': 2340, '3104': 2341, '3105': 2342, '3106': 2343, '3107': 2344, '3108': 2345, '3109': 2346, '3110': 2348, '3111': 2349, '3112': 2350, '3113': 2351, '3114': 2352, '3115': 2353, '3116': 2354, '3117': 2355, '3118': 2356, '3119': 2357, '3120': 2359, '3121': 2360, '3122': 2361, '3123': 2362, '3124': 2363, '3125': 2364, '3126': 2365, '3127': 2366, '3128': 2367, '3129': 2368, '3130': 2370, '3131': 2371, '3132': 2372, '3133': 2373, '3134': 2374, '3135': 2375, '3136': 2376, '3137': 2377, '3138': 2378, '3139': 2379, '3140': 2381, '3141': 2382, '3142': 2383, '3143': 2384, '3144': 2385, '3145': 2386, '3146': 2387, '3147': 2388, '3148': 2389, '3149': 2390, '3150': 2392, '3151': 2393, '3152': 2394, '3153': 2395, '3154': 2396, '3155': 2397, '3156': 2398, '3157': 2399, '3158': 2400, '3159': 2401, '3160': 2403, '3161': 2404, '3162': 2405, '3163': 2406, '3164': 2407, '3165': 2408, '3166': 2409, '3167': 2410, '3168': 2411, '3169': 2412, '3170': 2414, '3171': 2415, '3172': 2416, '3173': 2417, '3174': 2418, '3175': 2419, '3176': 2420, '3177': 2421, '3178': 2422, '3179': 2423, '3180': 2425, '3181': 2426, '3182': 2427, '3183': 2428, '3184': 2429, '3185': 2430, '3186': 2431, '3187': 2432, '3188': 2433, '3189': 2434, '3190': 2436, '3191': 2437, '3192': 2438, '3193': 2439, '3194': 2440, '3195': 2441, '3196': 2442, '3197': 2443, '3198': 2444, '3199': 2445, '3200': 2448, '3201': 2449, '3202': 2450, '3203': 2451, '3204': 2452, '3205': 2453, '3206': 2454, '3207': 2455, '3208': 2456, '3209': 2457, '3210': 2459, '3211': 2460, '3212': 2461, '3213': 2462, '3214': 2463, '3215': 2464, '3216': 2465, '3217': 2466, '3218': 2467, '3219': 2468, '3220': 2470, '3221': 2471, '3222': 2472, '3223': 2473, '3224': 2474, '3225': 2475, '3226': 2476, '3227': 2477, '3228': 2478, '3229': 2479, '3230': 2481, '3231': 2482, '3232': 2483, '3233': 2484, '3234': 2485, '3235': 2486, '3236': 2487, '3237': 2488, '3238': 2489, '3239': 2490, '3240': 2492, '3241': 2493, '3242': 2494, '3243': 2495, '3244': 2496, '3245': 2497, '3246': 2498, '3247': 2499, '3248': 2500, '3249': 2501, '3250': 2503, '3251': 2504, '3252': 2505, '3253': 2506, '3254': 2507, '3255': 2508, '3256': 2509, '3257': 2510, '3258': 2511, '3259': 2512, '3260': 2514, '3261': 2515, '3262': 2516, '3263': 2517, '3264': 2518, '3265': 2519, '3266': 2520, '3267': 2521, '3268': 2522, '3269': 2523, '3270': 2525, '3271': 2526, '3272': 2527, '3273': 2528, '3274': 2529, '3275': 2530, '3276': 2531, '3277': 2532, '3278': 2533, '3279': 2534, '3280': 2536, '3281': 2537, '3282': 2538, '3283': 2539, '3284': 2540, '3285': 2541, '3286': 2542, '3287': 2543, '3288': 2544, '3289': 2545, '3290': 2547, '3291': 2548, '3292': 2549, '3293': 2550, '3294': 2551, '3295': 2552, '3296': 2553, '3297': 2554, '3298': 2555, '3299': 2556, '3300': 2559, '3301': 2560, '3302': 2561, '3303': 2562, '3304': 2563, '3305': 2564, '3306': 2565, '3307': 2566, '3308': 2567, '3309': 2568, '3310': 2570, '3311': 2571, '3312': 2572, '3313': 2573, '3314': 2574, '3315': 2575, '3316': 2576, '3317': 2577, '3318': 2578, '3319': 2579, '3320': 2581, '3321': 2582, '3322': 2583, '3323': 2584, '3324': 2585, '3325': 2586, '3326': 2587, '3327': 2588, '3328': 2589, '3329': 2590, '3330': 2592, '3331': 2593, '3332': 2594, '3333': 2595, '3334': 2596, '3335': 2597, '3336': 2598, '3337': 2599, '3338': 2600, '3339': 2601, '3340': 2603, '3341': 2604, '3342': 2605, '3343': 2606, '3344': 2607, '3345': 2608, '3346': 2609, '3347': 2610, '3348': 2611, '3349': 2612, '3350': 2614, '3351': 2615, '3352': 2616, '3353': 2617, '3354': 2618, '3355': 2619, '3356': 2620, '3357': 2621, '3358': 2622, '3359': 2623, '3360': 2625, '3361': 2626, '3362': 2627, '3363': 2628, '3364': 2629, '3365': 2630, '3366': 2631, '3367': 2632, '3368': 2633, '3369': 2634, '3370': 2636, '3371': 2637, '3372': 2638, '3373': 2639, '3374': 2640, '3375': 2641, '3376': 2642, '3377': 2643, '3378': 2644, '3379': 2645, '3380': 2647, '3381': 2648, '3382': 2649, '3383': 2650, '3384': 2651, '3385': 2652, '3386': 2653, '3387': 2654, '3388': 2655, '3389': 2656, '3390': 2658, '3391': 2659, '3392': 2660, '3393': 2661, '3394': 2662, '3395': 2663, '3396': 2664, '3397': 2665, '3398': 2666, '3399': 2667, '3400': 2670, '3401': 2671, '3402': 2672, '3403': 2673, '3404': 2674, '3405': 2675, '3406': 2676, '3407': 2677, '3408': 2678, '3409': 2679, '3410': 2681, '3411': 2682, '3412': 2683, '3413': 2684, '3414': 2685, '3415': 2686, '3416': 2687, '3417': 2688, '3418': 2689, '3419': 2690, '3420': 2692, '3421': 2693, '3422': 2694, '3423': 2695, '3424': 2696, '3425': 2697, '3426': 2698, '3427': 2699, '3428': 2700, '3429': 2701, '3430': 2703, '3431': 2704, '3432': 2705, '3433': 2706, '3434': 2707, '3435': 2708, '3436': 2709, '3437': 2710, '3438': 2711, '3439': 2712, '3440': 2714, '3441': 2715, '3442': 2716, '3443': 2717, '3444': 2718, '3445': 2719, '3446': 2720, '3447': 2721, '3448': 2722, '3449': 2723, '3450': 2725, '3451': 2726, '3452': 2727, '3453': 2728, '3454': 2729, '3455': 2730, '3456': 2731, '3457': 2732, '3458': 2733, '3459': 2734, '3460': 2736, '3461': 2737, '3462': 2738, '3463': 2739, '3464': 2740, '3465': 2741, '3466': 2742, '3467': 2743, '3468': 2744, '3469': 2745, '3470': 2747, '3471': 2748, '3472': 2749, '3473': 2750, '3474': 2751, '3475': 2752, '3476': 2753, '3477': 2754, '3478': 2755, '3479': 2756, '3480': 2758, '3481': 2759, '3482': 2760, '3483': 2761, '3484': 2762, '3485': 2763, '3486': 2764, '3487': 2765, '3488': 2766, '3489': 2767, '3490': 2769, '3491': 2770, '3492': 2771, '3493': 2772, '3494': 2773, '3495': 2774, '3496': 2775, '3497': 2776, '3498': 2777, '3499': 2778, '3500': 2781, '3501': 2782, '3502': 2783, '3503': 2784, '3504': 2785, '3505': 2786, '3506': 2787, '3507': 2788, '3508': 2789, '3509': 2790, '3510': 2792, '3511': 2793, '3512': 2794, '3513': 2795, '3514': 2796, '3515': 2797, '3516': 2798, '3517': 2799, '3518': 2800, '3519': 2801, '3520': 2803, '3521': 2804, '3522': 2805, '3523': 2806, '3524': 2807, '3525': 2808, '3526': 2809, '3527': 2810, '3528': 2811, '3529': 2812, '3530': 2814, '3531': 2815, '3532': 2816, '3533': 2817, '3534': 2818, '3535': 2819, '3536': 2820, '3537': 2821, '3538': 2822, '3539': 2823, '3540': 2825, '3541': 2826, '3542': 2827, '3543': 2828, '3544': 2829, '3545': 2830, '3546': 2831, '3547': 2832, '3548': 2833, '3549': 2834, '3550': 2836, '3551': 2837, '3552': 2838, '3553': 2839, '3554': 2840, '3555': 2841, '3556': 2842, '3557': 2843, '3558': 2844, '3559': 2845, '3560': 2847, '3561': 2848, '3562': 2849, '3563': 2850, '3564': 2851, '3565': 2852, '3566': 2853, '3567': 2854, '3568': 2855, '3569': 2856, '3570': 2858, '3571': 2859, '3572': 2860, '3573': 2861, '3574': 2862, '3575': 2863, '3576': 2864, '3577': 2865, '3578': 2866, '3579': 2867, '3580': 2869, '3581': 2870, '3582': 2871, '3583': 2872, '3584': 2873, '3585': 2874, '3586': 2875, '3587': 2876, '3588': 2877, '3589': 2878, '3590': 2880, '3591': 2881, '3592': 2882, '3593': 2883, '3594': 2884, '3595': 2885, '3596': 2886, '3597': 2887, '3598': 2888, '3599': 2889, '3600': 2892, '3601': 2893, '3602': 2894, '3603': 2895, '3604': 2896, '3605': 2897, '3606': 2898, '3607': 2899, '3608': 2900, '3609': 2901, '3610': 2903, '3611': 2904, '3612': 2905, '3613': 2906, '3614': 2907, '3615': 2908, '3616': 2909, '3617': 2910, '3618': 2911, '3619': 2912, '3620': 2914, '3621': 2915, '3622': 2916, '3623': 2917, '3624': 2918, '3625': 2919, '3626': 2920, '3627': 2921, '3628': 2922, '3629': 2923, '3630': 2925, '3631': 2926, '3632': 2927, '3633': 2928, '3634': 2929, '3635': 2930, '3636': 2931, '3637': 2932, '3638': 2933, '3639': 2934, '3640': 2936, '3641': 2937, '3642': 2938, '3643': 2939, '3644': 2940, '3645': 2941, '3646': 2942, '3647': 2943, '3648': 2944, '3649': 2945, '3650': 2947, '3651': 2948, '3652': 2949, '3653': 2950, '3654': 2951, '3655': 2952, '3656': 2953, '3657': 2954, '3658': 2955, '3659': 2956, '3660': 2958, '3661': 2959, '3662': 2960, '3663': 2961, '3664': 2962, '3665': 2963, '3666': 2964, '3667': 2965, '3668': 2966, '3669': 2967, '3670': 2969, '3671': 2970, '3672': 2971, '3673': 2972, '3674': 2973, '3675': 2974, '3676': 2975, '3677': 2976, '3678': 2977, '3679': 2978, '3680': 2980, '3681': 2981, '3682': 2982, '3683': 2983, '3684': 2984, '3685': 2985, '3686': 2986, '3687': 2987, '3688': 2988, '3689': 2989, '3690': 2991, '3691': 2992, '3692': 2993, '3693': 2994, '3694': 2995, '3695': 2996, '3696': 2997, '3697': 2998, '3698': 2999, '3699': 3000, '3700': 3003, '3701': 3004, '3702': 3005, '3703': 3006, '3704': 3007, '3705': 3008, '3706': 3009, '3707': 3010, '3708': 3011, '3709': 3012, '3710': 3014, '3711': 3015, '3712': 3016, '3713': 3017, '3714': 3018, '3715': 3019, '3716': 3020, '3717': 3021, '3718': 3022, '3719': 3023, '3720': 3025, '3721': 3026, '3722': 3027, '3723': 3028, '3724': 3029, '3725': 3030, '3726': 3031, '3727': 3032, '3728': 3033, '3729': 3034, '3730': 3036, '3731': 3037, '3732': 3038, '3733': 3039, '3734': 3040, '3735': 3041, '3736': 3042, '3737': 3043, '3738': 3044, '3739': 3045, '3740': 3047, '3741': 3048, '3742': 3049, '3743': 3050, '3744': 3051, '3745': 3052, '3746': 3053, '3747': 3054, '3748': 3055, '3749': 3056, '3750': 3058, '3751': 3059, '3752': 3060, '3753': 3061, '3754': 3062, '3755': 3063, '3756': 3064, '3757': 3065, '3758': 3066, '3759': 3067, '3760': 3069, '3761': 3070, '3762': 3071, '3763': 3072, '3764': 3073, '3765': 3074, '3766': 3075, '3767': 3076, '3768': 3077, '3769': 3078, '3770': 3080, '3771': 3081, '3772': 3082, '3773': 3083, '3774': 3084, '3775': 3085, '3776': 3086, '3777': 3087, '3778': 3088, '3779': 3089, '3780': 3091, '3781': 3092, '3782': 3093, '3783': 3094, '3784': 3095, '3785': 3096, '3786': 3097, '3787': 3098, '3788': 3099, '3789': 3100, '3790': 3102, '3791': 3103, '3792': 3104, '3793': 3105, '3794': 3106, '3795': 3107, '3796': 3108, '3797': 3109, '3798': 3110, '3799': 3111, '3800': 3114, '3801': 3115, '3802': 3116, '3803': 3117, '3804': 3118, '3805': 3119, '3806': 3120, '3807': 3121, '3808': 3122, '3809': 3123, '3810': 3125, '3811': 3126, '3812': 3127, '3813': 3128, '3814': 3129, '3815': 3130, '3816': 3131, '3817': 3132, '3818': 3133, '3819': 3134, '3820': 3136, '3821': 3137, '3822': 3138, '3823': 3139, '3824': 3140, '3825': 3141, '3826': 3142, '3827': 3143, '3828': 3144, '3829': 3145, '3830': 3147, '3831': 3148, '3832': 3149, '3833': 3150, '3834': 3151, '3835': 3152, '3836': 3153, '3837': 3154, '3838': 3155, '3839': 3156, '3840': 3158, '3841': 3159, '3842': 3160, '3843': 3161, '3844': 3162, '3845': 3163, '3846': 3164, '3847': 3165, '3848': 3166, '3849': 3167, '3850': 3169, '3851': 3170, '3852': 3171, '3853': 3172, '3854': 3173, '3855': 3174, '3856': 3175, '3857': 3176, '3858': 3177, '3859': 3178, '3860': 3180, '3861': 3181, '3862': 3182, '3863': 3183, '3864': 3184, '3865': 3185, '3866': 3186, '3867': 3187, '3868': 3188, '3869': 3189, '3870': 3191, '3871': 3192, '3872': 3193, '3873': 3194, '3874': 3195, '3875': 3196, '3876': 3197, '3877': 3198, '3878': 3199, '3879': 3200, '3880': 3202, '3881': 3203, '3882': 3204, '3883': 3205, '3884': 3206, '3885': 3207, '3886': 3208, '3887': 3209, '3888': 3210, '3889': 3211, '3890': 3213, '3891': 3214, '3892': 3215, '3893': 3216, '3894': 3217, '3895': 3218, '3896': 3219, '3897': 3220, '3898': 3221, '3899': 3222, '3900': 3225, '3901': 3226, '3902': 3227, '3903': 3228, '3904': 3229, '3905': 3230, '3906': 3231, '3907': 3232, '3908': 3233, '3909': 3234, '3910': 3236, '3911': 3237, '3912': 3238, '3913': 3239, '3914': 3240, '3915': 3241, '3916': 3242, '3917': 3243, '3918': 3244, '3919': 3245, '3920': 3247, '3921': 3248, '3922': 3249, '3923': 3250, '3924': 3251, '3925': 3252, '3926': 3253, '3927': 3254, '3928': 3255, '3929': 3256, '3930': 3258, '3931': 3259, '3932': 3260, '3933': 3261, '3934': 3262, '3935': 3263, '3936': 3264, '3937': 3265, '3938': 3266, '3939': 3267, '3940': 3269, '3941': 3270, '3942': 3271, '3943': 3272, '3944': 3273, '3945': 3274, '3946': 3275, '3947': 3276, '3948': 3277, '3949': 3278, '3950': 3280, '3951': 3281, '3952': 3282, '3953': 3283, '3954': 3284, '3955': 3285, '3956': 3286, '3957': 3287, '3958': 3288, '3959': 3289, '3960': 3291, '3961': 3292, '3962': 3293, '3963': 3294, '3964': 3295, '3965': 3296, '3966': 3297, '3967': 3298, '3968': 3299, '3969': 3300, '3970': 3302, '3971': 3303, '3972': 3304, '3973': 3305, '3974': 3306, '3975': 3307, '3976': 3308, '3977': 3309, '3978': 3310, '3979': 3311, '3980': 3313, '3981': 3314, '3982': 3315, '3983': 3316, '3984': 3317, '3985': 3318, '3986': 3319, '3987': 3320, '3988': 3321, '3989': 3322, '3990': 3324, '3991': 3325, '3992': 3326, '3993': 3327, '3994': 3328, '3995': 3329, '3996': 3330, '3997': 3331, '3998': 3332, '3999': 3333, '4000': 3337, '4001': 3338, '4002': 3339, '4003': 3340, '4004': 3341, '4005': 3342, '4006': 3343, '4007': 3344, '4008': 3345, '4009': 3346, '4010': 3348, '4011': 3349, '4012': 3350, '4013': 3351, '4014': 3352, '4015': 3353, '4016': 3354, '4017': 3355, '4018': 3356, '4019': 3357, '4020': 3359, '4021': 3360, '4022': 3361, '4023': 3362, '4024': 3363, '4025': 3364, '4026': 3365, '4027': 3366, '4028': 3367, '4029': 3368, '4030': 3370, '4031': 3371, '4032': 3372, '4033': 3373, '4034': 3374, '4035': 3375, '4036': 3376, '4037': 3377, '4038': 3378, '4039': 3379, '4040': 3381, '4041': 3382, '4042': 3383, '4043': 3384, '4044': 3385, '4045': 3386, '4046': 3387, '4047': 3388, '4048': 3389, '4049': 3390, '4050': 3392, '4051': 3393, '4052': 3394, '4053': 3395, '4054': 3396, '4055': 3397, '4056': 3398, '4057': 3399, '4058': 3400, '4059': 3401, '4060': 3403, '4061': 3404, '4062': 3405, '4063': 3406, '4064': 3407, '4065': 3408, '4066': 3409, '4067': 3410, '4068': 3411, '4069': 3412, '4070': 3414, '4071': 3415, '4072': 3416, '4073': 3417, '4074': 3418, '4075': 3419, '4076': 3420, '4077': 3421, '4078': 3422, '4079': 3423, '4080': 3425, '4081': 3426, '4082': 3427, '4083': 3428, '4084': 3429, '4085': 3430, '4086': 3431, '4087': 3432, '4088': 3433, '4089': 3434, '4090': 3436, '4091': 3437, '4092': 3438, '4093': 3439, '4094': 3440, '4095': 3441, '4096': 3442, '4097': 3443, '4098': 3444, '4099': 3445, '4100': 3448, '4101': 3449, '4102': 3450, '4103': 3451, '4104': 3452, '4105': 3453, '4106': 3454, '4107': 3455, '4108': 3456, '4109': 3457, '4110': 3459, '4111': 3460, '4112': 3461, '4113': 3462, '4114': 3463, '4115': 3464, '4116': 3465, '4117': 3466, '4118': 3467, '4119': 3468, '4120': 3470, '4121': 3471, '4122': 3472, '4123': 3473, '4124': 3474, '4125': 3475, '4126': 3476, '4127': 3477, '4128': 3478, '4129': 3479, '4130': 3481, '4131': 3482, '4132': 3483, '4133': 3484, '4134': 3485, '4135': 3486, '4136': 3487, '4137': 3488, '4138': 3489, '4139': 3490, '4140': 3492, '4141': 3493, '4142': 3494, '4143': 3495, '4144': 3496, '4145': 3497, '4146': 3498, '4147': 3499, '4148': 3500, '4149': 3501, '4150': 3503, '4151': 3504, '4152': 3505, '4153': 3506, '4154': 3507, '4155': 3508, '4156': 3509, '4157': 3510, '4158': 3511, '4159': 3512, '4160': 3514, '4161': 3515, '4162': 3516, '4163': 3517, '4164': 3518, '4165': 3519, '4166': 3520, '4167': 3521, '4168': 3522, '4169': 3523, '4170': 3525, '4171': 3526, '4172': 3527, '4173': 3528, '4174': 3529, '4175': 3530, '4176': 3531, '4177': 3532, '4178': 3533, '4179': 3534, '4180': 3536, '4181': 3537, '4182': 3538, '4183': 3539, '4184': 3540, '4185': 3541, '4186': 3542, '4187': 3543, '4188': 3544, '4189': 3545, '4190': 3547, '4191': 3548, '4192': 3549, '4193': 3550, '4194': 3551, '4195': 3552, '4196': 3553, '4197': 3554, '4198': 3555, '4199': 3556, '4200': 3559, '4201': 3560, '4202': 3561, '4203': 3562, '4204': 3563, '4205': 3564, '4206': 3565, '4207': 3566, '4208': 3567, '4209': 3568, '4210': 3570, '4211': 3571, '4212': 3572, '4213': 3573, '4214': 3574, '4215': 3575, '4216': 3576, '4217': 3577, '4218': 3578, '4219': 3579, '4220': 3581, '4221': 3582, '4222': 3583, '4223': 3584, '4224': 3585, '4225': 3586, '4226': 3587, '4227': 3588, '4228': 3589, '4229': 3590, '4230': 3592, '4231': 3593, '4232': 3594, '4233': 3595, '4234': 3596, '4235': 3597, '4236': 3598, '4237': 3599, '4238': 3600, '4239': 3601, '4240': 3603, '4241': 3604, '4242': 3605, '4243': 3606, '4244': 3607, '4245': 3608, '4246': 3609, '4247': 3610, '4248': 3611, '4249': 3612, '4250': 3614, '4251': 3615, '4252': 3616, '4253': 3617, '4254': 3618, '4255': 3619, '4256': 3620, '4257': 3621, '4258': 3622, '4259': 3623, '4260': 3625, '4261': 3626, '4262': 3627, '4263': 3628, '4264': 3629, '4265': 3630, '4266': 3631, '4267': 3632, '4268': 3633, '4269': 3634, '4270': 3636, '4271': 3637, '4272': 3638, '4273': 3639, '4274': 3640, '4275': 3641, '4276': 3642, '4277': 3643, '4278': 3644, '4279': 3645, '4280': 3647, '4281': 3648, '4282': 3649, '4283': 3650, '4284': 3651, '4285': 3652, '4286': 3653, '4287': 3654, '4288': 3655, '4289': 3656, '4290': 3658, '4291': 3659, '4292': 3660, '4293': 3661, '4294': 3662, '4295': 3663, '4296': 3664, '4297': 3665, '4298': 3666, '4299': 3667, '4300': 3670, '4301': 3671, '4302': 3672, '4303': 3673, '4304': 3674, '4305': 3675, '4306': 3676, '4307': 3677, '4308': 3678, '4309': 3679, '4310': 3681, '4311': 3682, '4312': 3683, '4313': 3684, '4314': 3685, '4315': 3686, '4316': 3687, '4317': 3688, '4318': 3689, '4319': 3690, '4320': 3692, '4321': 3693, '4322': 3694, '4323': 3695, '4324': 3696, '4325': 3697, '4326': 3698, '4327': 3699, '4328': 3700, '4329': 3701, '4330': 3703, '4331': 3704, '4332': 3705, '4333': 3706, '4334': 3707, '4335': 3708, '4336': 3709, '4337': 3710, '4338': 3711, '4339': 3712, '4340': 3714, '4341': 3715, '4342': 3716, '4343': 3717, '4344': 3718, '4345': 3719, '4346': 3720, '4347': 3721, '4348': 3722, '4349': 3723, '4350': 3725, '4351': 3726, '4352': 3727, '4353': 3728, '4354': 3729, '4355': 3730, '4356': 3731, '4357': 3732, '4358': 3733, '4359': 3734, '4360': 3736, '4361': 3737, '4362': 3738, '4363': 3739, '4364': 3740, '4365': 3741, '4366': 3742, '4367': 3743, '4368': 3744, '4369': 3745, '4370': 3747, '4371': 3748, '4372': 3749, '4373': 3750, '4374': 3751, '4375': 3752, '4376': 3753, '4377': 3754, '4378': 3755, '4379': 3756, '4380': 3758, '4381': 3759, '4382': 3760, '4383': 3761, '4384': 3762, '4385': 3763, '4386': 3764, '4387': 3765, '4388': 3766, '4389': 3767, '4390': 3769, '4391': 3770, '4392': 3771, '4393': 3772, '4394': 3773, '4395': 3774, '4396': 3775, '4397': 3776, '4398': 3777, '4399': 3778, '4400': 3781, '4401': 3782, '4402': 3783, '4403': 3784, '4404': 3785, '4405': 3786, '4406': 3787, '4407': 3788, '4408': 3789, '4409': 3790, '4410': 3792, '4411': 3793, '4412': 3794, '4413': 3795, '4414': 3796, '4415': 3797, '4416': 3798, '4417': 3799, '4418': 3800, '4419': 3801, '4420': 3803, '4421': 3804, '4422': 3805, '4423': 3806, '4424': 3807, '4425': 3808, '4426': 3809, '4427': 3810, '4428': 3811, '4429': 3812, '4430': 3814, '4431': 3815, '4432': 3816, '4433': 3817, '4434': 3818, '4435': 3819, '4436': 3820, '4437': 3821, '4438': 3822, '4439': 3823, '4440': 3825, '4441': 3826, '4442': 3827, '4443': 3828, '4444': 3829, '4445': 3830, '4446': 3831, '4447': 3832, '4448': 3833, '4449': 3834, '4450': 3836, '4451': 3837, '4452': 3838, '4453': 3839, '4454': 3840, '4455': 3841, '4456': 3842, '4457': 3843, '4458': 3844, '4459': 3845, '4460': 3847, '4461': 3848, '4462': 3849, '4463': 3850, '4464': 3851, '4465': 3852, '4466': 3853, '4467': 3854, '4468': 3855, '4469': 3856, '4470': 3858, '4471': 3859, '4472': 3860, '4473': 3861, '4474': 3862, '4475': 3863, '4476': 3864, '4477': 3865, '4478': 3866, '4479': 3867, '4480': 3869, '4481': 3870, '4482': 3871, '4483': 3872, '4484': 3873, '4485': 3874, '4486': 3875, '4487': 3876, '4488': 3877, '4489': 3878, '4490': 3880, '4491': 3881, '4492': 3882, '4493': 3883, '4494': 3884, '4495': 3885, '4496': 3886, '4497': 3887, '4498': 3888, '4499': 3889, '4500': 3892, '4501': 3893, '4502': 3894, '4503': 3895, '4504': 3896, '4505': 3897, '4506': 3898, '4507': 3899, '4508': 3900, '4509': 3901, '4510': 3903, '4511': 3904, '4512': 3905, '4513': 3906, '4514': 3907, '4515': 3908, '4516': 3909, '4517': 3910, '4518': 3911, '4519': 3912, '4520': 3914, '4521': 3915, '4522': 3916, '4523': 3917, '4524': 3918, '4525': 3919, '4526': 3920, '4527': 3921, '4528': 3922, '4529': 3923, '4530': 3925, '4531': 3926, '4532': 3927, '4533': 3928, '4534': 3929, '4535': 3930, '4536': 3931, '4537': 3932, '4538': 3933, '4539': 3934, '4540': 3936, '4541': 3937, '4542': 3938, '4543': 3939, '4544': 3940, '4545': 3941, '4546': 3942, '4547': 3943, '4548': 3944, '4549': 3945, '4550': 3947, '4551': 3948, '4552': 3949, '4553': 3950, '4554': 3951, '4555': 3952, '4556': 3953, '4557': 3954, '4558': 3955, '4559': 3956, '4560': 3958, '4561': 3959, '4562': 3960, '4563': 3961, '4564': 3962, '4565': 3963, '4566': 3964, '4567': 3965, '4568': 3966, '4569': 3967, '4570': 3969, '4571': 3970, '4572': 3971, '4573': 3972, '4574': 3973, '4575': 3974, '4576': 3975, '4577': 3976, '4578': 3977, '4579': 3978, '4580': 3980, '4581': 3981, '4582': 3982, '4583': 3983, '4584': 3984, '4585': 3985, '4586': 3986, '4587': 3987, '4588': 3988, '4589': 3989, '4590': 3991, '4591': 3992, '4592': 3993, '4593': 3994, '4594': 3995, '4595': 3996, '4596': 3997, '4597': 3998, '4598': 3999, '4599': 4000, '4600': 4003, '4601': 4004, '4602': 4005, '4603': 4006, '4604': 4007, '4605': 4008, '4606': 4009, '4607': 4010, '4608': 4011, '4609': 4012, '4610': 4014, '4611': 4015, '4612': 4016, '4613': 4017, '4614': 4018, '4615': 4019, '4616': 4020, '4617': 4021, '4618': 4022, '4619': 4023, '4620': 4025, '4621': 4026, '4622': 4027, '4623': 4028, '4624': 4029, '4625': 4030, '4626': 4031, '4627': 4032, '4628': 4033, '4629': 4034, '4630': 4036, '4631': 4037, '4632': 4038, '4633': 4039, '4634': 4040, '4635': 4041, '4636': 4042, '4637': 4043, '4638': 4044, '4639': 4045, '4640': 4047, '4641': 4048, '4642': 4049, '4643': 4050, '4644': 4051, '4645': 4052, '4646': 4053, '4647': 4054, '4648': 4055, '4649': 4056, '4650': 4058, '4651': 4059, '4652': 4060, '4653': 4061, '4654': 4062, '4655': 4063, '4656': 4064, '4657': 4065, '4658': 4066, '4659': 4067, '4660': 4069, '4661': 4070, '4662': 4071, '4663': 4072, '4664': 4073, '4665': 4074, '4666': 4075, '4667': 4076, '4668': 4077, '4669': 4078, '4670': 4080, '4671': 4081, '4672': 4082, '4673': 4083, '4674': 4084, '4675': 4085, '4676': 4086, '4677': 4087, '4678': 4088, '4679': 4089, '4680': 4091, '4681': 4092, '4682': 4093, '4683': 4094, '4684': 4095, '4685': 4096, '4686': 4097, '4687': 4098, '4688': 4099, '4689': 4100, '4690': 4102, '4691': 4103, '4692': 4104, '4693': 4105, '4694': 4106, '4695': 4107, '4696': 4108, '4697': 4109, '4698': 4110, '4699': 4111, '4700': 4114, '4701': 4115, '4702': 4116, '4703': 4117, '4704': 4118, '4705': 4119, '4706': 4120, '4707': 4121, '4708': 4122, '4709': 4123, '4710': 4125, '4711': 4126, '4712': 4127, '4713': 4128, '4714': 4129, '4715': 4130, '4716': 4131, '4717': 4132, '4718': 4133, '4719': 4134, '4720': 4136, '4721': 4137, '4722': 4138, '4723': 4139, '4724': 4140, '4725': 4141, '4726': 4142, '4727': 4143, '4728': 4144, '4729': 4145, '4730': 4147, '4731': 4148, '4732': 4149, '4733': 4150, '4734': 4151, '4735': 4152, '4736': 4153, '4737': 4154, '4738': 4155, '4739': 4156, '4740': 4158, '4741': 4159, '4742': 4160, '4743': 4161, '4744': 4162, '4745': 4163, '4746': 4164, '4747': 4165, '4748': 4166, '4749': 4167, '4750': 4169, '4751': 4170, '4752': 4171, '4753': 4172, '4754': 4173, '4755': 4174, '4756': 4175, '4757': 4176, '4758': 4177, '4759': 4178, '4760': 4180, '4761': 4181, '4762': 4182, '4763': 4183, '4764': 4184, '4765': 4185, '4766': 4186, '4767': 4187, '4768': 4188, '4769': 4189, '4770': 4191, '4771': 4192, '4772': 4193, '4773': 4194, '4774': 4195, '4775': 4196, '4776': 4197, '4777': 4198, '4778': 4199, '4779': 4200, '4780': 4202, '4781': 4203, '4782': 4204, '4783': 4205, '4784': 4206, '4785': 4207, '4786': 4208, '4787': 4209, '4788': 4210, '4789': 4211, '4790': 4213, '4791': 4214, '4792': 4215, '4793': 4216, '4794': 4217, '4795': 4218, '4796': 4219, '4797': 4220, '4798': 4221, '4799': 4222, '4800': 4225, '4801': 4226, '4802': 4227, '4803': 4228, '4804': 4229, '4805': 4230, '4806': 4231, '4807': 4232, '4808': 4233, '4809': 4234, '4810': 4236, '4811': 4237, '4812': 4238, '4813': 4239, '4814': 4240, '4815': 4241, '4816': 4242, '4817': 4243, '4818': 4244, '4819': 4245, '4820': 4247, '4821': 4248, '4822': 4249, '4823': 4250, '4824': 4251, '4825': 4252, '4826': 4253, '4827': 4254, '4828': 4255, '4829': 4256, '4830': 4258, '4831': 4259, '4832': 4260, '4833': 4261, '4834': 4262, '4835': 4263, '4836': 4264, '4837': 4265, '4838': 4266, '4839': 4267, '4840': 4269, '4841': 4270, '4842': 4271, '4843': 4272, '4844': 4273, '4845': 4274, '4846': 4275, '4847': 4276, '4848': 4277, '4849': 4278, '4850': 4280, '4851': 4281, '4852': 4282, '4853': 4283, '4854': 4284, '4855': 4285, '4856': 4286, '4857': 4287, '4858': 4288, '4859': 4289, '4860': 4291, '4861': 4292, '4862': 4293, '4863': 4294, '4864': 4295, '4865': 4296, '4866': 4297, '4867': 4298, '4868': 4299, '4869': 4300, '4870': 4302, '4871': 4303, '4872': 4304, '4873': 4305, '4874': 4306, '4875': 4307, '4876': 4308, '4877': 4309, '4878': 4310, '4879': 4311, '4880': 4313, '4881': 4314, '4882': 4315, '4883': 4316, '4884': 4317, '4885': 4318, '4886': 4319, '4887': 4320, '4888': 4321, '4889': 4322, '4890': 4324, '4891': 4325, '4892': 4326, '4893': 4327, '4894': 4328, '4895': 4329, '4896': 4330, '4897': 4331, '4898': 4332, '4899': 4333, '4900': 4336, '4901': 4337, '4902': 4338, '4903': 4339, '4904': 4340, '4905': 4341, '4906': 4342, '4907': 4343, '4908': 4344, '4909': 4345, '4910': 4347, '4911': 4348, '4912': 4349, '4913': 4350, '4914': 4351, '4915': 4352, '4916': 4353, '4917': 4354, '4918': 4355, '4919': 4356, '4920': 4358, '4921': 4359, '4922': 4360, '4923': 4361, '4924': 4362, '4925': 4363, '4926': 4364, '4927': 4365, '4928': 4366, '4929': 4367, '4930': 4369, '4931': 4370, '4932': 4371, '4933': 4372, '4934': 4373, '4935': 4374, '4936': 4375, '4937': 4376, '4938': 4377, '4939': 4378, '4940': 4380, '4941': 4381, '4942': 4382, '4943': 4383, '4944': 4384, '4945': 4385, '4946': 4386, '4947': 4387, '4948': 4388, '4949': 4389, '4950': 4391, '4951': 4392, '4952': 4393, '4953': 4394, '4954': 4395, '4955': 4396, '4956': 4397, '4957': 4398, '4958': 4399, '4959': 4400, '4960': 4402, '4961': 4403, '4962': 4404, '4963': 4405, '4964': 4406, '4965': 4407, '4966': 4408, '4967': 4409, '4968': 4410, '4969': 4411, '4970': 4413, '4971': 4414, '4972': 4415, '4973': 4416, '4974': 4417, '4975': 4418, '4976': 4419, '4977': 4420, '4978': 4421, '4979': 4422, '4980': 4424, '4981': 4425, '4982': 4426, '4983': 4427, '4984': 4428, '4985': 4429, '4986': 4430, '4987': 4431, '4988': 4432, '4989': 4433, '4990': 4435, '4991': 4436, '4992': 4437, '4993': 4438, '4994': 4439, '4995': 4440, '4996': 4441, '4997': 4442, '4998': 4443, '4999': 4444}\n",
      "Encoded Document is:\n",
      "[[32 14  3 ...  0  0  0]\n",
      " [ 2 11  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 7  1  0 ...  0  0  0]\n",
      " [27 18  6 ...  0  0  0]]\n",
      "Shape of X: (1000, 5000)\n",
      "Shape of y: (0,)\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "label = []\n",
    "\n",
    "with open(\"../../data/test_set.json\") as f:\n",
    "    for line in f:\n",
    "        # read line by line\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # add values\n",
    "        text.append(data[\"text\"])\n",
    "        #label.append(data[\"label\"])\n",
    "vector_sample = np.arange(5000)\n",
    "\n",
    "def toStr(n):\n",
    "   return str(n)\n",
    "\n",
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer(preprocessor= toStr, analyzer=\"word\", token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "vectorizer.fit(vector_sample)\n",
    "\n",
    "# Printing the identified Unique words along with their indices\n",
    "print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "\n",
    "# Encode the Document\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "# Summarizing the Encoded Texts\n",
    "print(\"Encoded Document is:\")\n",
    "print(vector.toarray())\n",
    "\n",
    "X_predict = vector.toarray()\n",
    "y_predict = np.array(label).ravel()\n",
    "\n",
    "print(\"Shape of X:\", X_predict.shape)\n",
    "print(\"Shape of y:\", y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32, 14,  3, ...,  0,  0,  0],\n",
       "       [ 2, 11,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 7,  1,  0, ...,  0,  0,  0],\n",
       "       [27, 18,  6, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "loaded_model = TextClassifier(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Load the saved weights\n",
    "loaded_model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    test_tensor = torch.tensor(X_predict, dtype=torch.float32)  # Assuming you've got your test data in X_test\n",
    "    outputs = loaded_model(test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # Now `predicted` contains the predicted labels for the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Your tensor\n",
    "tensor_data = predicted  # Fill in with your tensor data\n",
    "\n",
    "# Convert tensor to list\n",
    "data_list = tensor_data.tolist()\n",
    "\n",
    "# Write to CSV\n",
    "with open('result_NN_domain2.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"class\"])\n",
    "    for idx, value in enumerate(data_list):\n",
    "        writer.writerow([idx, value])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback:\n",
    "1. domain 2 is imbalanced and need more preprocessing (sampling etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "### Strategy\n",
    "\n",
    "\n",
    "1. **Resampling:** Consider using techniques like oversampling the minority class, undersampling the majority class, or using Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset.\n",
    "\n",
    "2. **Different Metrics:** Evaluate your model using precision, recall, F1-score, or AUC-ROC to get a clearer picture of how it's performing for each class.\n",
    "\n",
    "3. **Adjust Class Weights:** Many models in PyTorch, like `nn.CrossEntropyLoss`, allow you to set class weights. This can help in penalizing misclassifications of the minority class more than the majority class.\n",
    "\n",
    "4. **Regularization:** Regularization techniques, like dropout or L2 regularization, can be used to prevent overfitting.\n",
    "\n",
    "5. **Model Complexity:** Consider using a simpler model or reducing the complexity of your existing model.\n",
    "\n",
    "6. **Stratified K-Fold:** Instead of standard K-Fold, use Stratified K-Fold which maintains the percentage of samples for each class. This ensures that each fold is a good representative of the overall class distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resampling:\n",
    "Oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_indices = np.where(y == 0)[0]\n",
    "minority_indices = np.where(y == 1)[0]\n",
    "\n",
    "majority = X[majority_indices]\n",
    "minority = X[minority_indices]\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority,\n",
    "                              replace=True,\n",
    "                              n_samples=majority.shape[0],\n",
    "                              random_state=42)\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "X_upsampled = np.vstack([majority, minority_upsampled])\n",
    "y_upsampled = np.hstack([y[majority_indices], [1] * minority_upsampled.shape[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "majority_downsampled = resample(majority,\n",
    "                                replace=False,\n",
    "                                n_samples=minority.shape[0],\n",
    "                                random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_downsampled = np.vstack([majority_downsampled, minority])\n",
    "y_downsampled = np.hstack([y[majority_indices][:minority.shape[0]], y[minority_indices]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text data to 3-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 999, 'text': [[9, 1017, 4], [1017, 4, 1394], [4, 1394, 0], [1394, 0, 61], [0, 61, 365], [61, 365, 2539], [365, 2539, 3], [2539, 3, 0], [3, 0, 7], [0, 7, 89], [7, 89, 1615], [89, 1615, 27], [1615, 27, 71], [27, 71, 91], [71, 91, 365], [91, 365, 76], [365, 76, 27], [76, 27, 10], [27, 10, 125], [10, 125, 4], [125, 4, 200], [4, 200, 0], [200, 0, 7], [0, 7, 36], [7, 36, 188], [36, 188, 1], [188, 1, 11], [1, 11, 119], [11, 119, 2], [119, 2, 294], [2, 294, 4], [294, 4, 631], [4, 631, 36], [631, 36, 97], [36, 97, 4894], [97, 4894, 118], [4894, 118, 0], [118, 0, 36], [0, 36, 1278], [36, 1278, 8], [1278, 8, 37], [8, 37, 125], [37, 125, 4], [125, 4, 4113], [4, 4113, 2], [4113, 2, 566], [2, 566, 19], [566, 19, 36], [19, 36, 273], [36, 273, 135], [273, 135, 2585], [135, 2585, 3], [2585, 3, 27], [3, 27, 23], [27, 23, 1], [23, 1, 1234], [1, 1234, 133], [1234, 133, 114], [133, 114, 533], [114, 533, 0], [533, 0, 7], [0, 7, 3257], [7, 3257, 0], [3257, 0, 1485], [0, 1485, 6], [1485, 6, 4894], [6, 4894, 16], [4894, 16, 2], [16, 2, 188], [2, 188, 1], [188, 1, 27], [1, 27, 121], [27, 121, 168], [121, 168, 18], [168, 18, 321], [18, 321, 27], [321, 27, 239], [27, 239, 36], [239, 36, 0], [36, 0, 1266], [0, 1266, 1], [1266, 1, 11], [1, 11, 32], [11, 32, 427], [32, 427, 874], [427, 874, 276], [874, 276, 113], [276, 113, 3], [113, 3, 7], [3, 7, 2], [7, 2, 67], [2, 67, 11], [67, 11, 147], [11, 147, 19], [147, 19, 32], [19, 32, 87], [32, 87, 427], [87, 427, 874], [427, 874, 276], [874, 276, 3], [276, 3, 23], [3, 23, 1234], [23, 1234, 3], [1234, 3, 5], [3, 5, 0], [5, 0, 140], [0, 140, 3366], [140, 3366, 1], [3366, 1, 1519], [1, 1519, 0], [1519, 0, 8], [0, 8, 4340], [8, 4340, 0], [4340, 0, 143], [0, 143, 2], [143, 2, 4121], [2, 4121, 10], [4121, 10, 74], [10, 74, 108], [74, 108, 0], [108, 0, 383], [0, 383, 16], [383, 16, 36], [16, 36, 183], [36, 183, 6], [183, 6, 0], [6, 0, 3], [0, 3, 1234], [3, 1234, 121], [1234, 121, 0], [121, 0, 1], [0, 1, 392], [1, 392, 0], [392, 0, 3164], [0, 3164, 0], [3164, 0, 1], [0, 1, 4], [1, 4, 93], [4, 93, 81], [93, 81, 116], [81, 116, 143], [116, 143, 2], [143, 2, 4121], [2, 4121, 59], [4121, 59, 42], [59, 42, 522], [42, 522, 81], [522, 81, 9], [81, 9, 3], [9, 3, 13], [3, 13, 10], [13, 10, 85], [10, 85, 1319], [85, 1319, 3], [1319, 3, 27], [3, 27, 23], [27, 23, 1], [23, 1, 12], [1, 12, 0], [12, 0, 4], [0, 4, 57], [4, 57, 10], [57, 10, 1485], [10, 1485, 13], [1485, 13, 1], [13, 1, 0], [1, 0, 23], [0, 23, 2], [23, 2, 188], [2, 188, 582], [188, 582, 52], [582, 52, 6], [52, 6, 286], [6, 286, 72], [286, 72, 36], [72, 36, 1840], [36, 1840, 325], [1840, 325, 21], [325, 21, 274], [21, 274, 7], [274, 7, 5], [7, 5, 0], [5, 0, 480], [0, 480, 561], [480, 561, 2], [561, 2, 233], [2, 233, 2640], [233, 2640, 34], [2640, 34, 26], [34, 26, 44], [26, 44, 2974], [44, 2974, 1], [2974, 1, 1234], [1, 1234, 121], [1234, 121, 0], [121, 0, 27], [0, 27, 10], [27, 10, 125], [10, 125, 4], [125, 4, 1386], [4, 1386, 45], [1386, 45, 1919], [45, 1919, 9], [1919, 9, 816], [9, 816, 16], [816, 16, 2], [16, 2, 472], [2, 472, 4894], [472, 4894, 1], [4894, 1, 2], [1, 2, 92], [2, 92, 291], [92, 291, 11], [291, 11, 190], [11, 190, 6], [190, 6, 36], [6, 36, 17], [36, 17, 3], [17, 3, 59], [3, 59, 27], [59, 27, 899], [27, 899, 18], [899, 18, 36], [18, 36, 800], [36, 800, 3], [800, 3, 12], [3, 12, 27], [12, 27, 200], [27, 200, 327], [200, 327, 564], [327, 564, 52], [564, 52, 3], [52, 3, 2], [3, 2, 604], [2, 604, 23], [604, 23, 1], [23, 1, 7], [1, 7, 27], [7, 27, 23], [27, 23, 27], [23, 27, 60], [27, 60, 1], [60, 1, 161], [1, 161, 2], [161, 2, 253], [2, 253, 197], [253, 197, 52], [197, 52, 3], [52, 3, 1234], [3, 1234, 23], [1234, 23, 27], [23, 27, 4967], [27, 4967, 8], [4967, 8, 37], [8, 37, 1574], [37, 1574, 4], [1574, 4, 0], [4, 0, 76], [0, 76, 406], [76, 406, 27], [406, 27, 60], [27, 60, 85], [60, 85, 4], [85, 4, 76], [4, 76, 29], [76, 29, 41], [29, 41, 44], [41, 44, 0], [44, 0, 19], [0, 19, 67], [19, 67, 0], [67, 0, 57], [0, 57, 3], [57, 3, 252], [3, 252, 97], [252, 97, 1652], [97, 1652, 674], [1652, 674, 1], [674, 1, 45], [1, 45, 98], [45, 98, 137], [98, 137, 214], [137, 214, 140], [214, 140, 2940], [140, 2940, 4], [2940, 4, 631], [4, 631, 4894], [631, 4894, 16], [4894, 16, 2], [16, 2, 188], [2, 188, 3], [188, 3, 27], [3, 27, 23], [27, 23, 1], [23, 1, 2], [1, 2, 604], [2, 604, 23], [604, 23, 27], [23, 27, 8], [27, 8, 15], [8, 15, 44], [15, 44, 156], [44, 156, 623], [156, 623, 33], [623, 33, 2], [33, 2, 242], [2, 242, 0], [242, 0, 6], [0, 6, 0], [6, 0, 3], [0, 3, 718], [3, 718, 27], [718, 27, 78], [27, 78, 28], [78, 28, 669], [28, 669, 12], [669, 12, 88], [12, 88, 1], [88, 1, 36], [1, 36, 8], [36, 8, 1542], [8, 1542, 20], [1542, 20, 8], [20, 8, 4580], [8, 4580, 57], [4580, 57, 5], [57, 5, 232], [5, 232, 683], [232, 683, 3], [683, 3, 1234], [3, 1234, 23], [1234, 23, 1], [23, 1, 27], [1, 27, 10], [27, 10, 127], [10, 127, 0], [127, 0, 3], [0, 3, 7], [3, 7, 12], [7, 12, 119], [12, 119, 13], [119, 13, 53], [13, 53, 0], [53, 0, 1], [0, 1, 954], [1, 954, 18], [954, 18, 5], [18, 5, 0], [5, 0, 3], [0, 3, 8], [3, 8, 30], [8, 30, 3250], [30, 3250, 17], [3250, 17, 18], [17, 18, 157], [18, 157, 8]]}\n"
     ]
    }
   ],
   "source": [
    "def sequence_to_trigrams(sequence):\n",
    "    # Extract 3-grams from the sequence\n",
    "    return [sequence[i:i+3] for i in range(len(sequence)-2)]\n",
    "\n",
    "data[\"text\"] = sequence_to_trigrams(data[\"text\"])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2)) \n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Modelling\n",
    "- Data\n",
    "    - Domain 1\n",
    "    - Domain 2\n",
    "    - Domain 1 & 2\n",
    "\n",
    "- Data Processing\n",
    "    - Sequence\n",
    "    - Bag of Words\n",
    "        - with n-gram\n",
    "    - TFIDF\n",
    "        - with n-gram\n",
    "\n",
    "- Parameters\n",
    "    - Tree Depth\n",
    "\n",
    "- Validation\n",
    "    - 10-fold cross validation\n",
    "    \n",
    "- Visualisation\n",
    "    - Accuracy Graph\n",
    "    - Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(index):\n",
    "    text = []\n",
    "    label = []\n",
    "\n",
    "    if index == 1 or index == 3:\n",
    "        with open(\"../../data/domain1_train.json\") as f:\n",
    "            for line in f:\n",
    "                # read line by line\n",
    "                data = json.loads(line)\n",
    "\n",
    "                # add values\n",
    "                text.append(data[\"text\"])\n",
    "                label.append(data[\"label\"])\n",
    "\n",
    "    if index == 2 or index == 3:\n",
    "        with open(\"../../data/domain2_train.json\") as f:\n",
    "            for line in f:\n",
    "                # read line by line\n",
    "                data = json.loads(line)\n",
    "\n",
    "                # add values\n",
    "                text.append(data[\"text\"])\n",
    "                label.append(data[\"label\"])\n",
    "\n",
    "    # print(f\"Domain{index} length:\", len(text))\n",
    "    \n",
    "    return text, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain1 length: 19500\n",
      "Domain2 length: 14900\n",
      "Domain1&2 length: 34400\n"
     ]
    }
   ],
   "source": [
    "print(\"Domain1 length:\", len(load_data(1)[0]))\n",
    "print(\"Domain2 length:\", len(load_data(2)[0]))\n",
    "print(\"Domain1&2 length:\", len(load_data(3)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sample data for making vertor space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_sample(text):\n",
    "    # Number of words: 5000\n",
    "    sample = [np.arange(5000).tolist()]\n",
    "\n",
    "    # For n-gram\n",
    "    sample += text\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size for D1: 19501\n"
     ]
    }
   ],
   "source": [
    "# Data domain\n",
    "d = 1\n",
    "print(f\"sample size for D{d}:\", len(vector_sample(load_data(d)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def toStr(n):\n",
    "   return str(n)\n",
    "\n",
    "def count_vec(vector_sample, text, n_features):\n",
    "   # Create a Vectorizer Object\n",
    "   vectorizer = CountVectorizer(preprocessor= toStr, analyzer=\"word\", token_pattern=r\"(?u)\\b\\w+\\b\", ngram_range=(1, 3), max_features=n_features)\n",
    "\n",
    "   vectorizer.fit(vector_sample)\n",
    "\n",
    "   # Printing the identified Unique words along with their indices\n",
    "   # print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "\n",
    "   # Encode the Document\n",
    "   vector = vectorizer.transform(text)\n",
    "\n",
    "   # Summarizing the Encoded Texts\n",
    "   # print(\"Encoded Document is:\")\n",
    "   # print(vector.toarray())\n",
    "\n",
    "   return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19500, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data domain\n",
    "d = 1\n",
    "count_vec(vector_sample(load_data(d)[0]), load_data(d)[0], 10000).toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Parameters & Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAINS = range(1, 4)\n",
    "N_FEATURES = range(5000, 20000, 5000)\n",
    "T_DEPTHS = range(1, 10, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW_training(domain, features, t_depth):\n",
    "    # BoW\n",
    "    d = domain\n",
    "    f = features\n",
    "    t = t_depth\n",
    "    text, label = load_data(d)\n",
    "    sample = vector_sample(text)\n",
    "    X = count_vec(sample, text, f).toarray()\n",
    "    y = np.array(label).ravel()\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=t, random_state=0)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    return clf, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "n = 10\n",
    "cv_scores = []\n",
    "r2_scores = []\n",
    "c_matrix = []\n",
    "\n",
    "\n",
    "for d in (2,3):#DOMAINS:\n",
    "    for f in N_FEATURES:\n",
    "        for t in T_DEPTHS:\n",
    "            # For BoW\n",
    "            clf, X, y = BoW_training(d, f, t)\n",
    "\n",
    "            print(f\"For Domain{d} & {f} Features & {t} Depth:\")\n",
    "            print(\"Shape of X:\", X.shape)\n",
    "            print(\"Shape of y:\", y.shape)\n",
    "    \n",
    "            # r2 score\n",
    "            y_pred = clf.predict(X)\n",
    "            r2_scores.append(r2_score(y, y_pred))\n",
    "            print(\"R2 Score\\n\", r2_scores[-1])\n",
    "\n",
    "            # Confusion matrix\n",
    "            c_matrix.append(confusion_matrix(y, y_pred))\n",
    "            print(\"Confusion Matirx\\n\", c_matrix[-1])\n",
    "\n",
    "            # Cross-validation score\n",
    "            cv_scores.append(cross_val_score(clf, X, y, cv=n))\n",
    "            print(\"CV Score\\n\", cv_scores[-1], \"\\n\")\n",
    "\n",
    "            # To csv\n",
    "            cv_result = pd.DataFrame([r2_scores[-1]]+[sum(cv_scores[-1])/n]+cv_scores[-1].tolist(), index=[\"r2\", \"cv_avg\"]+[f\"{i}\" for i in range(1,11)], columns=[\"scores\"])\n",
    "            cv_result.to_csv(f\"../../data/results/RF/RF-CV-D{d}_F{f}T{t}.csv\")\n",
    "            cm_result = pd.DataFrame({\"tn\": [c_matrix[-1][0][0]], \"fn\": [c_matrix[-1][1][0]], \"tp\": [c_matrix[-1][1][1]], \"fp\": [c_matrix[-1][0][1]]})\n",
    "            cm_result.to_csv(f\"../../data/results/RF/RF-CM-D{d}_F{f}T{t}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
